{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dcm2bids \u2693\ufe0e Your friendly DICOM converter. dcm2bids reorganises NIfTI files using dcm2niix into the Brain Imaging Data Structure (BIDS). Scope \u2693\ufe0e dcm2bids is a community-centered project. It aims to be a friendly, easy-to-use tool to convert your dicoms. Our main goal is to make the dicom to BIDS conversion as effortless as possible. Even if in the near future more advanced features will be added, we'll keep the focus on your day to day use case without complicating anything. That's the promise of the dcm2bids project. Documentation \u2693\ufe0e Please take a look at the documentation to: Learn about bids with some dataset examples Install dcm2bids Follow the tutorial Seek for more advanced usage Issues and Questions \u2693\ufe0e We work hard to make sure dcm2bids is robust and we welcome comments and questions to make sure it meets your use case! Here's our preferred workflow: If you have a usage question , we encourage you to post your question on Neurostars with dcm2bids as an optional tag. The tag is really important because Neurostars will notify the dcm2bids team only if the tag is present. Neurostars is a question and answer forum for neuroscience researchers, infrastructure providers and software developers, and free to access. Before posting your question, you may want to first browse through questions that were tagged with the dcm2bids tag . If your question persists, feel free to comment on previous questions or ask your own question. If you think you've found a bug , please open an issue on our repository . To do this, you'll need a GitHub account. See our contributing guide for more details.","title":"Home"},{"location":"#dcm2bids","text":"Your friendly DICOM converter. dcm2bids reorganises NIfTI files using dcm2niix into the Brain Imaging Data Structure (BIDS).","title":"dcm2bids"},{"location":"#scope","text":"dcm2bids is a community-centered project. It aims to be a friendly, easy-to-use tool to convert your dicoms. Our main goal is to make the dicom to BIDS conversion as effortless as possible. Even if in the near future more advanced features will be added, we'll keep the focus on your day to day use case without complicating anything. That's the promise of the dcm2bids project.","title":"Scope"},{"location":"#documentation","text":"Please take a look at the documentation to: Learn about bids with some dataset examples Install dcm2bids Follow the tutorial Seek for more advanced usage","title":"Documentation"},{"location":"#issues-and-questions","text":"We work hard to make sure dcm2bids is robust and we welcome comments and questions to make sure it meets your use case! Here's our preferred workflow: If you have a usage question , we encourage you to post your question on Neurostars with dcm2bids as an optional tag. The tag is really important because Neurostars will notify the dcm2bids team only if the tag is present. Neurostars is a question and answer forum for neuroscience researchers, infrastructure providers and software developers, and free to access. Before posting your question, you may want to first browse through questions that were tagged with the dcm2bids tag . If your question persists, feel free to comment on previous questions or ask your own question. If you think you've found a bug , please open an issue on our repository . To do this, you'll need a GitHub account. See our contributing guide for more details.","title":"Issues and Questions"},{"location":"CHANGELOG/","text":"CHANGELOG \u2693\ufe0e 2.1.7 - 2022-05-30 \u2693\ufe0e Last version before refactoring. Major and minor documentation fixes Fix \u00ccntended for Fix Entity table order Fix Windows paths Fix issue when no internet Remove support to Python 2.6 2.1.6 - 2021-02-16 \u2693\ufe0e New Containers Fix pypi package 2.1.5 - 2021-01-04 \u2693\ufe0e Add possibility to be not case sensitive Fix issue 34: dcm2bids not ordering runs chronologically 2.1.4 - 2019-04-04 \u2693\ufe0e Add a tutorial to the documentation Update BIDS version in dcm2bids_scaffold Bug fix when intendedFor was equal to 0 Restructuring of the documentation and add version description 2.1.3 - 2019-04-02 \u2693\ufe0e dicom_dir can be a list or str 2.1.2 - 2019-04-01 \u2693\ufe0e Add documentation with mkdocs Bug fix in dcm2niix_version 2.1.1 - 2019-03-29 \u2693\ufe0e Bug fix 2.1.0 - 2019-03-28 \u2693\ufe0e Checking if a new version of dcm2bids or dcm2niix is available on github dcm2niix output is now log to file as debug Add dcm2bids version to sidecars intendedFor option can also be a list 2.0.0 - 2019-03-10 \u2693\ufe0e The anonymizer option no longer exists from the script dcm2bids. It is still possible to deface the anatomical nifti images using the \"defaceTpl\" key in the congifuration file. Acquisitions are now sorted using the sidecar data instead of only the sidecar filename. The default behaviour is to sort by SeriesNumber then by AcquisitionTime then by the SidecarFilename . You can change this behaviour setting the key \"compKeys\" inside the configuration file. Add an option to use re for more flexibility for matching criteria. Set the key \"searchMethod\" to \"re\" in the config file. fnmatch is still the default. Design fix in matching with list in the sidecar. Sidecar modification using \"sidecarChanges\" in the configuration file. intendedFor option for fieldmap in the configuration file log improvement major code refactoring add docstrings add tests with pytest 1.1.8 - 2018-02-02 \u2693\ufe0e Add dcm2bids as runscript inside Singularity Remove logger from dcm2bids_helper 1.1.7 - 2018-02-01 \u2693\ufe0e 1.1.6 - 2018-02-01 \u2693\ufe0e 1.1.4 - 2017-11-09 \u2693\ufe0e 1.1.3 - 2017-11-09 \u2693\ufe0e 1.1.2 - 2017-11-03 \u2693\ufe0e 1.0.1 - 2017-11-01 \u2693\ufe0e","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"CHANGELOG"},{"location":"CHANGELOG/#217-2022-05-30","text":"Last version before refactoring. Major and minor documentation fixes Fix \u00ccntended for Fix Entity table order Fix Windows paths Fix issue when no internet Remove support to Python 2.6","title":"2.1.7 - 2022-05-30"},{"location":"CHANGELOG/#216-2021-02-16","text":"New Containers Fix pypi package","title":"2.1.6 - 2021-02-16"},{"location":"CHANGELOG/#215-2021-01-04","text":"Add possibility to be not case sensitive Fix issue 34: dcm2bids not ordering runs chronologically","title":"2.1.5 - 2021-01-04"},{"location":"CHANGELOG/#214-2019-04-04","text":"Add a tutorial to the documentation Update BIDS version in dcm2bids_scaffold Bug fix when intendedFor was equal to 0 Restructuring of the documentation and add version description","title":"2.1.4 - 2019-04-04"},{"location":"CHANGELOG/#213-2019-04-02","text":"dicom_dir can be a list or str","title":"2.1.3 - 2019-04-02"},{"location":"CHANGELOG/#212-2019-04-01","text":"Add documentation with mkdocs Bug fix in dcm2niix_version","title":"2.1.2 - 2019-04-01"},{"location":"CHANGELOG/#211-2019-03-29","text":"Bug fix","title":"2.1.1 - 2019-03-29"},{"location":"CHANGELOG/#210-2019-03-28","text":"Checking if a new version of dcm2bids or dcm2niix is available on github dcm2niix output is now log to file as debug Add dcm2bids version to sidecars intendedFor option can also be a list","title":"2.1.0 - 2019-03-28"},{"location":"CHANGELOG/#200-2019-03-10","text":"The anonymizer option no longer exists from the script dcm2bids. It is still possible to deface the anatomical nifti images using the \"defaceTpl\" key in the congifuration file. Acquisitions are now sorted using the sidecar data instead of only the sidecar filename. The default behaviour is to sort by SeriesNumber then by AcquisitionTime then by the SidecarFilename . You can change this behaviour setting the key \"compKeys\" inside the configuration file. Add an option to use re for more flexibility for matching criteria. Set the key \"searchMethod\" to \"re\" in the config file. fnmatch is still the default. Design fix in matching with list in the sidecar. Sidecar modification using \"sidecarChanges\" in the configuration file. intendedFor option for fieldmap in the configuration file log improvement major code refactoring add docstrings add tests with pytest","title":"2.0.0 - 2019-03-10"},{"location":"CHANGELOG/#118-2018-02-02","text":"Add dcm2bids as runscript inside Singularity Remove logger from dcm2bids_helper","title":"1.1.8 - 2018-02-02"},{"location":"CHANGELOG/#117-2018-02-01","text":"","title":"1.1.7 - 2018-02-01"},{"location":"CHANGELOG/#116-2018-02-01","text":"","title":"1.1.6 - 2018-02-01"},{"location":"CHANGELOG/#114-2017-11-09","text":"","title":"1.1.4 - 2017-11-09"},{"location":"CHANGELOG/#113-2017-11-09","text":"","title":"1.1.3 - 2017-11-09"},{"location":"CHANGELOG/#112-2017-11-03","text":"","title":"1.1.2 - 2017-11-03"},{"location":"CHANGELOG/#101-2017-11-01","text":"","title":"1.0.1 - 2017-11-01"},{"location":"CODE_OF_CONDUCT/","text":"Code of Conduct \u2693\ufe0e Each of us as a member of the dcm2bids community we ensure that every contributors enjoy their time contributing and helping people. Accordingly, everyone who participates in the development in any way possible is expected to show respect, courtesy to other community members including end-users who are seeking help on Neurostars or on GitHub . We also encourage everybody regardless of age, gender identity, level of experience, native langage, race or religion to be involved in the project. We pledge to make participation in the dcm2bids project an harassment-free experience for everyone. Our standards \u2693\ufe0e We commit to promote any behavior that contributes to create a positive environment including: Using welcoming and inclusive language; Being respectful; Show empathy towards everybody; Focusing on what is best for the community. We do NOT tolerate harassment or inappropriate behavior in the dcm2bids community. Our responsibilities \u2693\ufe0e Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u2693\ufe0e This Code of Conduct applies both within our online GitHub repository and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u2693\ufe0e Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting Arnaud Bor\u00e9 at arnaud.bore@criugm.qc.ca . Confidentiality will be respected in reporting. As the first interim Benevolent Dictator for Life (BDFL) , Arnaud Bor\u00e9 can take any action he deems appropriate for the safety of the dcm2bids community, including but not limited to: facilitating a conversation between the two parties involved in the violation of the code of conduct; requesting a contributor apologize for their behavior; asking a contributor or multiple contributors to enter a cooling off period that puts a time-limited pause on a particular discussion topic; asking a contributor to no longer participate in the development of dcm2bids . Attribution \u2693\ufe0e This Code of Conduct was adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html as well as Code of Conduct from the tedana and STEMMRoleModels projects.","title":"Code of conduct"},{"location":"CODE_OF_CONDUCT/#code-of-conduct","text":"Each of us as a member of the dcm2bids community we ensure that every contributors enjoy their time contributing and helping people. Accordingly, everyone who participates in the development in any way possible is expected to show respect, courtesy to other community members including end-users who are seeking help on Neurostars or on GitHub . We also encourage everybody regardless of age, gender identity, level of experience, native langage, race or religion to be involved in the project. We pledge to make participation in the dcm2bids project an harassment-free experience for everyone.","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT/#our-standards","text":"We commit to promote any behavior that contributes to create a positive environment including: Using welcoming and inclusive language; Being respectful; Show empathy towards everybody; Focusing on what is best for the community. We do NOT tolerate harassment or inappropriate behavior in the dcm2bids community.","title":"Our standards"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our responsibilities"},{"location":"CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies both within our online GitHub repository and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting Arnaud Bor\u00e9 at arnaud.bore@criugm.qc.ca . Confidentiality will be respected in reporting. As the first interim Benevolent Dictator for Life (BDFL) , Arnaud Bor\u00e9 can take any action he deems appropriate for the safety of the dcm2bids community, including but not limited to: facilitating a conversation between the two parties involved in the violation of the code of conduct; requesting a contributor apologize for their behavior; asking a contributor or multiple contributors to enter a cooling off period that puts a time-limited pause on a particular discussion topic; asking a contributor to no longer participate in the development of dcm2bids .","title":"Enforcement"},{"location":"CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct was adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html as well as Code of Conduct from the tedana and STEMMRoleModels projects.","title":"Attribution"},{"location":"CONTRIBUTING/","text":"Contributing to dcm2bids \u2693\ufe0e Welcome to the dcm2bids repository and thank you for thinking about contributing! This document has been written in such a way you feel at ease to find your way on how you can make a difference for the dcm2bids community. We tried to cover as much as possible in few words possible. If you have any questions don't hesitate to share them in the section below. There are multiple ways to be helpful to the dcm2bids community. If you already know what you are looking for, you can select one of the section below: Contributing to dcm2bids Welcome Contributing through Neurostars Contributing through GitHub Recommended workflow Open an issue or choose one to fix Fork the dcm2bids repository Test your branch Check list Submit and tag your pull request Recognizing your contribution Thank you! If you don't know where or how to get started, keep on reading below. Welcome \u2693\ufe0e dcm2bids is a small project started in 2017 by Christophe Bedetti ( @cbedetti ). In 2021, we have started a new initiative and we're excited to have you join! You can introduce yourself on our Welcome to Dcm2Bids Discussion and tell us how you would like to contribute in the dcm2bids community. Let us know what your interests are and we will help you find an issue to contribute to if you haven't already spotted one yet. Most of our discussions will take place on open issues and in the newly created GitHub Discussions . Thanks so much! As a reminder, we expect all contributions to dcm2bids to adhere to our Code of Conduct . Contributing through Neurostars \u2693\ufe0e The dcm2bids community highlight all contributions to dcm2bids . Helping users on Neurostars forum is one of them. Neurostars has a dcm2bids tag that helps us following any question regarding the project. You can ask Neurostars to notify you when a new message tagged with dcm2bids has been posted. If you know the answer, you can reply following our code of conduct . How to receive email notifications from Neurostars If you want to receive email notifications, you have to go set your settings accordingly on Neurostars. The procedure below will get you to this (personalized) URL: https://neurostars.org/u/ YOURUSERNAME /preferences/tags : Click on your picture in the top right corner Click on the \ud83d\udc64 (user) icon Click on \u2699\ufe0f Preferences Click on Notifications Click on Tags We recommend to add dcm2bids to the Watched section, but you can add it to any section that fits your need. Contributing through GitHub \u2693\ufe0e Git is a really useful tool for version control . GitHub sits on top of git and supports collaborative and distributed working. Before you start you'll need to set up a free GitHub account and sign in. You can sign up through this link and then interact on our repository at https://github.io/UNFmontreal/Dcm2Bids . You'll use Markdown to discuss on GitHub. You can think of Markdown as a few little symbols around your text that will allow GitHub to render the text with a little bit of formatting. For example you can write words as bold ( **bold** ), or in italics ( *italics* ), or as a link ( [link](https://youtu.be/dQw4w9WgXcQ) ) to another webpage. Did you know? Most software documentation websites are written in Markdown. Even the dcm2bids documentation website is written in Markdown! GitHub has a helpful guide to get you started with writing and formatting Markdown . Recommended workflow \u2693\ufe0e We will be excited when you'll suggest a new PR to fix, enhance or develop dcm2bids . In order to make this as fluid as possible we recommend to follow this workflow: Open an issue or choose one to fix \u2693\ufe0e Issues are individual pieces of work that need to be completed to move the project forwards. Before starting to work on a new pull request we highly recommend you open an issue to explain what you want to do and how it echoes a specific demand from the community. Keep in mind the scope of the dcm2bids project. If you have more an inquiry or suggestion to make than a bug to report, we encourage you to start a conversation in the Discussions section . A general guideline: if you find yourself tempted to write a great big issue that is difficult to describe as one unit of work, please consider splitting it into two or more. Moreover, it will be interesting to see how others approach your issue and give their opinion and maybe give you advice to find the best way to code it. Finally, it will prevent you to start working on something that is already in progress. The list of all labels is here and include: These issues contain a task that a member of the team has determined we need additional help with. If you feel that you can contribute to one of these issues, we especially encourage you to do so! These issues point to problems in the project. If you find new a bug, please give as much detail as possible in your issue, including steps to recreate the error. If you experience the same bug as one already listed, please add any additional information that you have as a comment. These issues are asking for enhancements to be added to the project. Please try to make sure that your enhancement is distinct from any others that have already been requested or implemented. If you find one that's similar but there are subtle differences please reference the other request in your issue. Fork the dcm2bids repository \u2693\ufe0e This way you'll be able to work on your own instance of dcm2bids . It will be a safe place where nothing can affect the main repository. Make sure your master branch is always up-to-date with dcm2bids' master branch. You can also follow these command lines. The first time you try to sync your fork , you may have to set the upstream branch : 1 2 git remote add upstream https://github.com/UNFmontreal/Dcm2Bids.git git remote -v # Verify the new upstream repo appears. 1 2 3 git checkout master git fetch upstream master git merge upstream/master Then create a new branch for each issue. Using a new branch allows you to follow the standard GitHub workflow when making changes. This guide provides a useful overview for this workflow. Please keep the name of your branch short and self explanatory. 1 git checkout -b MYBRANCH Test your branch \u2693\ufe0e If you are proposing new features, you'll need to add new tests as well. In any case, you have to test your branch prior to submit your PR. If you have new code you will have to run pytest: 1 pytest -v tests/test_dcm2bids.py dcm2bids project is following PEP8 convention whenever possible. You can check your code using this command line: 1 flake8 FileIWantToCheck Regardless, when you open a Pull Request, we use Tox to run all unit and integration tests. If you have propose a PR about a modification on the documentation you can have a preview from an editor like Atom using CTRL+SHIFT+M . Check list \u2693\ufe0e Pull Request Checklist (For Fastest Review): Check that all tests are passing (\"All tests passsed\") Make sure you have docstrings for any new functions Make sure that docstrings are updated for edited functions Make sure you note any issues that will be closed by your PR Add a clear description of the purpose of you PR Submit and tag your pull request \u2693\ufe0e When you submit a pull request we ask you to follow the tag specification. In order to simplify reviewers work, we ask you to use at least one of the following tags: [BRK] for changes which break existing builds or tests [DOC] for new or updated documentation [ENH] for enhancements [FIX] for bug fixes [TST] for new or updated tests [REF] for refactoring existing code [MAINT] for maintenance of code [WIP] for work in progress You can also combine the tags above, for example if you are updating both a test and the documentation: [TST, DOC]. Recognizing your contribution \u2693\ufe0e We welcome and recognize all contributions from documentation to testing to code development. You can see a list of current contributors in the README (kept up to date by the all contributors bot ). You can see here for instructions on how to use the bot. Thank you! \u2693\ufe0e You're amazing. \u2014 Based on contributing guidelines from the STEMMRoleModels and tedana projects.","title":"Contribute to dcm2bids"},{"location":"CONTRIBUTING/#contributing-to-dcm2bids","text":"Welcome to the dcm2bids repository and thank you for thinking about contributing! This document has been written in such a way you feel at ease to find your way on how you can make a difference for the dcm2bids community. We tried to cover as much as possible in few words possible. If you have any questions don't hesitate to share them in the section below. There are multiple ways to be helpful to the dcm2bids community. If you already know what you are looking for, you can select one of the section below: Contributing to dcm2bids Welcome Contributing through Neurostars Contributing through GitHub Recommended workflow Open an issue or choose one to fix Fork the dcm2bids repository Test your branch Check list Submit and tag your pull request Recognizing your contribution Thank you! If you don't know where or how to get started, keep on reading below.","title":"Contributing to dcm2bids"},{"location":"CONTRIBUTING/#welcome","text":"dcm2bids is a small project started in 2017 by Christophe Bedetti ( @cbedetti ). In 2021, we have started a new initiative and we're excited to have you join! You can introduce yourself on our Welcome to Dcm2Bids Discussion and tell us how you would like to contribute in the dcm2bids community. Let us know what your interests are and we will help you find an issue to contribute to if you haven't already spotted one yet. Most of our discussions will take place on open issues and in the newly created GitHub Discussions . Thanks so much! As a reminder, we expect all contributions to dcm2bids to adhere to our Code of Conduct .","title":"Welcome"},{"location":"CONTRIBUTING/#contributing-through-neurostars","text":"The dcm2bids community highlight all contributions to dcm2bids . Helping users on Neurostars forum is one of them. Neurostars has a dcm2bids tag that helps us following any question regarding the project. You can ask Neurostars to notify you when a new message tagged with dcm2bids has been posted. If you know the answer, you can reply following our code of conduct . How to receive email notifications from Neurostars If you want to receive email notifications, you have to go set your settings accordingly on Neurostars. The procedure below will get you to this (personalized) URL: https://neurostars.org/u/ YOURUSERNAME /preferences/tags : Click on your picture in the top right corner Click on the \ud83d\udc64 (user) icon Click on \u2699\ufe0f Preferences Click on Notifications Click on Tags We recommend to add dcm2bids to the Watched section, but you can add it to any section that fits your need.","title":"Contributing through Neurostars"},{"location":"CONTRIBUTING/#contributing-through-github","text":"Git is a really useful tool for version control . GitHub sits on top of git and supports collaborative and distributed working. Before you start you'll need to set up a free GitHub account and sign in. You can sign up through this link and then interact on our repository at https://github.io/UNFmontreal/Dcm2Bids . You'll use Markdown to discuss on GitHub. You can think of Markdown as a few little symbols around your text that will allow GitHub to render the text with a little bit of formatting. For example you can write words as bold ( **bold** ), or in italics ( *italics* ), or as a link ( [link](https://youtu.be/dQw4w9WgXcQ) ) to another webpage. Did you know? Most software documentation websites are written in Markdown. Even the dcm2bids documentation website is written in Markdown! GitHub has a helpful guide to get you started with writing and formatting Markdown .","title":"Contributing through GitHub"},{"location":"CONTRIBUTING/#recommended-workflow","text":"We will be excited when you'll suggest a new PR to fix, enhance or develop dcm2bids . In order to make this as fluid as possible we recommend to follow this workflow:","title":"Recommended workflow"},{"location":"CONTRIBUTING/#open-an-issue-or-choose-one-to-fix","text":"Issues are individual pieces of work that need to be completed to move the project forwards. Before starting to work on a new pull request we highly recommend you open an issue to explain what you want to do and how it echoes a specific demand from the community. Keep in mind the scope of the dcm2bids project. If you have more an inquiry or suggestion to make than a bug to report, we encourage you to start a conversation in the Discussions section . A general guideline: if you find yourself tempted to write a great big issue that is difficult to describe as one unit of work, please consider splitting it into two or more. Moreover, it will be interesting to see how others approach your issue and give their opinion and maybe give you advice to find the best way to code it. Finally, it will prevent you to start working on something that is already in progress. The list of all labels is here and include: These issues contain a task that a member of the team has determined we need additional help with. If you feel that you can contribute to one of these issues, we especially encourage you to do so! These issues point to problems in the project. If you find new a bug, please give as much detail as possible in your issue, including steps to recreate the error. If you experience the same bug as one already listed, please add any additional information that you have as a comment. These issues are asking for enhancements to be added to the project. Please try to make sure that your enhancement is distinct from any others that have already been requested or implemented. If you find one that's similar but there are subtle differences please reference the other request in your issue.","title":"Open an issue or choose one to fix"},{"location":"CONTRIBUTING/#fork-the-dcm2bids-repository","text":"This way you'll be able to work on your own instance of dcm2bids . It will be a safe place where nothing can affect the main repository. Make sure your master branch is always up-to-date with dcm2bids' master branch. You can also follow these command lines. The first time you try to sync your fork , you may have to set the upstream branch : 1 2 git remote add upstream https://github.com/UNFmontreal/Dcm2Bids.git git remote -v # Verify the new upstream repo appears. 1 2 3 git checkout master git fetch upstream master git merge upstream/master Then create a new branch for each issue. Using a new branch allows you to follow the standard GitHub workflow when making changes. This guide provides a useful overview for this workflow. Please keep the name of your branch short and self explanatory. 1 git checkout -b MYBRANCH","title":"Fork the dcm2bids repository"},{"location":"CONTRIBUTING/#test-your-branch","text":"If you are proposing new features, you'll need to add new tests as well. In any case, you have to test your branch prior to submit your PR. If you have new code you will have to run pytest: 1 pytest -v tests/test_dcm2bids.py dcm2bids project is following PEP8 convention whenever possible. You can check your code using this command line: 1 flake8 FileIWantToCheck Regardless, when you open a Pull Request, we use Tox to run all unit and integration tests. If you have propose a PR about a modification on the documentation you can have a preview from an editor like Atom using CTRL+SHIFT+M .","title":"Test your branch"},{"location":"CONTRIBUTING/#check-list","text":"Pull Request Checklist (For Fastest Review): Check that all tests are passing (\"All tests passsed\") Make sure you have docstrings for any new functions Make sure that docstrings are updated for edited functions Make sure you note any issues that will be closed by your PR Add a clear description of the purpose of you PR","title":"Check list"},{"location":"CONTRIBUTING/#submit-and-tag-your-pull-request","text":"When you submit a pull request we ask you to follow the tag specification. In order to simplify reviewers work, we ask you to use at least one of the following tags: [BRK] for changes which break existing builds or tests [DOC] for new or updated documentation [ENH] for enhancements [FIX] for bug fixes [TST] for new or updated tests [REF] for refactoring existing code [MAINT] for maintenance of code [WIP] for work in progress You can also combine the tags above, for example if you are updating both a test and the documentation: [TST, DOC].","title":"Submit and tag your pull request"},{"location":"CONTRIBUTING/#recognizing-your-contribution","text":"We welcome and recognize all contributions from documentation to testing to code development. You can see a list of current contributors in the README (kept up to date by the all contributors bot ). You can see here for instructions on how to use the bot.","title":"Recognizing your contribution"},{"location":"CONTRIBUTING/#thank-you","text":"You're amazing. \u2014 Based on contributing guidelines from the STEMMRoleModels and tedana projects.","title":"Thank you!"},{"location":"docs/get-started/","text":"Getting started with dcm2bids \u2693\ufe0e How to get the most out of the documentation \u2693\ufe0e Our documentation is organized in 4 main parts and each fulfills a different function: Installation : A beginner-friendly guide that walks through the installation process, including the creation of a dedicated environment. TL;DR: Run conda install -c conda-forge dcm2bids or pip install dcm2bids within your project environment. Tutorials : Aimed at beginners and people new to dcm2bids, the tutorials are a series of steps that describes in length how to use dcm2bids in order to understand how dcm2bids works. How-to guides : Analogous to recipes, these guides provides series of steps to address typical problems and use-cases when converting into BIDS. They are less verbose than tutorials and assume some understanding of BIDS-related concepts and how dcm2bids works. There is an exception worth reading by anyone: How-to Get help and support Technical reference : Automated rendering of the code that composes the inner machinery of dcm2bids.","title":"index"},{"location":"docs/get-started/#getting-started-with-dcm2bids","text":"","title":"Getting started with dcm2bids"},{"location":"docs/get-started/#how-to-get-the-most-out-of-the-documentation","text":"Our documentation is organized in 4 main parts and each fulfills a different function: Installation : A beginner-friendly guide that walks through the installation process, including the creation of a dedicated environment. TL;DR: Run conda install -c conda-forge dcm2bids or pip install dcm2bids within your project environment. Tutorials : Aimed at beginners and people new to dcm2bids, the tutorials are a series of steps that describes in length how to use dcm2bids in order to understand how dcm2bids works. How-to guides : Analogous to recipes, these guides provides series of steps to address typical problems and use-cases when converting into BIDS. They are less verbose than tutorials and assume some understanding of BIDS-related concepts and how dcm2bids works. There is an exception worth reading by anyone: How-to Get help and support Technical reference : Automated rendering of the code that composes the inner machinery of dcm2bids.","title":"How to get the most out of the documentation"},{"location":"docs/get-started/install/","text":"Installation \u2693\ufe0e Before you can use dcm2bids, you will need to get it installed. This page guides you through a minimal, typical dcm2bids installation workflow that is sufficient to complete all dcm2bids tasks. We recommend to skim-read the full page before you start installing anything considering there are many ways to install software in the Python ecosystem which are often dependent on the familiarity and preference of the user. We offer recommendations at the bottom of the page that will take care of the whole installation process in one go and make use of a dedicated environment for dcm2bids. You just want the installation command? If you are used to installing packages, you can get it from PyPI or conda: pip install dcm2bids conda install -c conda-forge dcm2bids Dependencies \u2693\ufe0e Python \u2693\ufe0e As dcm2bids is a Python package, the first prerequisite is that Python must be installed on the machine you will use dcm2bids. You will need Python 3.7 or above to run dcm2bids properly. If you are unsure what version(s) of Python is available on your machine, you can find out by opening a terminal and typing python --version or python . The former will output the version directly in the terminal while the latter will open an interactive Python shell with the version displayed in the first line. python --version 1 2 sam:~$ python --version Python 3 .10.4 python 1 2 3 4 sam:~$ python Python 3 .10.4 | packaged by conda-forge | ( main, Mar 24 2022 , 17 :39:04 ) [ GCC 10 .3.0 ] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>> exit () If your system-wide version of Python is lower 3.7, it is okay. We will make sure to use a higher version in the isolated environment that will be created for dcm2bids. The important part is to verify that Python is installed. If you are a beginning user in the Python ecosystem, the odds are that you have installed Anaconda , which contains all Python versions so you should be good. If you were not able to find out which version of Python is installed on your machine or find Anaconda on your machine, we recommend that you install Python through Anaconda . Should I install Anaconda or Miniconda? If you unsure what to install read this section describing the differences between Anaconda and Miniconda to help you choose. dcm2niix \u2693\ufe0e dcm2niix can also be installed in a variety of ways as seen on the main page of the software . Whether you want to install the latest compiled executable directly on your machine is up to you but you have to make sure you can call the software from any directory . In other words, you have to make sure it is included in your $PATH . Otherwise, dcm2bids won't be able to run dcm2niix for you. That's why we recommend to install it at the same time in the dedicated environment. As you can see, dcm2niix is available through conda so that is the approach chosen in this guide. We will benefit from the simplicity of installing all software from the same located at. Steps to install dcm2niix are included in the next secton. Recommendations \u2693\ufe0e We recommend to install all the dependencies at once when installing dcm2bids on a machine or server. As mentioned above the minimal installation requires only dcm2bids, dcm2niix and Python >= 3.7. For ease of use and to make sure we have a reproducible environment, we recommend to use a dedicated environment through conda or, for those who have it installed, Anaconda . Note that you don't need to use specifically them to use dcm2bids, but it will make your life easier. More info on conda Conda is an open-source package management system and environment management system that runs on Windows, macOS, and Linux. Conda quickly installs, runs, and updates packages and their dependencies. Conda easily creates, saves, loads, and switches between environments on your local computer. The conda package and environment manager is included in all versions of Anaconda and Miniconda. - conda docs But I use another package/env management system, what do I do? Of course you can use your preferred package/env management system, whether it is venv, virtualenv, pyenv, pip, poetry, etc. This guide was built on the basis that no previous knowledge is required to install and learn dcm2bids by so providing a simple way to install dcm2bids without having to worry about the rest. I already created an environment for my project, what do I do? You can update your environment either by: installing dcm2bids while your environment is active like any package; or adding dcm2bids to the dependencies and updating your environment Here's an example with conda after updating an environment.yml file: 1 conda env update --file environment.yml --prune Install dcm2bids \u2693\ufe0e From now on, it is assumed that conda (or Anaconda ) is installed and correctly setup on your computer as it is the easiest way to install dcm2bids and its dependencies on any OS. We assume that if you want to install it in a different way, you have enough skills to do it on your own. If you installed Anaconda and want to use the graphical user interface (GUI), you can follow the steps as demonstrated below and only read the steps until the end of the installation guide. Create your environment with the Anaconda Navigator GUI Open Anaconda Navigator Click on Environments, then the + button at the bottom Enter the name of the environment, it can be anything. You can call it dcm2bids then select Python Click on the new dcm2bids environment, then on Channels If you only see defaults, click on Add... then enter conda-forge then click on Update channels You now need to add the two main software, so you need to search for them in the top right corner. You should see them appear as soon as you right dcm2 . You can select both at the same time. If you don't seem them, you probabble need to select All channels instead of Installed . It will ask you to install a bunch of packages, Apply . You environment should now be ready, click on the green circle with the white arrow to start the environment. A terminal window should open. You should see the name of your environment (dcm2bids) to the left. You can now test that dcm2bids works. We could install all the software one by one using a series of command: 1 2 conda install -c conda-forge dcm2bids conda install -c conda-forge dcm2niix But this would install the software in the main environment instead of a dedicated one, assuming none were active. This could have atrocious dependencies issues in the long-term if you want to install other software. Create environment.yml \u2693\ufe0e That is exactly why dedicated environments were invented. To help creating dedicated environments, we can create a file, often called environment.yml , which is used to specify things such as the dependencies that need to be installed inside the environment. To create such a file, you can use any code editor or your terminal to write or paste the information below, and save it in your project directory with the name environment.yml : You can create a project directory anywhere on your computer, it does not matter. You can create dcm2bids-proj if you need inspiration. 1 2 3 4 5 6 7 name : dcm2bids channels : - conda-forge dependencies : - python>=3.7 - dcm2niix - dcm2bids In short, here's what the fields mean: The name: key refers to the name of the dedicated environment. You will have to use this name to activate your environment and use software installed inside. The name is arbitrary, you can name it however you want. The channels: key tells conda where to look for the declared dependencies. In our case, all our dependencies are located on the conda-forge channel . The dependencies: key lists all the dependencies to be installed inside the environment. If you are creating an environment for your analysis project, this is where you would list other dependencies such as nilearn , pandas , and especially as pip since you don't want to use the pip outside of your environment Note that we specify python>=3.7 to make sure the requirement is satisfied for dcm2bids as the newer version of dcm2bids may face issue with Python 3.6 and below. Now that all the dependencies have been specified, it is time to create the new conda environment dedicated to dcm2bids! Create conda environment + install dcm2bids \u2693\ufe0e Open a terminal and go in the directory where you put the environment.yml run this command: 1 conda env create --file environment.yml If the executation was successful, you should see a message similar to: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 sam:~/dcm2bids-proj$ nano environment.yml sam:~/dcm2bids-proj$ conda env create --file environment.yml Collecting package metadata ( repodata.json ) : done Solving environment: | done Downloading and Extracting Packages future-0.18.2 | 738 KB | ########################################## | 100% Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate dcm2bids # # To deactivate an active environment, use # # $ conda deactivate Activate environment \u2693\ufe0e Last step is to make sure you can activate 1 your environment by running the command: 1 conda activate dcm2bids Remember that dcm2bids here refer to the name given specified in the environment.yml . 1 2 sam:~/dcm2bids-proj$ conda activate dcm2bids ( dcm2bids ) sam:~/dcm2bids-proj$ You can see the environment is activated as a new (dcm2bids) appear in front of the username. Verify that dcm2bids works \u2693\ufe0e Finally, you can test that dcm2bids was installed correctly by running the any dcm2bids command such as dcm2bids --help : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ( dcm2bids ) sam:~/dcm2bids-proj$ dcm2bids --help usage: dcm2bids [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] -p PARTICIPANT [ -s SESSION ] -c CONFIG [ -o OUTPUT_DIR ] [ --forceDcm2niix ] [ --clobber ] [ -l { DEBUG,INFO,WARNING,ERROR,CRITICAL }] [ -a ] Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure dcm2bids 3 .0.0 options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM directory ( ies ) -p PARTICIPANT, --participant PARTICIPANT Participant ID -s SESSION, --session SESSION Session ID -c CONFIG, --config CONFIG JSON configuration file ( see example/config.json ) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory ( /home/sam/dcm2bids-proj ) --bids_validate If set, once your conversion is done it will check if your output folder is BIDS valid. [ False ] bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator#quickstart --forceDcm2niix Overwrite previous temporary dcm2niix output if it exists --clobber Overwrite output if it exists -l { DEBUG,INFO,WARNING,ERROR,CRITICAL } , --log_level { DEBUG,INFO,WARNING,ERROR,CRITICAL } Set logging level -a, --anonymizer This option no longer exists from the script in this release. See:https://github.com/unfmontreal/Dcm2Bids/blob/m aster/README.md#defaceTpl Documentation at https://github.com/unfmontreal/Dcm2Bids Voil\u00e0, you are ready to use dcm2bids or at least move onto the tutorial !! Go to the Tutorial section Go to the How-to section Containers \u2693\ufe0e We also provide a container image that includes both dcm2niix and dcm2bids which you can install using Docker or Apptainer/Singularity . Docker docker pull unfmontreal/dcm2bids:latest Apptainer/Singularity singularity pull dcm2bids_latest.sif docker://unfmontreal/dcm2bids:latest Summary of the steps \u2693\ufe0e In sum, installing dcm2bids is quite easy if you know how to install Python packages. The easiest way to install it is to follow the steps below using conda but it is also possible to use other software, including containers: Create an environment.yml file with dependencies Content: 1 2 3 4 5 6 7 name: dcm2bids channels: - conda-forge dependencies: - python>=3.7 - dcm2niix - dcm2bids Create conda environment conda env create --file environment.yml Activate conda environment conda activate dcm2bids Verify a dcm2bids command dcm2bids --help Consult how-to guides or follow the tutorial To get out of a conda environment, you have to deactivate it with the conda deactivate command. \u21a9","title":"Installation"},{"location":"docs/get-started/install/#installation","text":"Before you can use dcm2bids, you will need to get it installed. This page guides you through a minimal, typical dcm2bids installation workflow that is sufficient to complete all dcm2bids tasks. We recommend to skim-read the full page before you start installing anything considering there are many ways to install software in the Python ecosystem which are often dependent on the familiarity and preference of the user. We offer recommendations at the bottom of the page that will take care of the whole installation process in one go and make use of a dedicated environment for dcm2bids. You just want the installation command? If you are used to installing packages, you can get it from PyPI or conda: pip install dcm2bids conda install -c conda-forge dcm2bids","title":"Installation"},{"location":"docs/get-started/install/#dependencies","text":"","title":"Dependencies"},{"location":"docs/get-started/install/#python","text":"As dcm2bids is a Python package, the first prerequisite is that Python must be installed on the machine you will use dcm2bids. You will need Python 3.7 or above to run dcm2bids properly. If you are unsure what version(s) of Python is available on your machine, you can find out by opening a terminal and typing python --version or python . The former will output the version directly in the terminal while the latter will open an interactive Python shell with the version displayed in the first line. python --version 1 2 sam:~$ python --version Python 3 .10.4 python 1 2 3 4 sam:~$ python Python 3 .10.4 | packaged by conda-forge | ( main, Mar 24 2022 , 17 :39:04 ) [ GCC 10 .3.0 ] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>> exit () If your system-wide version of Python is lower 3.7, it is okay. We will make sure to use a higher version in the isolated environment that will be created for dcm2bids. The important part is to verify that Python is installed. If you are a beginning user in the Python ecosystem, the odds are that you have installed Anaconda , which contains all Python versions so you should be good. If you were not able to find out which version of Python is installed on your machine or find Anaconda on your machine, we recommend that you install Python through Anaconda . Should I install Anaconda or Miniconda? If you unsure what to install read this section describing the differences between Anaconda and Miniconda to help you choose.","title":"Python"},{"location":"docs/get-started/install/#dcm2niix","text":"dcm2niix can also be installed in a variety of ways as seen on the main page of the software . Whether you want to install the latest compiled executable directly on your machine is up to you but you have to make sure you can call the software from any directory . In other words, you have to make sure it is included in your $PATH . Otherwise, dcm2bids won't be able to run dcm2niix for you. That's why we recommend to install it at the same time in the dedicated environment. As you can see, dcm2niix is available through conda so that is the approach chosen in this guide. We will benefit from the simplicity of installing all software from the same located at. Steps to install dcm2niix are included in the next secton.","title":"dcm2niix"},{"location":"docs/get-started/install/#recommendations","text":"We recommend to install all the dependencies at once when installing dcm2bids on a machine or server. As mentioned above the minimal installation requires only dcm2bids, dcm2niix and Python >= 3.7. For ease of use and to make sure we have a reproducible environment, we recommend to use a dedicated environment through conda or, for those who have it installed, Anaconda . Note that you don't need to use specifically them to use dcm2bids, but it will make your life easier. More info on conda Conda is an open-source package management system and environment management system that runs on Windows, macOS, and Linux. Conda quickly installs, runs, and updates packages and their dependencies. Conda easily creates, saves, loads, and switches between environments on your local computer. The conda package and environment manager is included in all versions of Anaconda and Miniconda. - conda docs But I use another package/env management system, what do I do? Of course you can use your preferred package/env management system, whether it is venv, virtualenv, pyenv, pip, poetry, etc. This guide was built on the basis that no previous knowledge is required to install and learn dcm2bids by so providing a simple way to install dcm2bids without having to worry about the rest. I already created an environment for my project, what do I do? You can update your environment either by: installing dcm2bids while your environment is active like any package; or adding dcm2bids to the dependencies and updating your environment Here's an example with conda after updating an environment.yml file: 1 conda env update --file environment.yml --prune","title":"Recommendations"},{"location":"docs/get-started/install/#install-dcm2bids","text":"From now on, it is assumed that conda (or Anaconda ) is installed and correctly setup on your computer as it is the easiest way to install dcm2bids and its dependencies on any OS. We assume that if you want to install it in a different way, you have enough skills to do it on your own. If you installed Anaconda and want to use the graphical user interface (GUI), you can follow the steps as demonstrated below and only read the steps until the end of the installation guide. Create your environment with the Anaconda Navigator GUI Open Anaconda Navigator Click on Environments, then the + button at the bottom Enter the name of the environment, it can be anything. You can call it dcm2bids then select Python Click on the new dcm2bids environment, then on Channels If you only see defaults, click on Add... then enter conda-forge then click on Update channels You now need to add the two main software, so you need to search for them in the top right corner. You should see them appear as soon as you right dcm2 . You can select both at the same time. If you don't seem them, you probabble need to select All channels instead of Installed . It will ask you to install a bunch of packages, Apply . You environment should now be ready, click on the green circle with the white arrow to start the environment. A terminal window should open. You should see the name of your environment (dcm2bids) to the left. You can now test that dcm2bids works. We could install all the software one by one using a series of command: 1 2 conda install -c conda-forge dcm2bids conda install -c conda-forge dcm2niix But this would install the software in the main environment instead of a dedicated one, assuming none were active. This could have atrocious dependencies issues in the long-term if you want to install other software.","title":"Install dcm2bids"},{"location":"docs/get-started/install/#create-environmentyml","text":"That is exactly why dedicated environments were invented. To help creating dedicated environments, we can create a file, often called environment.yml , which is used to specify things such as the dependencies that need to be installed inside the environment. To create such a file, you can use any code editor or your terminal to write or paste the information below, and save it in your project directory with the name environment.yml : You can create a project directory anywhere on your computer, it does not matter. You can create dcm2bids-proj if you need inspiration. 1 2 3 4 5 6 7 name : dcm2bids channels : - conda-forge dependencies : - python>=3.7 - dcm2niix - dcm2bids In short, here's what the fields mean: The name: key refers to the name of the dedicated environment. You will have to use this name to activate your environment and use software installed inside. The name is arbitrary, you can name it however you want. The channels: key tells conda where to look for the declared dependencies. In our case, all our dependencies are located on the conda-forge channel . The dependencies: key lists all the dependencies to be installed inside the environment. If you are creating an environment for your analysis project, this is where you would list other dependencies such as nilearn , pandas , and especially as pip since you don't want to use the pip outside of your environment Note that we specify python>=3.7 to make sure the requirement is satisfied for dcm2bids as the newer version of dcm2bids may face issue with Python 3.6 and below. Now that all the dependencies have been specified, it is time to create the new conda environment dedicated to dcm2bids!","title":"Create environment.yml"},{"location":"docs/get-started/install/#create-conda-environment-install-dcm2bids","text":"Open a terminal and go in the directory where you put the environment.yml run this command: 1 conda env create --file environment.yml If the executation was successful, you should see a message similar to: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 sam:~/dcm2bids-proj$ nano environment.yml sam:~/dcm2bids-proj$ conda env create --file environment.yml Collecting package metadata ( repodata.json ) : done Solving environment: | done Downloading and Extracting Packages future-0.18.2 | 738 KB | ########################################## | 100% Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate dcm2bids # # To deactivate an active environment, use # # $ conda deactivate","title":"Create conda environment + install dcm2bids"},{"location":"docs/get-started/install/#activate-environment","text":"Last step is to make sure you can activate 1 your environment by running the command: 1 conda activate dcm2bids Remember that dcm2bids here refer to the name given specified in the environment.yml . 1 2 sam:~/dcm2bids-proj$ conda activate dcm2bids ( dcm2bids ) sam:~/dcm2bids-proj$ You can see the environment is activated as a new (dcm2bids) appear in front of the username.","title":"Activate environment"},{"location":"docs/get-started/install/#verify-that-dcm2bids-works","text":"Finally, you can test that dcm2bids was installed correctly by running the any dcm2bids command such as dcm2bids --help : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ( dcm2bids ) sam:~/dcm2bids-proj$ dcm2bids --help usage: dcm2bids [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] -p PARTICIPANT [ -s SESSION ] -c CONFIG [ -o OUTPUT_DIR ] [ --forceDcm2niix ] [ --clobber ] [ -l { DEBUG,INFO,WARNING,ERROR,CRITICAL }] [ -a ] Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure dcm2bids 3 .0.0 options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM directory ( ies ) -p PARTICIPANT, --participant PARTICIPANT Participant ID -s SESSION, --session SESSION Session ID -c CONFIG, --config CONFIG JSON configuration file ( see example/config.json ) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory ( /home/sam/dcm2bids-proj ) --bids_validate If set, once your conversion is done it will check if your output folder is BIDS valid. [ False ] bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator#quickstart --forceDcm2niix Overwrite previous temporary dcm2niix output if it exists --clobber Overwrite output if it exists -l { DEBUG,INFO,WARNING,ERROR,CRITICAL } , --log_level { DEBUG,INFO,WARNING,ERROR,CRITICAL } Set logging level -a, --anonymizer This option no longer exists from the script in this release. See:https://github.com/unfmontreal/Dcm2Bids/blob/m aster/README.md#defaceTpl Documentation at https://github.com/unfmontreal/Dcm2Bids Voil\u00e0, you are ready to use dcm2bids or at least move onto the tutorial !! Go to the Tutorial section Go to the How-to section","title":"Verify that dcm2bids works"},{"location":"docs/get-started/install/#containers","text":"We also provide a container image that includes both dcm2niix and dcm2bids which you can install using Docker or Apptainer/Singularity . Docker docker pull unfmontreal/dcm2bids:latest Apptainer/Singularity singularity pull dcm2bids_latest.sif docker://unfmontreal/dcm2bids:latest","title":"Containers"},{"location":"docs/get-started/install/#summary-of-the-steps","text":"In sum, installing dcm2bids is quite easy if you know how to install Python packages. The easiest way to install it is to follow the steps below using conda but it is also possible to use other software, including containers: Create an environment.yml file with dependencies Content: 1 2 3 4 5 6 7 name: dcm2bids channels: - conda-forge dependencies: - python>=3.7 - dcm2niix - dcm2bids Create conda environment conda env create --file environment.yml Activate conda environment conda activate dcm2bids Verify a dcm2bids command dcm2bids --help Consult how-to guides or follow the tutorial To get out of a conda environment, you have to deactivate it with the conda deactivate command. \u21a9","title":"Summary of the steps"},{"location":"docs/how-to/","text":"How-to guides \u2693\ufe0e Help \u2693\ufe0e Get help and support Usage \u2693\ufe0e Use main commands Create a config file Use advanced commands Development and Community \u2693\ufe0e Contribute to dcm2bids","title":"index"},{"location":"docs/how-to/#how-to-guides","text":"","title":"How-to guides"},{"location":"docs/how-to/#help","text":"Get help and support","title":"Help"},{"location":"docs/how-to/#usage","text":"Use main commands Create a config file Use advanced commands","title":"Usage"},{"location":"docs/how-to/#development-and-community","text":"Contribute to dcm2bids","title":"Development and Community"},{"location":"docs/how-to/create-config-file/","text":"How to create a configuration file \u2693\ufe0e Configuration file example \u2693\ufe0e 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 { \"descriptions\" : [ { \"dataType\" : \"anat\" , \"modalityLabel\" : \"T2w\" , \"criteria\" : { \"SeriesDescription\" : \"*T2*\" , \"EchoTime\" : 0.1 }, \"sidecarChanges\" : { \"ProtocolName\" : \"T2\" } }, { \"id\" : \"task-rest\" , \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"ProtocolName\" : \"func_task-*\" , \"ImageType\" : [ \"ORIG*\" , \"PRIMARY\" , \"M\" , \"MB\" , \"ND\" , \"MOSAIC\" ] } }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"fmap\" , \"intendedFor\" : \"task_rest\" , \"criteria\" : { \"ProtocolName\" : \"*field_mapping*\" } }, { \"id\" : \"id_task_learning\" , \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-learning\" , \"criteria\" : { \"SeriesDescription\" : \"bold_task-learning\" }, \"sidecarChanges\" : { \"TaskName\" : \"learning\" } }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"epi\" , \"criteria\" : { \"SeriesDescription\" : \"fmap_task-learning\" }, \"IntendedFor\" : \"id_task_learning\" , \"sidecarChanges\" : { \"TaskName\" : \"learning\" } } ] } The descriptions field is a list of descriptions, each describing some acquisition. In this example, the configuration describes five acquisitions, a T2-weighted, a resting-state fMRI, a fieldmap, and an fMRI learning task with another fieldmap. Each description tells dcm2bids how to group a set of acquisitions and how to label them. In this config file, Dcm2Bids is being told to collect files containing 1 2 3 4 { \"SeriesDescription\" : \"AXIAL_T2_SPACE\" , \"EchoTime\" : 0.1 } in their sidecars 1 and label them as anat , T2w type images. criteria \u2693\ufe0e dcm2bids will try to match the sidecars 1 of dcm2niix to the descriptions of the configuration file. The values you enter inside the criteria dictionary are patterns that will be compared to the corresponding key of the sidecar. The pattern matching is shell-style. It's possible to use wildcard * , single character ? etc ... Please have a look at the GNU documentation to know more. For example, in the second description, the pattern *T2* will be compared to the value of SeriesDescription of a sidecar. AXIAL_T2_SPACE will be a match, AXIAL_T1 won't. dcm2bids has a SidecarFilename key, as in the first description, if you prefer to also match with the filename of the sidecar. Note that filename are subject to change depending on the dcm2niix version in use. You can enter several criteria. All criteria must match for a description to be linked to a sidecar. dataType \u2693\ufe0e It is a mandatory field. Here is a definition from bids v1.2.0 : Data type - a functional group of different types of data. In BIDS we define six data types: func (task based and resting state functional MRI), dwi (diffusion weighted imaging), fmap (field inhomogeneity mapping data such as field maps), anat (structural imaging such as T1, T2, etc.), meg (magnetoencephalography), beh (behavioral). modalityLabel \u2693\ufe0e It is a mandatory field. It describes the modality of the acquisition like T1w , T2w or dwi , bold . customLabels \u2693\ufe0e It is an optional field. For some acquisitions, you need to add information in the file name. For resting state fMRI, it is usually task-rest . To know more on how to set these fields, read the BIDS specifications . For a longer example of a Dcm2Bids config json, see here . Note that the different bids labels must come in a very specific order to be bids valid filenames. If the customLabels fields that are entered that are in the wrong order, then dcm2bids will reorder them for you. For example if you entered: 1 \"customLabels\" : \"run-01_task-rest\" when running dcm2bids, you will get the following warning: 1 2 3 WARNING:dcm2bids.structure:\u2705 Filename was reordered according to BIDS entity table order: from: sub-ID01_run-01_task-rest_bold to: sub-ID01_task-rest_run-01_bold sidecarChanges \u2693\ufe0e Optional field to change or add information in a sidecar. id and intendedFor \u2693\ufe0e Optional field to add an IntendedFor entry in the sidecar of a fieldmap. You will need to set an id to the corresponding description and put the same id in the IntendedFor field. Fo example, task_rest means it is intended for task-rest_bold and id_task_learning is intended for task-learning which will be renamed to only learning because of the \"sidecarChanges\": { \"TaskName\": \"learning\" } field. Multiple config files \u2693\ufe0e It is possible to create multiple config files and iterate the dcm2bids command over the different config files to structure data that have different parameters in their sidecar files. For each acquisition, dcm2niix creates an associated .json file, containing information from the dicom header. These are known as sidecars . These are the sidecars that dcm2bids uses to filter the groups of acquisitions. To define the filters you need, you will probably have to review these sidecars. You can generate all the sidecars for an individual participant using the dcm2bids_helper command. \u21a9 \u21a9","title":"Create a config file"},{"location":"docs/how-to/create-config-file/#how-to-create-a-configuration-file","text":"","title":"How to create a configuration file"},{"location":"docs/how-to/create-config-file/#configuration-file-example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 { \"descriptions\" : [ { \"dataType\" : \"anat\" , \"modalityLabel\" : \"T2w\" , \"criteria\" : { \"SeriesDescription\" : \"*T2*\" , \"EchoTime\" : 0.1 }, \"sidecarChanges\" : { \"ProtocolName\" : \"T2\" } }, { \"id\" : \"task-rest\" , \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"ProtocolName\" : \"func_task-*\" , \"ImageType\" : [ \"ORIG*\" , \"PRIMARY\" , \"M\" , \"MB\" , \"ND\" , \"MOSAIC\" ] } }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"fmap\" , \"intendedFor\" : \"task_rest\" , \"criteria\" : { \"ProtocolName\" : \"*field_mapping*\" } }, { \"id\" : \"id_task_learning\" , \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-learning\" , \"criteria\" : { \"SeriesDescription\" : \"bold_task-learning\" }, \"sidecarChanges\" : { \"TaskName\" : \"learning\" } }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"epi\" , \"criteria\" : { \"SeriesDescription\" : \"fmap_task-learning\" }, \"IntendedFor\" : \"id_task_learning\" , \"sidecarChanges\" : { \"TaskName\" : \"learning\" } } ] } The descriptions field is a list of descriptions, each describing some acquisition. In this example, the configuration describes five acquisitions, a T2-weighted, a resting-state fMRI, a fieldmap, and an fMRI learning task with another fieldmap. Each description tells dcm2bids how to group a set of acquisitions and how to label them. In this config file, Dcm2Bids is being told to collect files containing 1 2 3 4 { \"SeriesDescription\" : \"AXIAL_T2_SPACE\" , \"EchoTime\" : 0.1 } in their sidecars 1 and label them as anat , T2w type images.","title":"Configuration file example"},{"location":"docs/how-to/create-config-file/#criteria","text":"dcm2bids will try to match the sidecars 1 of dcm2niix to the descriptions of the configuration file. The values you enter inside the criteria dictionary are patterns that will be compared to the corresponding key of the sidecar. The pattern matching is shell-style. It's possible to use wildcard * , single character ? etc ... Please have a look at the GNU documentation to know more. For example, in the second description, the pattern *T2* will be compared to the value of SeriesDescription of a sidecar. AXIAL_T2_SPACE will be a match, AXIAL_T1 won't. dcm2bids has a SidecarFilename key, as in the first description, if you prefer to also match with the filename of the sidecar. Note that filename are subject to change depending on the dcm2niix version in use. You can enter several criteria. All criteria must match for a description to be linked to a sidecar.","title":"criteria"},{"location":"docs/how-to/create-config-file/#datatype","text":"It is a mandatory field. Here is a definition from bids v1.2.0 : Data type - a functional group of different types of data. In BIDS we define six data types: func (task based and resting state functional MRI), dwi (diffusion weighted imaging), fmap (field inhomogeneity mapping data such as field maps), anat (structural imaging such as T1, T2, etc.), meg (magnetoencephalography), beh (behavioral).","title":"dataType"},{"location":"docs/how-to/create-config-file/#modalitylabel","text":"It is a mandatory field. It describes the modality of the acquisition like T1w , T2w or dwi , bold .","title":"modalityLabel"},{"location":"docs/how-to/create-config-file/#customlabels","text":"It is an optional field. For some acquisitions, you need to add information in the file name. For resting state fMRI, it is usually task-rest . To know more on how to set these fields, read the BIDS specifications . For a longer example of a Dcm2Bids config json, see here . Note that the different bids labels must come in a very specific order to be bids valid filenames. If the customLabels fields that are entered that are in the wrong order, then dcm2bids will reorder them for you. For example if you entered: 1 \"customLabels\" : \"run-01_task-rest\" when running dcm2bids, you will get the following warning: 1 2 3 WARNING:dcm2bids.structure:\u2705 Filename was reordered according to BIDS entity table order: from: sub-ID01_run-01_task-rest_bold to: sub-ID01_task-rest_run-01_bold","title":"customLabels"},{"location":"docs/how-to/create-config-file/#sidecarchanges","text":"Optional field to change or add information in a sidecar.","title":"sidecarChanges"},{"location":"docs/how-to/create-config-file/#id-and-intendedfor","text":"Optional field to add an IntendedFor entry in the sidecar of a fieldmap. You will need to set an id to the corresponding description and put the same id in the IntendedFor field. Fo example, task_rest means it is intended for task-rest_bold and id_task_learning is intended for task-learning which will be renamed to only learning because of the \"sidecarChanges\": { \"TaskName\": \"learning\" } field.","title":"id and intendedFor"},{"location":"docs/how-to/create-config-file/#multiple-config-files","text":"It is possible to create multiple config files and iterate the dcm2bids command over the different config files to structure data that have different parameters in their sidecar files. For each acquisition, dcm2niix creates an associated .json file, containing information from the dicom header. These are known as sidecars . These are the sidecars that dcm2bids uses to filter the groups of acquisitions. To define the filters you need, you will probably have to review these sidecars. You can generate all the sidecars for an individual participant using the dcm2bids_helper command. \u21a9 \u21a9","title":"Multiple config files"},{"location":"docs/how-to/get-help/","text":"How to get help and support \u2693\ufe0e We work hard to make sure dcm2bids is robust and we welcome comments and questions to make sure it meets your use case! While the dcm2bids volunteers and the neuroimaging community at large do their best to respond to help requests about dcm2bids, there are steps you can do to try to find answers and ways to optimize how to ask questions on the different channels. The path may be different according to your situation whether you want to ask a usage question or report a bug. Where to look for answers \u2693\ufe0e Before looking for answers on any Web search engine, the best places to look for answers are: 1. This documentation \u2693\ufe0e You can use the built-in search function with key words or look throughout the documentation. If you end up finding your answer somewhere else, please inform us by opening an issue . If you faced an undocumented challenge while using dcm2bids, it is very likely others will face it as well. By gathering community knowledge, the documentation will improve drastically. Refer to the Request a new feature section below if you are unfamiliar with GitHub and issues. 2. Community support channels \u2693\ufe0e There is a couple of places you can look for NeuroStars \u2693\ufe0e What is neurostars.org ? NeuroStars is a question and answer forum for neuroscience researchers, infrastructure providers and software developers, and free to access. It is managed by the [International Neuroinformatics Coordinating Facility (INCF)][incf] and it is widely used by the neuroimaging community. NeuroStars is a gold mine of information about how others solved their problems or got answered to their questions regarding anything neuroscience, especially neuroimaging. NeuroStars is a good place to ask questions related to dcm2bids and the BIDS standards. Before asking your own questions, you may want to first browse through questions that were tagged with the dcm2bids tag . To look for everything related to a specific tag, here's how you can do it for the dcm2bids tag: The quick way Type in your URL bar https://neurostars.org/tag/dcm2bids or click directly on it to bring the page will all post tagged with a dcm2bids tag. Then if you click on search, the dcm2bids will already be selected for you. Go to https://neurostars.org . Click on the search ( ) icon. Either click on options to bring the advanced search and go to next step OR start typing dcm2bids . In the tag section on the right pane, select dcm2bids . Type your question in the search bar. You might have to refine your question a couple of times to find the most relevant answers. Steps in pictures The next step before going on a search engine is to go where we develop dcm2bids, namely GitHub. GitHub \u2693\ufe0e While we use GitHub to develop dcm2bids, some people have opened issues that could be relevant to your situation. You can browse through the open and closed issues: https://github.com/UNFmontreal/Dcm2Bids/issues?q=is%3Aissue and search for specific keywords or error messages. If you find a specific issue and would like more details about it, you can simply write an additional comment in the Leave a comment section and press Comment . Example in picture Where to ask for questions, report a bug or request a feature \u2693\ufe0e After having read thoroughly all information you could find online about your question or issue, you may still some lingering questions or even more questions - that is okay! After all, maybe you would like to use dcm2bids for a specific use-case that has never been mentioned anywhere before. Below are described 3 ways to request help depending on your situation: Ask a question about dcm2bids Report a bug Request a new feature Questions related to using dcm2bids: \u2693\ufe0e We encourage you to post your question on NeuroStars with dcm2bids as an optional tag. The tag is really important because NeuroStars will notify the dcm2bids team only if the tag is present. You will get a quicker reply this way. Report a bug \u2693\ufe0e If you think you've found a bug , and you could not find an issue already mentioning the problem, please open an issue on our repository . If you don't know how to open an issue, refer to the open an issue section below. Request a new feature \u2693\ufe0e If you have more an inquiry or suggestion to make than a bug to report, we encourage you to start a conversation in the Discussions section . Similar to the bug reporting procedure, follow the open an issue below. Open an issue \u2693\ufe0e To open or comment on an issue, you will need a GitHub account. Issues are individual pieces of work (a bug to fix or a feature) that need to be completed to move the project forwards. We highly recommend you open an issue to explain what you want to do and how it echoes a specific demand from the community. Keep in mind the scope of the dcm2bids project. A general guideline: if you find yourself tempted to write a great big issue that is difficult to describe as one unit of work, please consider splitting it into two or more. Moreover, it will be interesting to see how others approach your issue and give their opinion and advice to solve it. If you have more an inquiry or suggestion to make than a bug to report, we encourage you to start a conversation in the Discussions section . Note that issues may be converted to a discussion if deemed relevant by the maintainers.","title":"Get help and support"},{"location":"docs/how-to/get-help/#how-to-get-help-and-support","text":"We work hard to make sure dcm2bids is robust and we welcome comments and questions to make sure it meets your use case! While the dcm2bids volunteers and the neuroimaging community at large do their best to respond to help requests about dcm2bids, there are steps you can do to try to find answers and ways to optimize how to ask questions on the different channels. The path may be different according to your situation whether you want to ask a usage question or report a bug.","title":"How to get help and support"},{"location":"docs/how-to/get-help/#where-to-look-for-answers","text":"Before looking for answers on any Web search engine, the best places to look for answers are:","title":"Where to look for answers"},{"location":"docs/how-to/get-help/#1-this-documentation","text":"You can use the built-in search function with key words or look throughout the documentation. If you end up finding your answer somewhere else, please inform us by opening an issue . If you faced an undocumented challenge while using dcm2bids, it is very likely others will face it as well. By gathering community knowledge, the documentation will improve drastically. Refer to the Request a new feature section below if you are unfamiliar with GitHub and issues.","title":"1. This documentation"},{"location":"docs/how-to/get-help/#2-community-support-channels","text":"There is a couple of places you can look for","title":"2. Community support channels"},{"location":"docs/how-to/get-help/#neurostars","text":"What is neurostars.org ? NeuroStars is a question and answer forum for neuroscience researchers, infrastructure providers and software developers, and free to access. It is managed by the [International Neuroinformatics Coordinating Facility (INCF)][incf] and it is widely used by the neuroimaging community. NeuroStars is a gold mine of information about how others solved their problems or got answered to their questions regarding anything neuroscience, especially neuroimaging. NeuroStars is a good place to ask questions related to dcm2bids and the BIDS standards. Before asking your own questions, you may want to first browse through questions that were tagged with the dcm2bids tag . To look for everything related to a specific tag, here's how you can do it for the dcm2bids tag: The quick way Type in your URL bar https://neurostars.org/tag/dcm2bids or click directly on it to bring the page will all post tagged with a dcm2bids tag. Then if you click on search, the dcm2bids will already be selected for you. Go to https://neurostars.org . Click on the search ( ) icon. Either click on options to bring the advanced search and go to next step OR start typing dcm2bids . In the tag section on the right pane, select dcm2bids . Type your question in the search bar. You might have to refine your question a couple of times to find the most relevant answers. Steps in pictures The next step before going on a search engine is to go where we develop dcm2bids, namely GitHub.","title":"NeuroStars"},{"location":"docs/how-to/get-help/#github","text":"While we use GitHub to develop dcm2bids, some people have opened issues that could be relevant to your situation. You can browse through the open and closed issues: https://github.com/UNFmontreal/Dcm2Bids/issues?q=is%3Aissue and search for specific keywords or error messages. If you find a specific issue and would like more details about it, you can simply write an additional comment in the Leave a comment section and press Comment . Example in picture","title":"GitHub"},{"location":"docs/how-to/get-help/#where-to-ask-for-questions-report-a-bug-or-request-a-feature","text":"After having read thoroughly all information you could find online about your question or issue, you may still some lingering questions or even more questions - that is okay! After all, maybe you would like to use dcm2bids for a specific use-case that has never been mentioned anywhere before. Below are described 3 ways to request help depending on your situation: Ask a question about dcm2bids Report a bug Request a new feature","title":"Where to ask for questions, report a bug or request a feature"},{"location":"docs/how-to/get-help/#questions-related-to-using-dcm2bids","text":"We encourage you to post your question on NeuroStars with dcm2bids as an optional tag. The tag is really important because NeuroStars will notify the dcm2bids team only if the tag is present. You will get a quicker reply this way.","title":"Questions related to using dcm2bids:"},{"location":"docs/how-to/get-help/#report-a-bug","text":"If you think you've found a bug , and you could not find an issue already mentioning the problem, please open an issue on our repository . If you don't know how to open an issue, refer to the open an issue section below.","title":"Report a bug"},{"location":"docs/how-to/get-help/#request-a-new-feature","text":"If you have more an inquiry or suggestion to make than a bug to report, we encourage you to start a conversation in the Discussions section . Similar to the bug reporting procedure, follow the open an issue below.","title":"Request a new feature"},{"location":"docs/how-to/get-help/#open-an-issue","text":"To open or comment on an issue, you will need a GitHub account. Issues are individual pieces of work (a bug to fix or a feature) that need to be completed to move the project forwards. We highly recommend you open an issue to explain what you want to do and how it echoes a specific demand from the community. Keep in mind the scope of the dcm2bids project. A general guideline: if you find yourself tempted to write a great big issue that is difficult to describe as one unit of work, please consider splitting it into two or more. Moreover, it will be interesting to see how others approach your issue and give their opinion and advice to solve it. If you have more an inquiry or suggestion to make than a bug to report, we encourage you to start a conversation in the Discussions section . Note that issues may be converted to a discussion if deemed relevant by the maintainers.","title":"Open an issue"},{"location":"docs/how-to/use-advanced-commands/","text":"How to use advanced commands and configuration \u2693\ufe0e These optional configurations could be insert in the configuration file at the same level as the \"descriptions\" entry. 1 2 3 4 5 6 7 8 { \"searchMethod\": \"fnmatch\", \"caseSensitive\": true, \"defaceTpl\": [\"pydeface\", \"--outfile\", \"dstFile\", \"srcFile\"], \"description\": [ ... ] } searchMethod \u2693\ufe0e default: \"searchMethod\": \"fnmatch\" fnmatch is the behaviour (See criteria) by default and the fall back if this option is set incorrectly. re is the other choice if you want more flexibility to match criteria. caseSensitive \u2693\ufe0e default: \"caseSensitive\": \"true\" If false, comparisons between strings/lists will be not case sensitive. It's only disabled when used with \"searchMethod\": \"fnmatch\" . defaceTpl \u2693\ufe0e default: \"defaceTpl\": None !!! danger The anonymizer option no longer exists from v2.0.0 . It is still possible to deface the anatomical nifti images. For example, if you use the last version of pydeface, add: \"defaceTpl\": \"pydeface --outfile {dstFile} {srcFile}\" It is a template string and dcm2bids will replace {srcFile} and {dstFile} by the source file (input) and the destination file (output). dcm2niixOptions \u2693\ufe0e default: \"dcm2niixOptions\": \"-b y -ba y -z y -f '%3s_%f_%p_%t'\" Arguments for dcm2niix compKeys \u2693\ufe0e default: \"compKeys\": [\"SeriesNumber\", \"AcquisitionTime\", \"SidecarFilename\"] Acquisitions are sorted using the sidecar data. The default behaviour is to sort by SeriesNumber then by AcquisitionTime then by the SidecarFilename . You can change this behaviour setting this key inside the configuration file.","title":"Use advanced commands"},{"location":"docs/how-to/use-advanced-commands/#how-to-use-advanced-commands-and-configuration","text":"These optional configurations could be insert in the configuration file at the same level as the \"descriptions\" entry. 1 2 3 4 5 6 7 8 { \"searchMethod\": \"fnmatch\", \"caseSensitive\": true, \"defaceTpl\": [\"pydeface\", \"--outfile\", \"dstFile\", \"srcFile\"], \"description\": [ ... ] }","title":"How to use advanced commands and configuration"},{"location":"docs/how-to/use-advanced-commands/#searchmethod","text":"default: \"searchMethod\": \"fnmatch\" fnmatch is the behaviour (See criteria) by default and the fall back if this option is set incorrectly. re is the other choice if you want more flexibility to match criteria.","title":"searchMethod"},{"location":"docs/how-to/use-advanced-commands/#casesensitive","text":"default: \"caseSensitive\": \"true\" If false, comparisons between strings/lists will be not case sensitive. It's only disabled when used with \"searchMethod\": \"fnmatch\" .","title":"caseSensitive"},{"location":"docs/how-to/use-advanced-commands/#defacetpl","text":"default: \"defaceTpl\": None !!! danger The anonymizer option no longer exists from v2.0.0 . It is still possible to deface the anatomical nifti images. For example, if you use the last version of pydeface, add: \"defaceTpl\": \"pydeface --outfile {dstFile} {srcFile}\" It is a template string and dcm2bids will replace {srcFile} and {dstFile} by the source file (input) and the destination file (output).","title":"defaceTpl"},{"location":"docs/how-to/use-advanced-commands/#dcm2niixoptions","text":"default: \"dcm2niixOptions\": \"-b y -ba y -z y -f '%3s_%f_%p_%t'\" Arguments for dcm2niix","title":"dcm2niixOptions"},{"location":"docs/how-to/use-advanced-commands/#compkeys","text":"default: \"compKeys\": [\"SeriesNumber\", \"AcquisitionTime\", \"SidecarFilename\"] Acquisitions are sorted using the sidecar data. The default behaviour is to sort by SeriesNumber then by AcquisitionTime then by the SidecarFilename . You can change this behaviour setting this key inside the configuration file.","title":"compKeys"},{"location":"docs/how-to/use-main-commands/","text":"How to use main commands \u2693\ufe0e Command Line Interface (CLI) \u2693\ufe0e How to launch dcm2bids when you have build your configuration file ? First cd in your BIDS directory. 1 dcm2bids -d DICOM_DIR -p PARTICIPANT_ID -c CONFIG_FILE If your participant have a session ID: 1 dcm2bids -d DICOM_DIR -p PARTICIPANT_ID -s SESSION_ID -c CONFIG_FILE dcm2bids creates log files inside tmp_dcm2bids/log See dcm2bids -h or dcm2bids --help to show the help message that contains more information. Important If your directory or file names have space in them, we recommend that you change all the spaces for another character ( _ or - ) but if you can't change the names, you have to wrap each argument with quotes as in the exemple below: dcm2bids -d \"DICOM DIR\" -p PARTICIPANT_ID -c \"path/with spaces to/CONFIG FILE.json\" Output \u2693\ufe0e dcm2bids creates a sub-<PARTICIPANT_ID> directory in the output directory (by default the folder where the script is launched). Sidecars with one matching description will be convert to BIDS. If a file already exists, dcm2bids won't overwrite it. You should use the --clobber option to overwrite files. If a description matches several sidecars, dcm2bids will add automatically the custom label run- to the filename. Sidecars with no or more than one matching descriptions are kept in tmp_dcm2bids directory. Users can review these mismatches to change the configuration file accordingly. Tools \u2693\ufe0e Helper 1 dcm2bids_helper -d DICOM_DIR [ -o OUTPUT_DIR ] To build the configuration file, you need to have a example of the sidecars. You can use dcm2bids_helper with the DICOMs of one participant. It will launch dcm2niix and save the result inside the tmp_dcm2bids/helper of the output directory. Scaffold 1 dcm2bids_scaffold [ -o OUTPUT_DIR ] Create basic BIDS files and directories in the output directory (by default folder where the script is launched). For each acquisition, dcm2niix creates an associated .json file, containing information from the dicom header. These are known as sidecars . These are the sidecars dcm2bids uses to filter the groups of acquisitions. To define this filtering you will probably need to review these sidecars. You can generate all the sidecars for an individual participant using dcm2bids_helper . \u21a9","title":"Use main commands"},{"location":"docs/how-to/use-main-commands/#how-to-use-main-commands","text":"","title":"How to use main commands"},{"location":"docs/how-to/use-main-commands/#command-line-interface-cli","text":"How to launch dcm2bids when you have build your configuration file ? First cd in your BIDS directory. 1 dcm2bids -d DICOM_DIR -p PARTICIPANT_ID -c CONFIG_FILE If your participant have a session ID: 1 dcm2bids -d DICOM_DIR -p PARTICIPANT_ID -s SESSION_ID -c CONFIG_FILE dcm2bids creates log files inside tmp_dcm2bids/log See dcm2bids -h or dcm2bids --help to show the help message that contains more information. Important If your directory or file names have space in them, we recommend that you change all the spaces for another character ( _ or - ) but if you can't change the names, you have to wrap each argument with quotes as in the exemple below: dcm2bids -d \"DICOM DIR\" -p PARTICIPANT_ID -c \"path/with spaces to/CONFIG FILE.json\"","title":"Command Line Interface (CLI)"},{"location":"docs/how-to/use-main-commands/#output","text":"dcm2bids creates a sub-<PARTICIPANT_ID> directory in the output directory (by default the folder where the script is launched). Sidecars with one matching description will be convert to BIDS. If a file already exists, dcm2bids won't overwrite it. You should use the --clobber option to overwrite files. If a description matches several sidecars, dcm2bids will add automatically the custom label run- to the filename. Sidecars with no or more than one matching descriptions are kept in tmp_dcm2bids directory. Users can review these mismatches to change the configuration file accordingly.","title":"Output"},{"location":"docs/how-to/use-main-commands/#tools","text":"Helper 1 dcm2bids_helper -d DICOM_DIR [ -o OUTPUT_DIR ] To build the configuration file, you need to have a example of the sidecars. You can use dcm2bids_helper with the DICOMs of one participant. It will launch dcm2niix and save the result inside the tmp_dcm2bids/helper of the output directory. Scaffold 1 dcm2bids_scaffold [ -o OUTPUT_DIR ] Create basic BIDS files and directories in the output directory (by default folder where the script is launched). For each acquisition, dcm2niix creates an associated .json file, containing information from the dicom header. These are known as sidecars . These are the sidecars dcm2bids uses to filter the groups of acquisitions. To define this filtering you will probably need to review these sidecars. You can generate all the sidecars for an individual participant using dcm2bids_helper . \u21a9","title":"Tools"},{"location":"docs/tutorial/","text":"Tutorials \u2693\ufe0e Get to know dcm2bids through tutorials that describe in depth the dcm2bids commands. First steps with dcm2bids Interested in co-developing a tutorial? Whether you are a beginning or an advanced user, your input and effort would be greatly welcome. We will help you through the process of writing a good tutorial on your use-case. Get in contact with us on GitHub","title":"index"},{"location":"docs/tutorial/#tutorials","text":"Get to know dcm2bids through tutorials that describe in depth the dcm2bids commands. First steps with dcm2bids Interested in co-developing a tutorial? Whether you are a beginning or an advanced user, your input and effort would be greatly welcome. We will help you through the process of writing a good tutorial on your use-case. Get in contact with us on GitHub","title":"Tutorials"},{"location":"docs/tutorial/first-steps/","text":"Tutorial - First steps \u2693\ufe0e How to use this tutorial \u2693\ufe0e This tutorial was developed assuming no prior knowledge of the tool, and little knowledge of the command line (terminal). It aims to be beginner-friendly by giving a lot of details. To get the most out of it, you recommend that you run the commands throughout the tutorial and compare your outputs with the outputs from the example. Every time you need to run a command, you will see two tabs, one for the command you need to run, and another one with the expected output. While you can copy the command, you recommend that you type each command, which is good for your procedural memory :brain:. The Command and Output tabs will look like these: Command 1 echo \"Hello, World!\" Output 1 2 sam:~/$ echo \"Hello, World!\" Hello, World! Note that in the Output tab, the content before the command prompt ( $ ) will be dependend or your operating system and terminal configuration. What you want to compare is what follows it and the output below the command that was ran. The output you see was taken directly out of your terminal when you tested the tutorial. Setup \u2693\ufe0e dcm2bids must be installed If you have not installed dcm2bids yet, now is the time to go to the installation page and install dcm2bids with its dependencies. This tutorial does not cover the installation part and assumes you have dcm2bids properly installed. Activate your dcm2bids environment \u2693\ufe0e If you followed the installation procedure , you have to activate your dedicated environment for dcm2bids. Note that you use dcm2bids as the name of the environment but you should use the name you gave your environment when you created it. If you used Anaconda Navigator to install dcm2bids and create you environment, make sure to open your environment from Navigator as indicated in Create your environment with the Anaconda Navigator GUI . Command 1 conda activate dcm2bids Output 1 2 conda activate dcm2bids ( dcm2bids ) sam:~$ Test your environment \u2693\ufe0e It is always good to make sure you have access to the software you want to use. You can test it with any command but a safe way is to use the --help command. Command 1 dcm2bids --help Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ( dcm2bids ) sam:~$ dcm2bids --help usage: dcm2bids [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] -p PARTICIPANT [ -s SESSION ] -c CONFIG [ -o OUTPUT_DIR ] [ --forceDcm2niix ] [ --clobber ] [ -l { DEBUG,INFO,WARNING,ERROR,CRITICAL }] [ -a ] Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure dcm2bids 3 .0.0 options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM directory ( ies ) -p PARTICIPANT, --participant PARTICIPANT Participant ID -s SESSION, --session SESSION Session ID -c CONFIG, --config CONFIG JSON configuration file ( see example/config.json ) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory ( /home/sam ) --bids_validate If set, once your conversion is done it will check if your output folder is BIDS valid. [ False ] bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator#quickstart --forceDcm2niix Overwrite previous temporary dcm2niix output if it exists --clobber Overwrite output if it exists -l { DEBUG,INFO,WARNING,ERROR,CRITICAL } , --log_level { DEBUG,INFO,WARNING,ERROR,CRITICAL } Set logging level -a, --anonymizer This option no longer exists from the script in this release. See:https://github.com/unfmontreal/Dcm2Bids/blob/m aster/README.md#defaceTpl Documentation at https://github.com/unfmontreal/Dcm2Bids What you can do if you did not get this output If you got dcm2bids: command not found , it means dcm2bids is not either not installed or not accessible in your current environment. Did you activate your environment? Visit the installation page for more info. Create a new directory for this tutorial \u2693\ufe0e For the tutorial, you recommend that you create a new directory (folder) instead of jumping straight into a real project directory with real data. In this tutorial, we decided to named our project directory dcm2bids-tutorial . Command 1 2 mkdir dcm2bids-tutorial cd dcm2bids-tutorial Output 1 2 3 4 5 ( dcm2bids ) sam:~$ mkdir dcm2bids-tutorial ( dcm2bids ) sam:~$ cd dcm2bids-tutorial/ ( dcm2bids ) sam:~/dcm2bids-tutorial$ # no output is printed by mkdir and cd if when the command is successful. # You can now see that you are inside dcm2bids-tutorial directory. Scaffolding \u2693\ufe0e While scaffolding is a not mandatory step before converting data with the main dcm2bids command, it is highly recommended when you plan to convert data. dcm2bids has a command named dcm2bids_scaffold that will help you structure and organize your data in an efficient way by creating automatically for you a basic directory structure and the core files according to the Brain Imaging Data Structure (BIDS) specification . Tree structure of the scaffold created by dcm2bids \u2693\ufe0e 1 2 3 4 5 6 7 8 9 10 11 scaffold_directory/ \u251c\u2500\u2500 CHANGES \u251c\u2500\u2500 code/ \u251c\u2500\u2500 dataset_description.json \u251c\u2500\u2500 derivatives/ \u251c\u2500\u2500 participants.json \u251c\u2500\u2500 participants.tsv \u251c\u2500\u2500 README \u2514\u2500\u2500 sourcedata/ 3 directories, 5 files Describing the function of each directory and files is out of the scope of this tutorial but if you want to learn more about BIDS, you encourage you to go through the BIDS Starter Kit . Run dcm2bids_scaffold \u2693\ufe0e To find out how to run dcm2bids_scaffold work, you can use the --help option. Command 1 dcm2bids_scaffold --help Output 1 2 3 4 5 6 7 8 9 10 11 12 ( dcm2bids ) sam:~/dcm2bids-tutorial$ dcm2bids_scaffold --help usage: dcm2bids_scaffold [ -h ] [ -o OUTPUT_DIR ] Create basic BIDS files and directories options: -h, --help show this help message and exit -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory Documentation at https://github.com/unfmontreal/Dcm2Bids As you can see at lines 9-10, dcm2bids_scaffold has an --output_dir (or -o for short) option with a default option, which means you can either specify where you want the scaffolding to happen to be or it will create the scaffold in the current directory as a default. Below you can see the difference between specifying -o output_dir and NOT specifying (using the default) the -o option. Note that you don't have to create the directory where you want to put the scaffold beforehand, the command will create it for you. Commands 1 dcm2bids_scaffold VS 1 dcm2bids_scaffold -o bids_project Output 1 2 3 4 ( dcm2bids ) sam:~/dcm2bids-tutorial$ dcm2bids_scaffold ( dcm2bids ) sam:~/dcm2bids-tutorial$ ls CHANGES dataset_description.json participants.json README code derivatives participants.tsv sourcedata VS 1 2 3 4 5 6 ( dcm2bids ) sam:~/dcm2bids-tutorial$ dcm2bids_scaffold -o bids_project ( dcm2bids ) sam:~/dcm2bids-tutorial$ ls -F bids_project/ ( dcm2bids ) sam:~/dcm2bids-tutorial$ ls -F bids_project/ CHANGES dataset_description.json participants.json README code/ derivatives/ participants.tsv sourcedata/ For the purpose of the tutorial, you chose to specify the output directory bids_project as if it were the start of a new project. For your real projects, you can choose to create a new directory with the commands or not, it is entirely up to you. Change directory to go in your scaffold \u2693\ufe0e For those who created the scaffold in another directory, you must go inside that directory. Command 1 cd bids_project Output 1 2 ( dcm2bids ) sam:~/dcm2bids-tutorial$ cd bids_project/ ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ Download neuroimaging data \u2693\ufe0e For this tutorial, you will use a set of DICOMs made available by [neurolabusc][dcm_qa_nih] on GitHub. Why use these data in particular? You use the dcm_qa_nih data because it is the data used by the dcm2niix developers to validate the DICOM to NIfTI conversion process and it has been proven stable since 2017. It also includes data from both GE as well as Siemens MRI scanners so it gives a bit a diversity of data provenance. To download the data, you can use your terminal or the GitHub interface. You can do it any way you want as long as the directory with the dicoms is in sourcedata directory with the name dcm_qa_nih . Terminal Commands Download the zipped file from https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip . 1 wget -O dcm_qa_nih-master.zip https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip Extract/unzip the zipped file into sourcedata/ . 1 unzip dcm_qa_nih-master.zip -d sourcedata/ Rename the directory dcm_qa_nih . 1 mv sourcedata/dcm_qa_nih-master sourcedata/dcm_qa_nih OR You can clone the repository if you are familiar with Git. If you did the steps above, move on. 1 git clone https://github.com/neurolabusc/dcm_qa_nih/ sourcedata/dcm_qa_nih Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ wget -O dcm_qa_nih-master.zip https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip --2022-04-18 22 :17:26-- https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip Resolving github.com ( github.com ) ... 140 .82.112.3 Connecting to github.com ( github.com ) | 140 .82.112.3 | :443... connected. HTTP request sent, awaiting response... 302 Found Location: https://codeload.github.com/neurolabusc/dcm_qa_nih/zip/refs/heads/master [ following ] --2022-04-18 22 :17:26-- https://codeload.github.com/neurolabusc/dcm_qa_nih/zip/refs/heads/master Resolving codeload.github.com ( codeload.github.com ) ... 140 .82.113.9 Connecting to codeload.github.com ( codeload.github.com ) | 140 .82.113.9 | :443... connected. HTTP request sent, awaiting response... 200 OK Length: 10258820 ( 9 .8M ) [ application/zip ] Saving to: \u2018dcm_qa_nih-master.zip\u2019 dcm_qa_nih-master.zip 100 % [====================== > ] 9 .78M 3 .24MB/s in 3 .0s 2022 -04-18 22 :17:29 ( 3 .24 MB/s ) - \u2018dcm_qa_nih-master.zip\u2019 saved [ 10258820 /10258820 ] ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ unzip dcm_qa_nih-master.zip -d sourcedata/ Archive: dcm_qa_nih-master.zip aa82e560d5471b53f0d0332c4de33d88bf179157 creating: sourcedata/dcm_qa_nih-master/ extracting: sourcedata/dcm_qa_nih-master/.gitignore creating: sourcedata/dcm_qa_nih-master/In/ creating: sourcedata/dcm_qa_nih-master/In/20180918GE/ inflating: sourcedata/dcm_qa_nih-master/In/20180918GE/README-Study.txt creating: sourcedata/dcm_qa_nih-master/In/20180918GE/mr_0004/ inflating: sourcedata/dcm_qa_nih-master/In/20180918GE/mr_0004/README-Series.txt inflating: sourcedata/dcm_qa_nih-master/In/20180918GE/mr_0004/axial_epi_fmri_interleaved_i_to_s-00001.dcm # [...] output was manually truncated because it was really really long inflating: sourcedata/dcm_qa_nih-master/Ref/EPI_PE = RL_5.nii inflating: sourcedata/dcm_qa_nih-master/batch.sh ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ mv sourcedata/dcm_qa_nih-master sourcedata/dcm_qa_nih GitHub Go to: https://github.com/neurolabusc/dcm_qa_nih and click on the green button (Code) to download ZIP . Download the zipped file. Extract/unzip the zipped file to the sourcedata directory inside your scaffold and rename the newly created directory dcm_qa_nih . You should now have a dcm_qa_nih directory nested in sourcedata with a bunch of files and directories: Command 1 ls sourcedata/dcm_qa_nih Output 1 2 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ ls sourcedata/dcm_qa_nih/ batch.sh In LICENSE README.md Ref Building the configuration file \u2693\ufe0e The configuration file is the central element for dcm2bids to organize your data into the Brain Imaging Data Structure standard. dcm2bids uses information from the config file to determine which data in the protocol will be converted, and how they will be renamed based on a set of rules. For this reason, it is important to have a little understanding of the core BIDS principles. The BIDS Starter Kit a good place to start Tutorial on Annotating a BIDS dataset from . As you will see below, the configuration file must be structured in the Javascript Object Notation (JSON) format. More info about the configuration file The How-to guide on creating a config file provides useful information about required and optional fields, and the inner working of a config file. In short you need a configuration file because, for each acquisition, dcm2niix creates an associated .json file, containing information from the dicom header. These are known as sidecar files . These are the sidecars that dcm2bids uses to filter the groups of acquisitions based on the configuration file. You have to input the filters yourself, which is way easier to define when you have access to an example of the sidecar files. You can generate all the sidecar files for an individual participant using the dcm2bids_helper command. dcm2bids_helper command \u2693\ufe0e This command will convert the DICOM files it finds to NIfTI files and save them inside a temporary directory for you to inspect and make some filters for the config file. As usual the first command will be to request the help info. Command 1 dcm2bids_helper --help Output 1 2 3 4 5 6 7 8 9 10 11 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids_helper --help usage: dcm2bids_helper [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] [ -o OUTPUT_DIR ] options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM files directory -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory Documentation at https://github.com/unfmontreal/Dcm2Bids To run the commands, you have to specify the -d option, namely the input directory containing the DICOM files. The -o option is optional, defaulting to moving the files inside a new tmp_dcm2bids/helper directory from where you run the command, the current directory. Use one participant only For this tutorial, it is easy since you there are only few data. However, in project with many participants, it is recommended to use data from one one session of one participant only by targeting their directory, otherwise you may be overwhelmed by the number of files for nothing. In this tutorial, there are two folders with data, one with data coming from a Siemens scanner ( 20180918Si ), and one with data coming from GE (20180918GE). The tutorial will use the data acquired on both scanners and Siemens scanner located in sourcedata/dcm_qa_nih/In/ and pretend it is one participant only. Command 1 dcm2bids_helper -d sourcedata/dcm_qa_nih/In/ Output 1 2 3 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids_helper -d sourcedata/dcm_qa_nih/In/ Example in : /home/sam/dcm2bids-tutorial/bids_project/tmp_dcm2bids/helper Finding what you need in tmp_dcm2bids/helper \u2693\ufe0e You should now able to see a list of compressed NIfTI files ( nii.gz ) with their respective sidecar files ( .json ). You can tell which file goes with which file based on their identical names, only with a Command 1 ls tmp_dcm2bids/helper Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ ls tmp_dcm2bids/helper/ '003_In_EPI_PE=AP_20180918121230.json' '003_In_EPI_PE=AP_20180918121230.nii.gz' 004_In_DCM2NIIX_regression_test_20180918114023.json 004_In_DCM2NIIX_regression_test_20180918114023.nii.gz '004_In_EPI_PE=PA_20180918121230.json' '004_In_EPI_PE=PA_20180918121230.nii.gz' 005_In_DCM2NIIX_regression_test_20180918114023.json 005_In_DCM2NIIX_regression_test_20180918114023.nii.gz '005_In_EPI_PE=RL_20180918121230.json' '005_In_EPI_PE=RL_20180918121230.nii.gz' 006_In_DCM2NIIX_regression_test_20180918114023.json 006_In_DCM2NIIX_regression_test_20180918114023.nii.gz '006_In_EPI_PE=LR_20180918121230.json' '006_In_EPI_PE=LR_20180918121230.nii.gz' 007_In_DCM2NIIX_regression_test_20180918114023.json 007_In_DCM2NIIX_regression_test_20180918114023.nii.gz As you can see, it is not necessarily easy to tell which scan files ( nii.gz ) refer to which acquisitions from their names only. That is why you have to go through their sidecar files to find unique identifiers for one acquisiton you want to BIDSify . Go ahead and use any code editor, file viewer or your terminal to inspect the sidecar files. Here, we compare two files that have similar names to highlight their differences: Command 1 diff --side-by-side tmp_dcm2bids/helper/ \"003_In_EPI_PE=AP_20180918121230.json\" tmp_dcm2bids/helper/ \"004_In_EPI_PE=PA_20180918121230.json\" Note than in this example, the filename are wrapped with quotes ( \" ) as in \"filename.ext\" because there is an = include in the name. You have to wrap your filenames if they contains special characters, including spaces. To avoid weird problems, we highly recommend to use alphanumeric only names when you can choose the name of your MRI protocols and sequences. Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ diff --side-by-side tmp_dcm2bids/helper/003_In_EPI_PE \\= AP_20180918121230.json tmp_dcm2bids/helper/004_In_EPI_PE \\= PA_20180918121230.json { { \"Modality\" : \"MR\" , \"Modality\" : \"MR\" , \"MagneticFieldStrength\" : 3 , \"MagneticFieldStrength\" : 3 , \"ImagingFrequency\" : 123 .204, \"ImagingFrequency\" : 123 .204, \"Manufacturer\" : \"Siemens\" , \"Manufacturer\" : \"Siemens\" , \"ManufacturersModelName\" : \"Skyra\" , \"ManufacturersModelName\" : \"Skyra\" , \"InstitutionName\" : \"NIH\" , \"InstitutionName\" : \"NIH\" , \"InstitutionalDepartmentName\" : \"FMRIF 3TD\" , \"InstitutionalDepartmentName\" : \"FMRIF 3TD\" , \"InstitutionAddress\" : \"10 Center Drive Building 10 Ro \" InstitutionAddress \": \" 10 Center Drive Building 10 Ro \"DeviceSerialNumber\" : \"45160\" , \"DeviceSerialNumber\" : \"45160\" , \"StationName\" : \"AWP45160\" , \"StationName\" : \"AWP45160\" , \"BodyPartExamined\" : \"BRAIN\" , \"BodyPartExamined\" : \"BRAIN\" , \"PatientPosition\" : \"HFS\" , \"PatientPosition\" : \"HFS\" , \"ProcedureStepDescription\" : \"FMRIF^QA\" , \"ProcedureStepDescription\" : \"FMRIF^QA\" , \"SoftwareVersions\" : \"syngo MR E11\" , \"SoftwareVersions\" : \"syngo MR E11\" , \"MRAcquisitionType\" : \"2D\" , \"MRAcquisitionType\" : \"2D\" , \"SeriesDescription\" : \"EPI PE=AP\" , | \"SeriesDescription\" : \"EPI PE=PA\" , \"ProtocolName\" : \"EPI PE=AP\" , | \"ProtocolName\" : \"EPI PE=PA\" , \"ScanningSequence\" : \"EP\" , \"ScanningSequence\" : \"EP\" , \"SequenceVariant\" : \"SK\" , \"SequenceVariant\" : \"SK\" , \"ScanOptions\" : \"FS\" , \"ScanOptions\" : \"FS\" , \"SequenceName\" : \"epfid2d1_72\" , \"SequenceName\" : \"epfid2d1_72\" , \"ImageType\" : [ \"ORIGINAL\" , \"PRIMARY\" , \"M\" , \"ND\" , \"ECHO \" ImageType \": [\" ORIGINAL \", \" PRIMARY \", \" M \", \" ND \", \" ECHO \"SeriesNumber\" : 3 , | \"SeriesNumber\" : 4 , \"AcquisitionTime\" : \"12:24:58.102500\" , | \"AcquisitionTime\" : \"12:26:54.517500\" , \"AcquisitionNumber\" : 1 , \"AcquisitionNumber\" : 1 , \"ImageComments\" : \"None\" , \"ImageComments\" : \"None\" , \"SliceThickness\" : 3 , \"SliceThickness\" : 3 , \"SpacingBetweenSlices\" : 12 , \"SpacingBetweenSlices\" : 12 , \"SAR\" : 0 .00556578, \"SAR\" : 0 .00556578, \"EchoTime\" : 0 .05, \"EchoTime\" : 0 .05, \"RepetitionTime\" : 2 .43537, \"RepetitionTime\" : 2 .43537, \"FlipAngle\" : 75 , \"FlipAngle\" : 75 , \"PartialFourier\" : 1 , \"PartialFourier\" : 1 , \"BaseResolution\" : 72 , \"BaseResolution\" : 72 , \"ShimSetting\" : [ \"ShimSetting\" : [ -3717, -3717, 15233 , 15233 , -9833, -9833, -207, -207, -312, -312, -110, -110, 150 , 150 , 226 ] , 226 ] , \"TxRefAmp\" : 316 .97, \"TxRefAmp\" : 316 .97, \"PhaseResolution\" : 1 , \"PhaseResolution\" : 1 , \"ReceiveCoilName\" : \"Head_32\" , \"ReceiveCoilName\" : \"Head_32\" , \"ReceiveCoilActiveElements\" : \"HEA;HEP\" , \"ReceiveCoilActiveElements\" : \"HEA;HEP\" , \"PulseSequenceDetails\" : \"%CustomerSeq%\\\\nih_ep2d_bold \" PulseSequenceDetails \": \" %CustomerSeq% \\\\ nih_ep2d_bold \"CoilCombinationMethod\" : \"Sum of Squares\" , \"CoilCombinationMethod\" : \"Sum of Squares\" , \"ConsistencyInfo\" : \"N4_VE11C_LATEST_20160120\" , \"ConsistencyInfo\" : \"N4_VE11C_LATEST_20160120\" , \"MatrixCoilMode\" : \"SENSE\" , \"MatrixCoilMode\" : \"SENSE\" , \"PercentPhaseFOV\" : 100 , \"PercentPhaseFOV\" : 100 , \"PercentSampling\" : 100 , \"PercentSampling\" : 100 , \"EchoTrainLength\" : 72 , \"EchoTrainLength\" : 72 , \"PhaseEncodingSteps\" : 72 , \"PhaseEncodingSteps\" : 72 , \"AcquisitionMatrixPE\" : 72 , \"AcquisitionMatrixPE\" : 72 , \"ReconMatrixPE\" : 72 , \"ReconMatrixPE\" : 72 , \"BandwidthPerPixelPhaseEncode\" : 27 .778, \"BandwidthPerPixelPhaseEncode\" : 27 .778, \"EffectiveEchoSpacing\" : 0 .000499996, \"EffectiveEchoSpacing\" : 0 .000499996, \"DerivedVendorReportedEchoSpacing\" : 0 .000499996, \"DerivedVendorReportedEchoSpacing\" : 0 .000499996, \"TotalReadoutTime\" : 0 .0354997, \"TotalReadoutTime\" : 0 .0354997, \"PixelBandwidth\" : 2315 , \"PixelBandwidth\" : 2315 , \"DwellTime\" : 3e-06, \"DwellTime\" : 3e-06, \"PhaseEncodingDirection\" : \"j-\" , | \"PhaseEncodingDirection\" : \"j\" , \"SliceTiming\" : [ \"SliceTiming\" : [ 0 , 0 , 1 .45, | 1 .4475, 0 .4825, 0 .4825, 1 .9325, | 1 .93, 0 .9675 ] , | 0 .965 ] , \"ImageOrientationPatientDICOM\" : [ \"ImageOrientationPatientDICOM\" : [ 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 0 ] , 0 ] , \"ImageOrientationText\" : \"Tra\" , \"ImageOrientationText\" : \"Tra\" , \"InPlanePhaseEncodingDirectionDICOM\" : \"COL\" , \"InPlanePhaseEncodingDirectionDICOM\" : \"COL\" , \"ConversionSoftware\" : \"dcm2niix\" , \"ConversionSoftware\" : \"dcm2niix\" , \"ConversionSoftwareVersion\" : \"v1.0.20211006\" \"ConversionSoftwareVersion\" : \"v1.0.20211006\" } } Again, when you will do it with your DICOMs, you will want to run dcm2bids_helper on a typical session of one of your participants. You will probably get more files than this example For the purpose of the tutorial, we will be interested in three specific acquisitions, namely: 004_In_DCM2NIIX_regression_test_20180918114023 003_In_EPI_PE=AP_20180918121230 004_In_EPI_PE=PA_20180918121230 The first is an resting-state fMRI acquisiton whereas the second and third are fieldmap EPI. Setting up the configuration file \u2693\ufe0e Once you found the data you want to BIDSify , you can start setting up your configuration file. The file name is arbritrary but for the readibility purpose, you can name it dcm2bids_config.json like in the tutorial. You can create in the code/ directory. Use any code editor to create the file and add the following content: 1 2 3 { \"descriptions\" : [] } Command 1 nano code/dcm2bids_config.json Output 1 2 3 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ nano code/dcm2bids_config.json ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ # No output is shown since nano is an interactive terminal-based editor Populating the config file \u2693\ufe0e To populate the config file, you need to inspect each sidecar files one at a time and make sure there is a unique match for the acquisition you target. For example, with the resting-state fMRI data ( 004_In_DCM2NIIX_regression_test_20180918114023 ). You can inspect its sidecar file and look for the \"SeriesDescription\" field for example. It is often a good unique identifier. Command 1 cat tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ cat tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json { \"Modality\" : \"MR\" , \"MagneticFieldStrength\" : 3 , \"ImagingFrequency\" : 127 .697, \"Manufacturer\" : \"GE\" , \"PulseSequenceName\" : \"epiRT\" , \"InternalPulseSequenceName\" : \"EPI\" , \"ManufacturersModelName\" : \"DISCOVERY MR750\" , \"InstitutionName\" : \"NIH FMRIF\" , \"DeviceSerialNumber\" : \"000301496MR3T6MR\" , \"StationName\" : \"fmrif3tb\" , \"BodyPartExamined\" : \"BRAIN\" , \"PatientPosition\" : \"HFS\" , \"SoftwareVersions\" : \"27\\\\LX\\\\MR Software release:DV26.0_R01_1725.a\" , \"MRAcquisitionType\" : \"2D\" , \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)\" , \"ProtocolName\" : \"DCM2NIIX regression test\" , \"ScanningSequence\" : \"EP\\\\GR\" , \"SequenceVariant\" : \"SS\" , \"ScanOptions\" : \"EPI_GEMS\\\\PFF\" , \"ImageType\" : [ \"ORIGINAL\" , \"PRIMARY\" , \"EPI\" , \"NONE\" ] , \"SeriesNumber\" : 4 , \"AcquisitionTime\" : \"11:48:15.000000\" , \"AcquisitionNumber\" : 1 , \"SliceThickness\" : 3 , \"SpacingBetweenSlices\" : 5 , \"SAR\" : 0 .0166392, \"EchoTime\" : 0 .03, \"RepetitionTime\" : 5 , \"FlipAngle\" : 60 , \"PhaseEncodingPolarityGE\" : \"Unflipped\" , \"CoilString\" : \"32Ch Head\" , \"PercentPhaseFOV\" : 100 , \"PercentSampling\" : 100 , \"AcquisitionMatrixPE\" : 64 , \"ReconMatrixPE\" : 64 , \"EffectiveEchoSpacing\" : 0 .000388, \"TotalReadoutTime\" : 0 .024444, \"PixelBandwidth\" : 7812 .5, \"PhaseEncodingDirection\" : \"j-\" , \"SliceTiming\" : [ 0 , 2 .66667, 0 .333333, 3 , 0 .666667, 3 .33333, 1 , 3 .66667, 1 .33333, 4 , 1 .66667, 4 .33333, 2 , 4 .66667, 2 .33333 ] , \"ImageOrientationPatientDICOM\" : [ 1 , -0, 0 , -0, 1 , 0 ] , \"InPlanePhaseEncodingDirectionDICOM\" : \"COL\" , \"ConversionSoftware\" : \"dcm2niix\" , \"ConversionSoftwareVersion\" : \"v1.0.20211006\" } To match the \"SeriesDescription\" field, a pattern like Axial EPI-FMRI* could match it. However, we need to make sure we will match only one acquisition. You can test it by looking manually at inside all sidecar files but it is now recommend. It is rather trivial for the computer to look in all the .json files for you with the grep command: Command 1 grep \"Axial EPI-FMRI*\" tmp_dcm2bids/helper/*.json Output 1 2 3 4 5 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"Axial EPI-FMRI*\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)\" , tmp_dcm2bids/helper/005_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Sequential I to S)\" , tmp_dcm2bids/helper/006_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved S to I)\" , tmp_dcm2bids/helper/007_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Sequential S to I)\" , Unfortunately, this criteria is not enough and it could match other 4 files. In this situation, you can add another criteria to match the specific acquisition. Which one do you think would be more appropriate? Go back to the content of the fMRI sidecar file and find a another criteria that, in combination with the \"SeriesDescription\" , will uniquely match the fMRI data. Right, maybe instead of trying to look for another field, you could simply extend the criteria for the \"SeriesDescription\" . How many files does it match if you extend it to the full value ( Axial EPI-FMRI (Interleaved I to S) ? Command 1 grep \"Axial EPI-FMRI (Interleaved I to S)*\" tmp_dcm2bids/helper/*.json Output 1 2 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"Axial EPI-FMRI (Interleaved I to S)*\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)\" , , there is only one match! It means you can now update your configuration file by adding a couple of necessary fields for which you can find a description in How to create a config file . Since it is a resting-stage fMRI acquisition, you want to specify it like this then make dcm2bids change your task name: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"descriptions\" : [ { \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)*\" }, \"sidecarChanges\" : { \"TaskName\" : \"rest\" } } ] } Command 1 nano code/dcm2bids_config.json Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ nano code/dcm2bids_config.json ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ cat code/dcm2bids_config.json { \"descriptions\" : [ { \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"SeriesDescription\" : \"*Axial EPI-FMRI (Interleaved I to S)*\" } , \"sidecarChanges\" : { \"TaskName\" : \"rest\" } } ] } Avoid using filename as criteria While you can take file names to match as criteria, we do not recommend this as different versions of dcm2niix can lead to different file names (Refer to the release notes of version 17-March-2021 (v1.0.20210317) of dcmniix to now more, especially the GE file naming behavior changes (%p protocol name and %d description) section . Moving to the two fieldmaps, if you inspect their sidecar files (the same ones that were compared in the dcm2bids_helper section ), you can see a pattern of \"EPI PE=AP\" or \"EPI PE=PA\" in the SeriesDescription once again. Is it enough to match only the correct acquisition? You can test it, of course! Command 1 2 grep \"EPI PE=AP\" tmp_dcm2bids/helper/*.json grep \"EPI PE=PA\" tmp_dcm2bids/helper/*.json Output There are two matches per pattern but they come from the same file, so it is okay. 1 2 3 4 5 6 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"EPI PE=AP\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/003_In_EPI_PE = AP_20180918121230.json: \"SeriesDescription\" : \"EPI PE=AP\" , tmp_dcm2bids/helper/003_In_EPI_PE = AP_20180918121230.json: \"ProtocolName\" : \"EPI PE=AP\" , ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"EPI PE=PA\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/004_In_EPI_PE = PA_20180918121230.json: \"SeriesDescription\" : \"EPI PE=PA\" , tmp_dcm2bids/helper/004_In_EPI_PE = PA_20180918121230.json: \"ProtocolName\" : \"EPI PE=PA\" , Once you are sure of you matching criteria, you can update your configuration file with the appropriate info. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 { \"descriptions\" : [ { \"id\" : \"id_task-rest\" , \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)*\" }, \"sidecarChanges\" : { \"TaskName\" : \"rest\" } }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"epi\" , \"customLabels\" : \"dir-AP\" , \"criteria\" : { \"SeriesDescription\" : \"EPI PE=AP*\" }, \"intendedFor\" : \"id_task-rest\" }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"epi\" , \"customLabels\" : \"dir-PA\" , \"criteria\" : { \"SeriesDescription\" : \"EPI PE=PA*\" }, \"intendedFor\" : \"id_task-rest\" } ] } For fieldmaps, you need to add an \"intendedFor\" field to show that these fieldmaps should be used with your fMRI acquisition. Have a look at the explanation of intendedFor in the documentation or in the BIDS specification . Use an online JSON validator Editing JSON file is prone to errors such as misplacing or forgetting a comma or not having matched opening and closing [] or {} . JSON linters are useful to validate that we did enter all information successfully. You can find these tools online, for example https://jsonlint.com . Now that you have a configuration file ready, it is time to finally run dcm2bids . Running dcm2bids \u2693\ufe0e By now, you should be used to getting the --help information before running a command. Command 1 dcm2bids --help Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids --help usage: dcm2bids [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] -p PARTICIPANT [ -s SESSION ] -c CONFIG [ -o OUTPUT_DIR ] [ --forceDcm2niix ] [ --clobber ] [ -l { DEBUG,INFO,WARNING,ERROR,CRITICAL }] [ -a ] Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure dcm2bids 3 .0.0 options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM directory ( ies ) -p PARTICIPANT, --participant PARTICIPANT Participant ID -s SESSION, --session SESSION Session ID -c CONFIG, --config CONFIG JSON configuration file ( see example/config.json ) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory ( /home/sam/dcm2bids-tutorial/bids_project ) --bids_validate If set, once your conversion is done it will check if your output folder is BIDS valid. [ False ] bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator#quickstart --forceDcm2niix Overwrite previous temporary dcm2niix output if it exists --clobber Overwrite output if it exists -l { DEBUG,INFO,WARNING,ERROR,CRITICAL } , --log_level { DEBUG,INFO,WARNING,ERROR,CRITICAL } Set logging level -a, --anonymizer This option no longer exists from the script in this release. See:https://github.com/unfmontreal/Dcm2Bids/blob/master/README.md#defaceTpl Documentation at https://github.com/unfmontreal/Dcm2Bids As you can see, to run the dcm2bids command, you have to specify at least 3 required options with their argument. 1 dcm2bids -d path/to/source/data -p subject_id -c path/to/config/file.json dcm2bids will create a directory which will be named after the argument specified for -p , and put the BIDSified data in it. For the tutorial, pretend that the subject_id is simply ID01 . Note that if you don't specify the -o option, your current directory will be populated with the sub-<label> directories. That being said, you can run the command: Command 1 dcm2bids -d sourcedata/dcm_qa_nih/In/ -p ID01 -c code/dcm2bids_config.json Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids -d sourcedata/dcm_qa_nih/In/ -p ID01 -c code/dcm2bids_config.json INFO:dcm2bids.dcm2bids:--- dcm2bids start --- INFO:dcm2bids.dcm2bids:OS:version: Linux-5.13.0-39-generic-x86_64-with-glibc2.31 INFO:dcm2bids.dcm2bids:python:version: 3 .10.4 | packaged by conda-forge | ( main, Mar 24 2022 , 17 :39:04 ) [ GCC 10 .3.0 ] INFO:dcm2bids.dcm2bids:dcm2bids:version: 2 .1.7 INFO:dcm2bids.dcm2bids:dcm2niix:version: v1.0.20211006 INFO:dcm2bids.dcm2bids:participant: sub-ID01 INFO:dcm2bids.dcm2bids:session: INFO:dcm2bids.dcm2bids:config: /home/sam/dcm2bids-tutorial/bids_project/code/dcm2bids_config.json INFO:dcm2bids.dcm2bids:BIDS directory: /home/sam/dcm2bids-tutorial/bids_project INFO:dcm2bids.utils:Running dcm2niix -b y -ba y -z y -f '%3s_%f_%p_%t' -o /home/sam/dcm2bids-tutorial/bids_project/tmp_dcm2bids/sub-ID01 sourcedata/dcm_qa_nih/In/ INFO:dcm2bids.dcm2niix:Check log file for dcm2niix output INFO:dcm2bids.sidecar:Sidecars pairing: INFO:dcm2bids.sidecar:_dir-AP_epi <- 003_In_EPI_PE = AP_20180918121230 INFO:dcm2bids.sidecar:_task-rest_bold <- 004_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.sidecar:_dir-PA_epi <- 004_In_EPI_PE = PA_20180918121230 INFO:dcm2bids.sidecar:No Pairing <- 005_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.sidecar:No Pairing <- 005_In_EPI_PE = RL_20180918121230 INFO:dcm2bids.sidecar:No Pairing <- 006_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.sidecar:No Pairing <- 006_In_EPI_PE = LR_20180918121230 INFO:dcm2bids.sidecar:No Pairing <- 007_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.dcm2bids:moving acquisitions into BIDS folder A bunch of information is printed to the terminal as well as to a log file located at tmp_dcm2bids/log/sub-<label>_<datetime>.log . It is useful to keep these log files in case you notice an error after a while and need to find which participants are affected. You can see that dcm2bids was able to pair and match the files you specified at lines 14-16 in the previous output tab. You can now have a look in the newly created folder sub-ID01 and discover your converted data! Command 1 tree sub-ID01/ Output 1 2 3 4 5 6 7 8 9 10 11 12 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ tree sub-ID01/ sub-ID01/ \u251c\u2500\u2500 fmap \u2502 \u251c\u2500\u2500 sub-ID01_dir-AP_epi.json \u2502 \u251c\u2500\u2500 sub-ID01_dir-AP_epi.nii.gz \u2502 \u251c\u2500\u2500 sub-ID01_dir-PA_epi.json \u2502 \u2514\u2500\u2500 sub-ID01_dir-PA_epi.nii.gz \u2514\u2500\u2500 func \u251c\u2500\u2500 sub-ID01_task-rest_bold.json \u2514\u2500\u2500 sub-ID01_task-rest_bold.nii.gz 2 directories, 6 files Files that were not paired stay in a temporary directory tmp_dcm2bids/sub-<label> . In your case : tmp_dcm2bids/sub-ID01 . Command 1 tree tmp_dcm2bids/ Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ tree tmp_dcm2bids/ tmp_dcm2bids/ \u251c\u2500\u2500 helper \u2502 \u251c\u2500\u2500 003_In_EPI_PE = AP_20180918121230.json \u2502 \u251c\u2500\u2500 003_In_EPI_PE = AP_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 004_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u251c\u2500\u2500 004_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u2502 \u251c\u2500\u2500 004_In_EPI_PE = PA_20180918121230.json \u2502 \u251c\u2500\u2500 004_In_EPI_PE = PA_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u2502 \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.json \u2502 \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u2502 \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.json \u2502 \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u2514\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u251c\u2500\u2500 log \u2502 \u2514\u2500\u2500 sub-ID01_2022-04-19T111537.459742.log \u2514\u2500\u2500 sub-ID01 \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.json \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.json \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.nii.gz \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.json \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.json \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.nii.gz \u251c\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.json \u2514\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.nii.gz 3 directories, 27 files That is it, you are done with the tutorial! You can now browse through the documentation to find information about the different commands. Go to the How-to guides section Acknowledgment Thanks to @Remi-gau for letting us know that our tutorial needed an update, and for providing us with a clean and working configuration file through an issue #142 on GitHub .","title":"First steps"},{"location":"docs/tutorial/first-steps/#tutorial-first-steps","text":"","title":"Tutorial - First steps"},{"location":"docs/tutorial/first-steps/#how-to-use-this-tutorial","text":"This tutorial was developed assuming no prior knowledge of the tool, and little knowledge of the command line (terminal). It aims to be beginner-friendly by giving a lot of details. To get the most out of it, you recommend that you run the commands throughout the tutorial and compare your outputs with the outputs from the example. Every time you need to run a command, you will see two tabs, one for the command you need to run, and another one with the expected output. While you can copy the command, you recommend that you type each command, which is good for your procedural memory :brain:. The Command and Output tabs will look like these: Command 1 echo \"Hello, World!\" Output 1 2 sam:~/$ echo \"Hello, World!\" Hello, World! Note that in the Output tab, the content before the command prompt ( $ ) will be dependend or your operating system and terminal configuration. What you want to compare is what follows it and the output below the command that was ran. The output you see was taken directly out of your terminal when you tested the tutorial.","title":"How to use this tutorial"},{"location":"docs/tutorial/first-steps/#setup","text":"dcm2bids must be installed If you have not installed dcm2bids yet, now is the time to go to the installation page and install dcm2bids with its dependencies. This tutorial does not cover the installation part and assumes you have dcm2bids properly installed.","title":"Setup"},{"location":"docs/tutorial/first-steps/#activate-your-dcm2bids-environment","text":"If you followed the installation procedure , you have to activate your dedicated environment for dcm2bids. Note that you use dcm2bids as the name of the environment but you should use the name you gave your environment when you created it. If you used Anaconda Navigator to install dcm2bids and create you environment, make sure to open your environment from Navigator as indicated in Create your environment with the Anaconda Navigator GUI . Command 1 conda activate dcm2bids Output 1 2 conda activate dcm2bids ( dcm2bids ) sam:~$","title":"Activate your dcm2bids environment"},{"location":"docs/tutorial/first-steps/#test-your-environment","text":"It is always good to make sure you have access to the software you want to use. You can test it with any command but a safe way is to use the --help command. Command 1 dcm2bids --help Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ( dcm2bids ) sam:~$ dcm2bids --help usage: dcm2bids [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] -p PARTICIPANT [ -s SESSION ] -c CONFIG [ -o OUTPUT_DIR ] [ --forceDcm2niix ] [ --clobber ] [ -l { DEBUG,INFO,WARNING,ERROR,CRITICAL }] [ -a ] Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure dcm2bids 3 .0.0 options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM directory ( ies ) -p PARTICIPANT, --participant PARTICIPANT Participant ID -s SESSION, --session SESSION Session ID -c CONFIG, --config CONFIG JSON configuration file ( see example/config.json ) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory ( /home/sam ) --bids_validate If set, once your conversion is done it will check if your output folder is BIDS valid. [ False ] bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator#quickstart --forceDcm2niix Overwrite previous temporary dcm2niix output if it exists --clobber Overwrite output if it exists -l { DEBUG,INFO,WARNING,ERROR,CRITICAL } , --log_level { DEBUG,INFO,WARNING,ERROR,CRITICAL } Set logging level -a, --anonymizer This option no longer exists from the script in this release. See:https://github.com/unfmontreal/Dcm2Bids/blob/m aster/README.md#defaceTpl Documentation at https://github.com/unfmontreal/Dcm2Bids What you can do if you did not get this output If you got dcm2bids: command not found , it means dcm2bids is not either not installed or not accessible in your current environment. Did you activate your environment? Visit the installation page for more info.","title":"Test your environment"},{"location":"docs/tutorial/first-steps/#create-a-new-directory-for-this-tutorial","text":"For the tutorial, you recommend that you create a new directory (folder) instead of jumping straight into a real project directory with real data. In this tutorial, we decided to named our project directory dcm2bids-tutorial . Command 1 2 mkdir dcm2bids-tutorial cd dcm2bids-tutorial Output 1 2 3 4 5 ( dcm2bids ) sam:~$ mkdir dcm2bids-tutorial ( dcm2bids ) sam:~$ cd dcm2bids-tutorial/ ( dcm2bids ) sam:~/dcm2bids-tutorial$ # no output is printed by mkdir and cd if when the command is successful. # You can now see that you are inside dcm2bids-tutorial directory.","title":"Create a new directory for this tutorial"},{"location":"docs/tutorial/first-steps/#scaffolding","text":"While scaffolding is a not mandatory step before converting data with the main dcm2bids command, it is highly recommended when you plan to convert data. dcm2bids has a command named dcm2bids_scaffold that will help you structure and organize your data in an efficient way by creating automatically for you a basic directory structure and the core files according to the Brain Imaging Data Structure (BIDS) specification .","title":"Scaffolding"},{"location":"docs/tutorial/first-steps/#tree-structure-of-the-scaffold-created-by-dcm2bids","text":"1 2 3 4 5 6 7 8 9 10 11 scaffold_directory/ \u251c\u2500\u2500 CHANGES \u251c\u2500\u2500 code/ \u251c\u2500\u2500 dataset_description.json \u251c\u2500\u2500 derivatives/ \u251c\u2500\u2500 participants.json \u251c\u2500\u2500 participants.tsv \u251c\u2500\u2500 README \u2514\u2500\u2500 sourcedata/ 3 directories, 5 files Describing the function of each directory and files is out of the scope of this tutorial but if you want to learn more about BIDS, you encourage you to go through the BIDS Starter Kit .","title":"Tree structure of the scaffold created by dcm2bids"},{"location":"docs/tutorial/first-steps/#run-dcm2bids_scaffold","text":"To find out how to run dcm2bids_scaffold work, you can use the --help option. Command 1 dcm2bids_scaffold --help Output 1 2 3 4 5 6 7 8 9 10 11 12 ( dcm2bids ) sam:~/dcm2bids-tutorial$ dcm2bids_scaffold --help usage: dcm2bids_scaffold [ -h ] [ -o OUTPUT_DIR ] Create basic BIDS files and directories options: -h, --help show this help message and exit -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory Documentation at https://github.com/unfmontreal/Dcm2Bids As you can see at lines 9-10, dcm2bids_scaffold has an --output_dir (or -o for short) option with a default option, which means you can either specify where you want the scaffolding to happen to be or it will create the scaffold in the current directory as a default. Below you can see the difference between specifying -o output_dir and NOT specifying (using the default) the -o option. Note that you don't have to create the directory where you want to put the scaffold beforehand, the command will create it for you. Commands 1 dcm2bids_scaffold VS 1 dcm2bids_scaffold -o bids_project Output 1 2 3 4 ( dcm2bids ) sam:~/dcm2bids-tutorial$ dcm2bids_scaffold ( dcm2bids ) sam:~/dcm2bids-tutorial$ ls CHANGES dataset_description.json participants.json README code derivatives participants.tsv sourcedata VS 1 2 3 4 5 6 ( dcm2bids ) sam:~/dcm2bids-tutorial$ dcm2bids_scaffold -o bids_project ( dcm2bids ) sam:~/dcm2bids-tutorial$ ls -F bids_project/ ( dcm2bids ) sam:~/dcm2bids-tutorial$ ls -F bids_project/ CHANGES dataset_description.json participants.json README code/ derivatives/ participants.tsv sourcedata/ For the purpose of the tutorial, you chose to specify the output directory bids_project as if it were the start of a new project. For your real projects, you can choose to create a new directory with the commands or not, it is entirely up to you.","title":"Run dcm2bids_scaffold"},{"location":"docs/tutorial/first-steps/#change-directory-to-go-in-your-scaffold","text":"For those who created the scaffold in another directory, you must go inside that directory. Command 1 cd bids_project Output 1 2 ( dcm2bids ) sam:~/dcm2bids-tutorial$ cd bids_project/ ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$","title":"Change directory to go in your scaffold"},{"location":"docs/tutorial/first-steps/#download-neuroimaging-data","text":"For this tutorial, you will use a set of DICOMs made available by [neurolabusc][dcm_qa_nih] on GitHub. Why use these data in particular? You use the dcm_qa_nih data because it is the data used by the dcm2niix developers to validate the DICOM to NIfTI conversion process and it has been proven stable since 2017. It also includes data from both GE as well as Siemens MRI scanners so it gives a bit a diversity of data provenance. To download the data, you can use your terminal or the GitHub interface. You can do it any way you want as long as the directory with the dicoms is in sourcedata directory with the name dcm_qa_nih . Terminal Commands Download the zipped file from https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip . 1 wget -O dcm_qa_nih-master.zip https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip Extract/unzip the zipped file into sourcedata/ . 1 unzip dcm_qa_nih-master.zip -d sourcedata/ Rename the directory dcm_qa_nih . 1 mv sourcedata/dcm_qa_nih-master sourcedata/dcm_qa_nih OR You can clone the repository if you are familiar with Git. If you did the steps above, move on. 1 git clone https://github.com/neurolabusc/dcm_qa_nih/ sourcedata/dcm_qa_nih Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ wget -O dcm_qa_nih-master.zip https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip --2022-04-18 22 :17:26-- https://github.com/neurolabusc/dcm_qa_nih/archive/refs/heads/master.zip Resolving github.com ( github.com ) ... 140 .82.112.3 Connecting to github.com ( github.com ) | 140 .82.112.3 | :443... connected. HTTP request sent, awaiting response... 302 Found Location: https://codeload.github.com/neurolabusc/dcm_qa_nih/zip/refs/heads/master [ following ] --2022-04-18 22 :17:26-- https://codeload.github.com/neurolabusc/dcm_qa_nih/zip/refs/heads/master Resolving codeload.github.com ( codeload.github.com ) ... 140 .82.113.9 Connecting to codeload.github.com ( codeload.github.com ) | 140 .82.113.9 | :443... connected. HTTP request sent, awaiting response... 200 OK Length: 10258820 ( 9 .8M ) [ application/zip ] Saving to: \u2018dcm_qa_nih-master.zip\u2019 dcm_qa_nih-master.zip 100 % [====================== > ] 9 .78M 3 .24MB/s in 3 .0s 2022 -04-18 22 :17:29 ( 3 .24 MB/s ) - \u2018dcm_qa_nih-master.zip\u2019 saved [ 10258820 /10258820 ] ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ unzip dcm_qa_nih-master.zip -d sourcedata/ Archive: dcm_qa_nih-master.zip aa82e560d5471b53f0d0332c4de33d88bf179157 creating: sourcedata/dcm_qa_nih-master/ extracting: sourcedata/dcm_qa_nih-master/.gitignore creating: sourcedata/dcm_qa_nih-master/In/ creating: sourcedata/dcm_qa_nih-master/In/20180918GE/ inflating: sourcedata/dcm_qa_nih-master/In/20180918GE/README-Study.txt creating: sourcedata/dcm_qa_nih-master/In/20180918GE/mr_0004/ inflating: sourcedata/dcm_qa_nih-master/In/20180918GE/mr_0004/README-Series.txt inflating: sourcedata/dcm_qa_nih-master/In/20180918GE/mr_0004/axial_epi_fmri_interleaved_i_to_s-00001.dcm # [...] output was manually truncated because it was really really long inflating: sourcedata/dcm_qa_nih-master/Ref/EPI_PE = RL_5.nii inflating: sourcedata/dcm_qa_nih-master/batch.sh ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ mv sourcedata/dcm_qa_nih-master sourcedata/dcm_qa_nih GitHub Go to: https://github.com/neurolabusc/dcm_qa_nih and click on the green button (Code) to download ZIP . Download the zipped file. Extract/unzip the zipped file to the sourcedata directory inside your scaffold and rename the newly created directory dcm_qa_nih . You should now have a dcm_qa_nih directory nested in sourcedata with a bunch of files and directories: Command 1 ls sourcedata/dcm_qa_nih Output 1 2 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ ls sourcedata/dcm_qa_nih/ batch.sh In LICENSE README.md Ref","title":"Download neuroimaging data"},{"location":"docs/tutorial/first-steps/#building-the-configuration-file","text":"The configuration file is the central element for dcm2bids to organize your data into the Brain Imaging Data Structure standard. dcm2bids uses information from the config file to determine which data in the protocol will be converted, and how they will be renamed based on a set of rules. For this reason, it is important to have a little understanding of the core BIDS principles. The BIDS Starter Kit a good place to start Tutorial on Annotating a BIDS dataset from . As you will see below, the configuration file must be structured in the Javascript Object Notation (JSON) format. More info about the configuration file The How-to guide on creating a config file provides useful information about required and optional fields, and the inner working of a config file. In short you need a configuration file because, for each acquisition, dcm2niix creates an associated .json file, containing information from the dicom header. These are known as sidecar files . These are the sidecars that dcm2bids uses to filter the groups of acquisitions based on the configuration file. You have to input the filters yourself, which is way easier to define when you have access to an example of the sidecar files. You can generate all the sidecar files for an individual participant using the dcm2bids_helper command.","title":"Building the configuration file"},{"location":"docs/tutorial/first-steps/#dcm2bids_helper-command","text":"This command will convert the DICOM files it finds to NIfTI files and save them inside a temporary directory for you to inspect and make some filters for the config file. As usual the first command will be to request the help info. Command 1 dcm2bids_helper --help Output 1 2 3 4 5 6 7 8 9 10 11 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids_helper --help usage: dcm2bids_helper [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] [ -o OUTPUT_DIR ] options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM files directory -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory Documentation at https://github.com/unfmontreal/Dcm2Bids To run the commands, you have to specify the -d option, namely the input directory containing the DICOM files. The -o option is optional, defaulting to moving the files inside a new tmp_dcm2bids/helper directory from where you run the command, the current directory. Use one participant only For this tutorial, it is easy since you there are only few data. However, in project with many participants, it is recommended to use data from one one session of one participant only by targeting their directory, otherwise you may be overwhelmed by the number of files for nothing. In this tutorial, there are two folders with data, one with data coming from a Siemens scanner ( 20180918Si ), and one with data coming from GE (20180918GE). The tutorial will use the data acquired on both scanners and Siemens scanner located in sourcedata/dcm_qa_nih/In/ and pretend it is one participant only. Command 1 dcm2bids_helper -d sourcedata/dcm_qa_nih/In/ Output 1 2 3 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids_helper -d sourcedata/dcm_qa_nih/In/ Example in : /home/sam/dcm2bids-tutorial/bids_project/tmp_dcm2bids/helper","title":"dcm2bids_helper command"},{"location":"docs/tutorial/first-steps/#finding-what-you-need-in-tmp_dcm2bidshelper","text":"You should now able to see a list of compressed NIfTI files ( nii.gz ) with their respective sidecar files ( .json ). You can tell which file goes with which file based on their identical names, only with a Command 1 ls tmp_dcm2bids/helper Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ ls tmp_dcm2bids/helper/ '003_In_EPI_PE=AP_20180918121230.json' '003_In_EPI_PE=AP_20180918121230.nii.gz' 004_In_DCM2NIIX_regression_test_20180918114023.json 004_In_DCM2NIIX_regression_test_20180918114023.nii.gz '004_In_EPI_PE=PA_20180918121230.json' '004_In_EPI_PE=PA_20180918121230.nii.gz' 005_In_DCM2NIIX_regression_test_20180918114023.json 005_In_DCM2NIIX_regression_test_20180918114023.nii.gz '005_In_EPI_PE=RL_20180918121230.json' '005_In_EPI_PE=RL_20180918121230.nii.gz' 006_In_DCM2NIIX_regression_test_20180918114023.json 006_In_DCM2NIIX_regression_test_20180918114023.nii.gz '006_In_EPI_PE=LR_20180918121230.json' '006_In_EPI_PE=LR_20180918121230.nii.gz' 007_In_DCM2NIIX_regression_test_20180918114023.json 007_In_DCM2NIIX_regression_test_20180918114023.nii.gz As you can see, it is not necessarily easy to tell which scan files ( nii.gz ) refer to which acquisitions from their names only. That is why you have to go through their sidecar files to find unique identifiers for one acquisiton you want to BIDSify . Go ahead and use any code editor, file viewer or your terminal to inspect the sidecar files. Here, we compare two files that have similar names to highlight their differences: Command 1 diff --side-by-side tmp_dcm2bids/helper/ \"003_In_EPI_PE=AP_20180918121230.json\" tmp_dcm2bids/helper/ \"004_In_EPI_PE=PA_20180918121230.json\" Note than in this example, the filename are wrapped with quotes ( \" ) as in \"filename.ext\" because there is an = include in the name. You have to wrap your filenames if they contains special characters, including spaces. To avoid weird problems, we highly recommend to use alphanumeric only names when you can choose the name of your MRI protocols and sequences. Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ diff --side-by-side tmp_dcm2bids/helper/003_In_EPI_PE \\= AP_20180918121230.json tmp_dcm2bids/helper/004_In_EPI_PE \\= PA_20180918121230.json { { \"Modality\" : \"MR\" , \"Modality\" : \"MR\" , \"MagneticFieldStrength\" : 3 , \"MagneticFieldStrength\" : 3 , \"ImagingFrequency\" : 123 .204, \"ImagingFrequency\" : 123 .204, \"Manufacturer\" : \"Siemens\" , \"Manufacturer\" : \"Siemens\" , \"ManufacturersModelName\" : \"Skyra\" , \"ManufacturersModelName\" : \"Skyra\" , \"InstitutionName\" : \"NIH\" , \"InstitutionName\" : \"NIH\" , \"InstitutionalDepartmentName\" : \"FMRIF 3TD\" , \"InstitutionalDepartmentName\" : \"FMRIF 3TD\" , \"InstitutionAddress\" : \"10 Center Drive Building 10 Ro \" InstitutionAddress \": \" 10 Center Drive Building 10 Ro \"DeviceSerialNumber\" : \"45160\" , \"DeviceSerialNumber\" : \"45160\" , \"StationName\" : \"AWP45160\" , \"StationName\" : \"AWP45160\" , \"BodyPartExamined\" : \"BRAIN\" , \"BodyPartExamined\" : \"BRAIN\" , \"PatientPosition\" : \"HFS\" , \"PatientPosition\" : \"HFS\" , \"ProcedureStepDescription\" : \"FMRIF^QA\" , \"ProcedureStepDescription\" : \"FMRIF^QA\" , \"SoftwareVersions\" : \"syngo MR E11\" , \"SoftwareVersions\" : \"syngo MR E11\" , \"MRAcquisitionType\" : \"2D\" , \"MRAcquisitionType\" : \"2D\" , \"SeriesDescription\" : \"EPI PE=AP\" , | \"SeriesDescription\" : \"EPI PE=PA\" , \"ProtocolName\" : \"EPI PE=AP\" , | \"ProtocolName\" : \"EPI PE=PA\" , \"ScanningSequence\" : \"EP\" , \"ScanningSequence\" : \"EP\" , \"SequenceVariant\" : \"SK\" , \"SequenceVariant\" : \"SK\" , \"ScanOptions\" : \"FS\" , \"ScanOptions\" : \"FS\" , \"SequenceName\" : \"epfid2d1_72\" , \"SequenceName\" : \"epfid2d1_72\" , \"ImageType\" : [ \"ORIGINAL\" , \"PRIMARY\" , \"M\" , \"ND\" , \"ECHO \" ImageType \": [\" ORIGINAL \", \" PRIMARY \", \" M \", \" ND \", \" ECHO \"SeriesNumber\" : 3 , | \"SeriesNumber\" : 4 , \"AcquisitionTime\" : \"12:24:58.102500\" , | \"AcquisitionTime\" : \"12:26:54.517500\" , \"AcquisitionNumber\" : 1 , \"AcquisitionNumber\" : 1 , \"ImageComments\" : \"None\" , \"ImageComments\" : \"None\" , \"SliceThickness\" : 3 , \"SliceThickness\" : 3 , \"SpacingBetweenSlices\" : 12 , \"SpacingBetweenSlices\" : 12 , \"SAR\" : 0 .00556578, \"SAR\" : 0 .00556578, \"EchoTime\" : 0 .05, \"EchoTime\" : 0 .05, \"RepetitionTime\" : 2 .43537, \"RepetitionTime\" : 2 .43537, \"FlipAngle\" : 75 , \"FlipAngle\" : 75 , \"PartialFourier\" : 1 , \"PartialFourier\" : 1 , \"BaseResolution\" : 72 , \"BaseResolution\" : 72 , \"ShimSetting\" : [ \"ShimSetting\" : [ -3717, -3717, 15233 , 15233 , -9833, -9833, -207, -207, -312, -312, -110, -110, 150 , 150 , 226 ] , 226 ] , \"TxRefAmp\" : 316 .97, \"TxRefAmp\" : 316 .97, \"PhaseResolution\" : 1 , \"PhaseResolution\" : 1 , \"ReceiveCoilName\" : \"Head_32\" , \"ReceiveCoilName\" : \"Head_32\" , \"ReceiveCoilActiveElements\" : \"HEA;HEP\" , \"ReceiveCoilActiveElements\" : \"HEA;HEP\" , \"PulseSequenceDetails\" : \"%CustomerSeq%\\\\nih_ep2d_bold \" PulseSequenceDetails \": \" %CustomerSeq% \\\\ nih_ep2d_bold \"CoilCombinationMethod\" : \"Sum of Squares\" , \"CoilCombinationMethod\" : \"Sum of Squares\" , \"ConsistencyInfo\" : \"N4_VE11C_LATEST_20160120\" , \"ConsistencyInfo\" : \"N4_VE11C_LATEST_20160120\" , \"MatrixCoilMode\" : \"SENSE\" , \"MatrixCoilMode\" : \"SENSE\" , \"PercentPhaseFOV\" : 100 , \"PercentPhaseFOV\" : 100 , \"PercentSampling\" : 100 , \"PercentSampling\" : 100 , \"EchoTrainLength\" : 72 , \"EchoTrainLength\" : 72 , \"PhaseEncodingSteps\" : 72 , \"PhaseEncodingSteps\" : 72 , \"AcquisitionMatrixPE\" : 72 , \"AcquisitionMatrixPE\" : 72 , \"ReconMatrixPE\" : 72 , \"ReconMatrixPE\" : 72 , \"BandwidthPerPixelPhaseEncode\" : 27 .778, \"BandwidthPerPixelPhaseEncode\" : 27 .778, \"EffectiveEchoSpacing\" : 0 .000499996, \"EffectiveEchoSpacing\" : 0 .000499996, \"DerivedVendorReportedEchoSpacing\" : 0 .000499996, \"DerivedVendorReportedEchoSpacing\" : 0 .000499996, \"TotalReadoutTime\" : 0 .0354997, \"TotalReadoutTime\" : 0 .0354997, \"PixelBandwidth\" : 2315 , \"PixelBandwidth\" : 2315 , \"DwellTime\" : 3e-06, \"DwellTime\" : 3e-06, \"PhaseEncodingDirection\" : \"j-\" , | \"PhaseEncodingDirection\" : \"j\" , \"SliceTiming\" : [ \"SliceTiming\" : [ 0 , 0 , 1 .45, | 1 .4475, 0 .4825, 0 .4825, 1 .9325, | 1 .93, 0 .9675 ] , | 0 .965 ] , \"ImageOrientationPatientDICOM\" : [ \"ImageOrientationPatientDICOM\" : [ 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 0 ] , 0 ] , \"ImageOrientationText\" : \"Tra\" , \"ImageOrientationText\" : \"Tra\" , \"InPlanePhaseEncodingDirectionDICOM\" : \"COL\" , \"InPlanePhaseEncodingDirectionDICOM\" : \"COL\" , \"ConversionSoftware\" : \"dcm2niix\" , \"ConversionSoftware\" : \"dcm2niix\" , \"ConversionSoftwareVersion\" : \"v1.0.20211006\" \"ConversionSoftwareVersion\" : \"v1.0.20211006\" } } Again, when you will do it with your DICOMs, you will want to run dcm2bids_helper on a typical session of one of your participants. You will probably get more files than this example For the purpose of the tutorial, we will be interested in three specific acquisitions, namely: 004_In_DCM2NIIX_regression_test_20180918114023 003_In_EPI_PE=AP_20180918121230 004_In_EPI_PE=PA_20180918121230 The first is an resting-state fMRI acquisiton whereas the second and third are fieldmap EPI.","title":"Finding what you need in tmp_dcm2bids/helper"},{"location":"docs/tutorial/first-steps/#setting-up-the-configuration-file","text":"Once you found the data you want to BIDSify , you can start setting up your configuration file. The file name is arbritrary but for the readibility purpose, you can name it dcm2bids_config.json like in the tutorial. You can create in the code/ directory. Use any code editor to create the file and add the following content: 1 2 3 { \"descriptions\" : [] } Command 1 nano code/dcm2bids_config.json Output 1 2 3 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ nano code/dcm2bids_config.json ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ # No output is shown since nano is an interactive terminal-based editor","title":"Setting up the configuration file"},{"location":"docs/tutorial/first-steps/#populating-the-config-file","text":"To populate the config file, you need to inspect each sidecar files one at a time and make sure there is a unique match for the acquisition you target. For example, with the resting-state fMRI data ( 004_In_DCM2NIIX_regression_test_20180918114023 ). You can inspect its sidecar file and look for the \"SeriesDescription\" field for example. It is often a good unique identifier. Command 1 cat tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ cat tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json { \"Modality\" : \"MR\" , \"MagneticFieldStrength\" : 3 , \"ImagingFrequency\" : 127 .697, \"Manufacturer\" : \"GE\" , \"PulseSequenceName\" : \"epiRT\" , \"InternalPulseSequenceName\" : \"EPI\" , \"ManufacturersModelName\" : \"DISCOVERY MR750\" , \"InstitutionName\" : \"NIH FMRIF\" , \"DeviceSerialNumber\" : \"000301496MR3T6MR\" , \"StationName\" : \"fmrif3tb\" , \"BodyPartExamined\" : \"BRAIN\" , \"PatientPosition\" : \"HFS\" , \"SoftwareVersions\" : \"27\\\\LX\\\\MR Software release:DV26.0_R01_1725.a\" , \"MRAcquisitionType\" : \"2D\" , \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)\" , \"ProtocolName\" : \"DCM2NIIX regression test\" , \"ScanningSequence\" : \"EP\\\\GR\" , \"SequenceVariant\" : \"SS\" , \"ScanOptions\" : \"EPI_GEMS\\\\PFF\" , \"ImageType\" : [ \"ORIGINAL\" , \"PRIMARY\" , \"EPI\" , \"NONE\" ] , \"SeriesNumber\" : 4 , \"AcquisitionTime\" : \"11:48:15.000000\" , \"AcquisitionNumber\" : 1 , \"SliceThickness\" : 3 , \"SpacingBetweenSlices\" : 5 , \"SAR\" : 0 .0166392, \"EchoTime\" : 0 .03, \"RepetitionTime\" : 5 , \"FlipAngle\" : 60 , \"PhaseEncodingPolarityGE\" : \"Unflipped\" , \"CoilString\" : \"32Ch Head\" , \"PercentPhaseFOV\" : 100 , \"PercentSampling\" : 100 , \"AcquisitionMatrixPE\" : 64 , \"ReconMatrixPE\" : 64 , \"EffectiveEchoSpacing\" : 0 .000388, \"TotalReadoutTime\" : 0 .024444, \"PixelBandwidth\" : 7812 .5, \"PhaseEncodingDirection\" : \"j-\" , \"SliceTiming\" : [ 0 , 2 .66667, 0 .333333, 3 , 0 .666667, 3 .33333, 1 , 3 .66667, 1 .33333, 4 , 1 .66667, 4 .33333, 2 , 4 .66667, 2 .33333 ] , \"ImageOrientationPatientDICOM\" : [ 1 , -0, 0 , -0, 1 , 0 ] , \"InPlanePhaseEncodingDirectionDICOM\" : \"COL\" , \"ConversionSoftware\" : \"dcm2niix\" , \"ConversionSoftwareVersion\" : \"v1.0.20211006\" } To match the \"SeriesDescription\" field, a pattern like Axial EPI-FMRI* could match it. However, we need to make sure we will match only one acquisition. You can test it by looking manually at inside all sidecar files but it is now recommend. It is rather trivial for the computer to look in all the .json files for you with the grep command: Command 1 grep \"Axial EPI-FMRI*\" tmp_dcm2bids/helper/*.json Output 1 2 3 4 5 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"Axial EPI-FMRI*\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)\" , tmp_dcm2bids/helper/005_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Sequential I to S)\" , tmp_dcm2bids/helper/006_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved S to I)\" , tmp_dcm2bids/helper/007_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Sequential S to I)\" , Unfortunately, this criteria is not enough and it could match other 4 files. In this situation, you can add another criteria to match the specific acquisition. Which one do you think would be more appropriate? Go back to the content of the fMRI sidecar file and find a another criteria that, in combination with the \"SeriesDescription\" , will uniquely match the fMRI data. Right, maybe instead of trying to look for another field, you could simply extend the criteria for the \"SeriesDescription\" . How many files does it match if you extend it to the full value ( Axial EPI-FMRI (Interleaved I to S) ? Command 1 grep \"Axial EPI-FMRI (Interleaved I to S)*\" tmp_dcm2bids/helper/*.json Output 1 2 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"Axial EPI-FMRI (Interleaved I to S)*\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/004_In_DCM2NIIX_regression_test_20180918114023.json: \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)\" , , there is only one match! It means you can now update your configuration file by adding a couple of necessary fields for which you can find a description in How to create a config file . Since it is a resting-stage fMRI acquisition, you want to specify it like this then make dcm2bids change your task name: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"descriptions\" : [ { \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)*\" }, \"sidecarChanges\" : { \"TaskName\" : \"rest\" } } ] } Command 1 nano code/dcm2bids_config.json Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ nano code/dcm2bids_config.json ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ cat code/dcm2bids_config.json { \"descriptions\" : [ { \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"SeriesDescription\" : \"*Axial EPI-FMRI (Interleaved I to S)*\" } , \"sidecarChanges\" : { \"TaskName\" : \"rest\" } } ] } Avoid using filename as criteria While you can take file names to match as criteria, we do not recommend this as different versions of dcm2niix can lead to different file names (Refer to the release notes of version 17-March-2021 (v1.0.20210317) of dcmniix to now more, especially the GE file naming behavior changes (%p protocol name and %d description) section . Moving to the two fieldmaps, if you inspect their sidecar files (the same ones that were compared in the dcm2bids_helper section ), you can see a pattern of \"EPI PE=AP\" or \"EPI PE=PA\" in the SeriesDescription once again. Is it enough to match only the correct acquisition? You can test it, of course! Command 1 2 grep \"EPI PE=AP\" tmp_dcm2bids/helper/*.json grep \"EPI PE=PA\" tmp_dcm2bids/helper/*.json Output There are two matches per pattern but they come from the same file, so it is okay. 1 2 3 4 5 6 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"EPI PE=AP\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/003_In_EPI_PE = AP_20180918121230.json: \"SeriesDescription\" : \"EPI PE=AP\" , tmp_dcm2bids/helper/003_In_EPI_PE = AP_20180918121230.json: \"ProtocolName\" : \"EPI PE=AP\" , ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ grep \"EPI PE=PA\" tmp_dcm2bids/helper/*.json tmp_dcm2bids/helper/004_In_EPI_PE = PA_20180918121230.json: \"SeriesDescription\" : \"EPI PE=PA\" , tmp_dcm2bids/helper/004_In_EPI_PE = PA_20180918121230.json: \"ProtocolName\" : \"EPI PE=PA\" , Once you are sure of you matching criteria, you can update your configuration file with the appropriate info. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 { \"descriptions\" : [ { \"id\" : \"id_task-rest\" , \"dataType\" : \"func\" , \"modalityLabel\" : \"bold\" , \"customLabels\" : \"task-rest\" , \"criteria\" : { \"SeriesDescription\" : \"Axial EPI-FMRI (Interleaved I to S)*\" }, \"sidecarChanges\" : { \"TaskName\" : \"rest\" } }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"epi\" , \"customLabels\" : \"dir-AP\" , \"criteria\" : { \"SeriesDescription\" : \"EPI PE=AP*\" }, \"intendedFor\" : \"id_task-rest\" }, { \"dataType\" : \"fmap\" , \"modalityLabel\" : \"epi\" , \"customLabels\" : \"dir-PA\" , \"criteria\" : { \"SeriesDescription\" : \"EPI PE=PA*\" }, \"intendedFor\" : \"id_task-rest\" } ] } For fieldmaps, you need to add an \"intendedFor\" field to show that these fieldmaps should be used with your fMRI acquisition. Have a look at the explanation of intendedFor in the documentation or in the BIDS specification . Use an online JSON validator Editing JSON file is prone to errors such as misplacing or forgetting a comma or not having matched opening and closing [] or {} . JSON linters are useful to validate that we did enter all information successfully. You can find these tools online, for example https://jsonlint.com . Now that you have a configuration file ready, it is time to finally run dcm2bids .","title":"Populating the config file"},{"location":"docs/tutorial/first-steps/#running-dcm2bids","text":"By now, you should be used to getting the --help information before running a command. Command 1 dcm2bids --help Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids --help usage: dcm2bids [ -h ] -d DICOM_DIR [ DICOM_DIR ... ] -p PARTICIPANT [ -s SESSION ] -c CONFIG [ -o OUTPUT_DIR ] [ --forceDcm2niix ] [ --clobber ] [ -l { DEBUG,INFO,WARNING,ERROR,CRITICAL }] [ -a ] Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure dcm2bids 3 .0.0 options: -h, --help show this help message and exit -d DICOM_DIR [ DICOM_DIR ... ] , --dicom_dir DICOM_DIR [ DICOM_DIR ... ] DICOM directory ( ies ) -p PARTICIPANT, --participant PARTICIPANT Participant ID -s SESSION, --session SESSION Session ID -c CONFIG, --config CONFIG JSON configuration file ( see example/config.json ) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Output BIDS directory, Default: current directory ( /home/sam/dcm2bids-tutorial/bids_project ) --bids_validate If set, once your conversion is done it will check if your output folder is BIDS valid. [ False ] bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator#quickstart --forceDcm2niix Overwrite previous temporary dcm2niix output if it exists --clobber Overwrite output if it exists -l { DEBUG,INFO,WARNING,ERROR,CRITICAL } , --log_level { DEBUG,INFO,WARNING,ERROR,CRITICAL } Set logging level -a, --anonymizer This option no longer exists from the script in this release. See:https://github.com/unfmontreal/Dcm2Bids/blob/master/README.md#defaceTpl Documentation at https://github.com/unfmontreal/Dcm2Bids As you can see, to run the dcm2bids command, you have to specify at least 3 required options with their argument. 1 dcm2bids -d path/to/source/data -p subject_id -c path/to/config/file.json dcm2bids will create a directory which will be named after the argument specified for -p , and put the BIDSified data in it. For the tutorial, pretend that the subject_id is simply ID01 . Note that if you don't specify the -o option, your current directory will be populated with the sub-<label> directories. That being said, you can run the command: Command 1 dcm2bids -d sourcedata/dcm_qa_nih/In/ -p ID01 -c code/dcm2bids_config.json Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ dcm2bids -d sourcedata/dcm_qa_nih/In/ -p ID01 -c code/dcm2bids_config.json INFO:dcm2bids.dcm2bids:--- dcm2bids start --- INFO:dcm2bids.dcm2bids:OS:version: Linux-5.13.0-39-generic-x86_64-with-glibc2.31 INFO:dcm2bids.dcm2bids:python:version: 3 .10.4 | packaged by conda-forge | ( main, Mar 24 2022 , 17 :39:04 ) [ GCC 10 .3.0 ] INFO:dcm2bids.dcm2bids:dcm2bids:version: 2 .1.7 INFO:dcm2bids.dcm2bids:dcm2niix:version: v1.0.20211006 INFO:dcm2bids.dcm2bids:participant: sub-ID01 INFO:dcm2bids.dcm2bids:session: INFO:dcm2bids.dcm2bids:config: /home/sam/dcm2bids-tutorial/bids_project/code/dcm2bids_config.json INFO:dcm2bids.dcm2bids:BIDS directory: /home/sam/dcm2bids-tutorial/bids_project INFO:dcm2bids.utils:Running dcm2niix -b y -ba y -z y -f '%3s_%f_%p_%t' -o /home/sam/dcm2bids-tutorial/bids_project/tmp_dcm2bids/sub-ID01 sourcedata/dcm_qa_nih/In/ INFO:dcm2bids.dcm2niix:Check log file for dcm2niix output INFO:dcm2bids.sidecar:Sidecars pairing: INFO:dcm2bids.sidecar:_dir-AP_epi <- 003_In_EPI_PE = AP_20180918121230 INFO:dcm2bids.sidecar:_task-rest_bold <- 004_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.sidecar:_dir-PA_epi <- 004_In_EPI_PE = PA_20180918121230 INFO:dcm2bids.sidecar:No Pairing <- 005_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.sidecar:No Pairing <- 005_In_EPI_PE = RL_20180918121230 INFO:dcm2bids.sidecar:No Pairing <- 006_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.sidecar:No Pairing <- 006_In_EPI_PE = LR_20180918121230 INFO:dcm2bids.sidecar:No Pairing <- 007_In_DCM2NIIX_regression_test_20180918114023 INFO:dcm2bids.dcm2bids:moving acquisitions into BIDS folder A bunch of information is printed to the terminal as well as to a log file located at tmp_dcm2bids/log/sub-<label>_<datetime>.log . It is useful to keep these log files in case you notice an error after a while and need to find which participants are affected. You can see that dcm2bids was able to pair and match the files you specified at lines 14-16 in the previous output tab. You can now have a look in the newly created folder sub-ID01 and discover your converted data! Command 1 tree sub-ID01/ Output 1 2 3 4 5 6 7 8 9 10 11 12 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ tree sub-ID01/ sub-ID01/ \u251c\u2500\u2500 fmap \u2502 \u251c\u2500\u2500 sub-ID01_dir-AP_epi.json \u2502 \u251c\u2500\u2500 sub-ID01_dir-AP_epi.nii.gz \u2502 \u251c\u2500\u2500 sub-ID01_dir-PA_epi.json \u2502 \u2514\u2500\u2500 sub-ID01_dir-PA_epi.nii.gz \u2514\u2500\u2500 func \u251c\u2500\u2500 sub-ID01_task-rest_bold.json \u2514\u2500\u2500 sub-ID01_task-rest_bold.nii.gz 2 directories, 6 files Files that were not paired stay in a temporary directory tmp_dcm2bids/sub-<label> . In your case : tmp_dcm2bids/sub-ID01 . Command 1 tree tmp_dcm2bids/ Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ( dcm2bids ) sam:~/dcm2bids-tutorial/bids_project$ tree tmp_dcm2bids/ tmp_dcm2bids/ \u251c\u2500\u2500 helper \u2502 \u251c\u2500\u2500 003_In_EPI_PE = AP_20180918121230.json \u2502 \u251c\u2500\u2500 003_In_EPI_PE = AP_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 004_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u251c\u2500\u2500 004_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u2502 \u251c\u2500\u2500 004_In_EPI_PE = PA_20180918121230.json \u2502 \u251c\u2500\u2500 004_In_EPI_PE = PA_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u2502 \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.json \u2502 \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u2502 \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.json \u2502 \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.nii.gz \u2502 \u251c\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.json \u2502 \u2514\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u251c\u2500\u2500 log \u2502 \u2514\u2500\u2500 sub-ID01_2022-04-19T111537.459742.log \u2514\u2500\u2500 sub-ID01 \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.json \u251c\u2500\u2500 005_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.json \u251c\u2500\u2500 005_In_EPI_PE = RL_20180918121230.nii.gz \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.json \u251c\u2500\u2500 006_In_DCM2NIIX_regression_test_20180918114023.nii.gz \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.json \u251c\u2500\u2500 006_In_EPI_PE = LR_20180918121230.nii.gz \u251c\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.json \u2514\u2500\u2500 007_In_DCM2NIIX_regression_test_20180918114023.nii.gz 3 directories, 27 files That is it, you are done with the tutorial! You can now browse through the documentation to find information about the different commands. Go to the How-to guides section Acknowledgment Thanks to @Remi-gau for letting us know that our tutorial needed an update, and for providing us with a clean and working configuration file through an issue #142 on GitHub .","title":"Running dcm2bids"},{"location":"reference/dcm2bids/","text":"Module dcm2bids \u2693\ufe0e Sub-modules \u2693\ufe0e dcm2bids.acquisition dcm2bids.cli dcm2bids.dcm2bids_gen dcm2bids.dcm2niix_gen dcm2bids.participant dcm2bids.sidecar dcm2bids.utils dcm2bids.version","title":"Index"},{"location":"reference/dcm2bids/#module-dcm2bids","text":"","title":"Module dcm2bids"},{"location":"reference/dcm2bids/#sub-modules","text":"dcm2bids.acquisition dcm2bids.cli dcm2bids.dcm2bids_gen dcm2bids.dcm2niix_gen dcm2bids.participant dcm2bids.sidecar dcm2bids.utils dcm2bids.version","title":"Sub-modules"},{"location":"reference/dcm2bids/acquisition/","text":"Module dcm2bids.acquisition \u2693\ufe0e Participant class View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 # -*- coding: utf-8 -*- \"\"\"Participant class\"\"\" import logging from os.path import join as opj from dcm2bids.utils.utils import DEFAULT from dcm2bids.version import __version__ class Acquisition(object): \"\"\" Class representing an acquisition Args: participant (Participant): A participant object dataType (str): A functional group of MRI data (ex: func, anat ...) modalityLabel (str): The modality of the acquisition (ex: T1w, T2w, bold ...) customLabels (str): Optional labels (ex: task-rest) srcSidecar (Sidecar): Optional sidecar object \"\"\" def __init__( self, participant, dataType, modalityLabel, customLabels=\"\", id=None, srcSidecar=None, sidecarChanges=None, intendedFor=None, IntendedFor=None, **kwargs ): self.logger = logging.getLogger(__name__) self._modalityLabel = \"\" self._customLabels = \"\" self._id = \"\" self._intendedFor = None self.participant = participant self.dataType = dataType self.modalityLabel = modalityLabel self.customLabels = customLabels self.srcSidecar = srcSidecar if sidecarChanges is None: self.sidecarChanges = {} else: self.sidecarChanges = sidecarChanges if intendedFor is None: self.intendedFor = IntendedFor else: self.intendedFor = intendedFor if id is None: self.id = None else: self.id = id self.dstFile = '' def __eq__(self, other): return ( self.dataType == other.dataType and self.participant.prefix == other.participant.prefix and self.suffix == other.suffix ) @property def modalityLabel(self): \"\"\" Returns: A string '_<modalityLabel>' \"\"\" return self._modalityLabel @modalityLabel.setter def modalityLabel(self, modalityLabel): \"\"\" Prepend '_' if necessary\"\"\" self._modalityLabel = self.prepend(modalityLabel) @property def id(self): \"\"\" Returns: A string '_<id>' \"\"\" return self._id @id.setter def id(self, value): self._id = value @property def customLabels(self): \"\"\" Returns: A string '_<customLabels>' \"\"\" return self._customLabels @customLabels.setter def customLabels(self, customLabels): \"\"\" Prepend '_' if necessary\"\"\" self._customLabels = self.prepend(customLabels) @property def suffix(self): \"\"\" The suffix to build filenames Returns: A string '_<modalityLabel>' or '_<customLabels>_<modalityLabel>' \"\"\" if self.customLabels.strip() == \"\": return self.modalityLabel else: return self.customLabels + self.modalityLabel @property def srcRoot(self): \"\"\" Return: The sidecar source root to move \"\"\" if self.srcSidecar: return self.srcSidecar.root else: return None @property def dstRoot(self): \"\"\" Return: The destination root inside the BIDS structure \"\"\" return opj( self.participant.directory, self.dataType, self.dstFile, ) @property def dstIntendedFor(self): \"\"\" Return: The destination root inside the BIDS structure for intendedFor \"\"\" return opj( self.participant.session, self.dataType, self.dstFile, ) def setDstFile(self): \"\"\" Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html \"\"\" current_name = self.participant.prefix + self.suffix new_name = '' current_dict = dict(x.split(\"-\") for x in current_name.split(\"_\") if len(x.split('-')) == 2) suffix_list = [x for x in current_name.split(\"_\") if len(x.split('-')) == 1] for current_key in DEFAULT.entityTableKeys: if current_key in current_dict and new_name != '': new_name += f\"_{current_key}-{current_dict[current_key]}\" elif current_key in current_dict: new_name = f\"{current_key}-{current_dict[current_key]}\" current_dict.pop(current_key, None) for current_key in current_dict: new_name += f\"_{current_key}-{current_dict[current_key]}\" if current_dict: self.logger.warning(\"Entity \\\"{}\\\"\".format(list(current_dict.keys())) + \" is not a valid BIDS entity.\") new_name += f\"_{'_'.join(suffix_list)}\" # Allow multiple single keys (without value) if len(suffix_list) != 1: self.logger.warning(\"There was more than one suffix found \" f\"({suffix_list}). This is not BIDS \" \"compliant. Make sure you know what \" \"you are doing.\") if current_name != new_name: self.logger.warning( f\"\"\"\u2705 Filename was reordered according to BIDS entity table order: from: {current_name} to: {new_name}\"\"\") self.dstFile = new_name @property def intendedFor(self): return self._intendedFor @intendedFor.setter def intendedFor(self, value): if isinstance(value, list): self._intendedFor = value else: self._intendedFor = [value] def dstSidecarData(self, intendedForList): \"\"\" \"\"\" data = self.srcSidecar.origData data[\"Dcm2bidsVersion\"] = __version__ # intendedFor key if self.intendedFor != [None]: intendedValue = [] for index in self.intendedFor: if index in intendedForList: intendedValue = intendedValue + [intendedForList[index]] else: logging.warning(f\"No id found for IntendedFor value '{index}'.\") logging.warning(f\"No sidecar changes for field IntendedFor will be made for json file {self.dstFile}.json with this id.\") logging.warning(\"Check: https://unfmontreal.github.io/Dcm2Bids/docs/how-to/create-config-file/#id-and-intendedFor.\\n\") data[\"IntendedFor\"] = [item for sublist in intendedValue for item in sublist] # sidecarChanges for key, value in self.sidecarChanges.items(): data[key] = value return data @staticmethod def prepend(value, char=\"_\"): \"\"\" Prepend `char` to `value` if necessary Args: value (str) char (str) \"\"\" if value.strip() == \"\": return \"\" elif value.startswith(char): return value else: return char + value Classes \u2693\ufe0e Acquisition \u2693\ufe0e 1 2 3 4 5 6 7 8 9 10 11 12 class Acquisition ( participant , dataType , modalityLabel , customLabels = '' , id = None , srcSidecar = None , sidecarChanges = None , intendedFor = None , IntendedFor = None , ** kwargs ) Class representing an acquisition Attributes \u2693\ufe0e Name Type Description Default participant Participant A participant object None dataType str A functional group of MRI data (ex: func, anat ...) None modalityLabel str The modality of the acquisition (ex: T1w, T2w, bold ...) None customLabels str Optional labels (ex: task-rest) None srcSidecar Sidecar Optional sidecar object None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 class Acquisition(object): \"\"\" Class representing an acquisition Args: participant (Participant): A participant object dataType (str): A functional group of MRI data (ex: func, anat ...) modalityLabel (str): The modality of the acquisition (ex: T1w, T2w, bold ...) customLabels (str): Optional labels (ex: task-rest) srcSidecar (Sidecar): Optional sidecar object \"\"\" def __init__( self, participant, dataType, modalityLabel, customLabels=\"\", id=None, srcSidecar=None, sidecarChanges=None, intendedFor=None, IntendedFor=None, **kwargs ): self.logger = logging.getLogger(__name__) self._modalityLabel = \"\" self._customLabels = \"\" self._id = \"\" self._intendedFor = None self.participant = participant self.dataType = dataType self.modalityLabel = modalityLabel self.customLabels = customLabels self.srcSidecar = srcSidecar if sidecarChanges is None: self.sidecarChanges = {} else: self.sidecarChanges = sidecarChanges if intendedFor is None: self.intendedFor = IntendedFor else: self.intendedFor = intendedFor if id is None: self.id = None else: self.id = id self.dstFile = '' def __eq__(self, other): return ( self.dataType == other.dataType and self.participant.prefix == other.participant.prefix and self.suffix == other.suffix ) @property def modalityLabel(self): \"\"\" Returns: A string '_<modalityLabel>' \"\"\" return self._modalityLabel @modalityLabel.setter def modalityLabel(self, modalityLabel): \"\"\" Prepend '_' if necessary\"\"\" self._modalityLabel = self.prepend(modalityLabel) @property def id(self): \"\"\" Returns: A string '_<id>' \"\"\" return self._id @id.setter def id(self, value): self._id = value @property def customLabels(self): \"\"\" Returns: A string '_<customLabels>' \"\"\" return self._customLabels @customLabels.setter def customLabels(self, customLabels): \"\"\" Prepend '_' if necessary\"\"\" self._customLabels = self.prepend(customLabels) @property def suffix(self): \"\"\" The suffix to build filenames Returns: A string '_<modalityLabel>' or '_<customLabels>_<modalityLabel>' \"\"\" if self.customLabels.strip() == \"\": return self.modalityLabel else: return self.customLabels + self.modalityLabel @property def srcRoot(self): \"\"\" Return: The sidecar source root to move \"\"\" if self.srcSidecar: return self.srcSidecar.root else: return None @property def dstRoot(self): \"\"\" Return: The destination root inside the BIDS structure \"\"\" return opj( self.participant.directory, self.dataType, self.dstFile, ) @property def dstIntendedFor(self): \"\"\" Return: The destination root inside the BIDS structure for intendedFor \"\"\" return opj( self.participant.session, self.dataType, self.dstFile, ) def setDstFile(self): \"\"\" Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html \"\"\" current_name = self.participant.prefix + self.suffix new_name = '' current_dict = dict(x.split(\"-\") for x in current_name.split(\"_\") if len(x.split('-')) == 2) suffix_list = [x for x in current_name.split(\"_\") if len(x.split('-')) == 1] for current_key in DEFAULT.entityTableKeys: if current_key in current_dict and new_name != '': new_name += f\"_{current_key}-{current_dict[current_key]}\" elif current_key in current_dict: new_name = f\"{current_key}-{current_dict[current_key]}\" current_dict.pop(current_key, None) for current_key in current_dict: new_name += f\"_{current_key}-{current_dict[current_key]}\" if current_dict: self.logger.warning(\"Entity \\\"{}\\\"\".format(list(current_dict.keys())) + \" is not a valid BIDS entity.\") new_name += f\"_{'_'.join(suffix_list)}\" # Allow multiple single keys (without value) if len(suffix_list) != 1: self.logger.warning(\"There was more than one suffix found \" f\"({suffix_list}). This is not BIDS \" \"compliant. Make sure you know what \" \"you are doing.\") if current_name != new_name: self.logger.warning( f\"\"\"\u2705 Filename was reordered according to BIDS entity table order: from: {current_name} to: {new_name}\"\"\") self.dstFile = new_name @property def intendedFor(self): return self._intendedFor @intendedFor.setter def intendedFor(self, value): if isinstance(value, list): self._intendedFor = value else: self._intendedFor = [value] def dstSidecarData(self, intendedForList): \"\"\" \"\"\" data = self.srcSidecar.origData data[\"Dcm2bidsVersion\"] = __version__ # intendedFor key if self.intendedFor != [None]: intendedValue = [] for index in self.intendedFor: if index in intendedForList: intendedValue = intendedValue + [intendedForList[index]] else: logging.warning(f\"No id found for IntendedFor value '{index}'.\") logging.warning(f\"No sidecar changes for field IntendedFor will be made for json file {self.dstFile}.json with this id.\") logging.warning(\"Check: https://unfmontreal.github.io/Dcm2Bids/docs/how-to/create-config-file/#id-and-intendedFor.\\n\") data[\"IntendedFor\"] = [item for sublist in intendedValue for item in sublist] # sidecarChanges for key, value in self.sidecarChanges.items(): data[key] = value return data @staticmethod def prepend(value, char=\"_\"): \"\"\" Prepend `char` to `value` if necessary Args: value (str) char (str) \"\"\" if value.strip() == \"\": return \"\" elif value.startswith(char): return value else: return char + value Static methods \u2693\ufe0e prepend \u2693\ufe0e 1 2 3 4 def prepend ( value , char = '_' ) Prepend char to value if necessary Args: value (str) char (str) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @staticmethod def prepend(value, char=\"_\"): \"\"\" Prepend `char` to `value` if necessary Args: value (str) char (str) \"\"\" if value.strip() == \"\": return \"\" elif value.startswith(char): return value else: return char + value Instance variables \u2693\ufe0e 1 customLabels Returns: A string '_ ' 1 dstIntendedFor Return: The destination root inside the BIDS structure for intendedFor 1 dstRoot Return: The destination root inside the BIDS structure 1 id Returns: A string '_ ' 1 intendedFor 1 modalityLabel Returns: A string '_ ' 1 srcRoot Return: The sidecar source root to move 1 suffix The suffix to build filenames Methods \u2693\ufe0e dstSidecarData \u2693\ufe0e 1 2 3 4 def dstSidecarData ( self , intendedForList ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def dstSidecarData(self, intendedForList): \"\"\" \"\"\" data = self.srcSidecar.origData data[\"Dcm2bidsVersion\"] = __version__ # intendedFor key if self.intendedFor != [None]: intendedValue = [] for index in self.intendedFor: if index in intendedForList: intendedValue = intendedValue + [intendedForList[index]] else: logging.warning(f\"No id found for IntendedFor value '{index}'.\") logging.warning(f\"No sidecar changes for field IntendedFor will be made for json file {self.dstFile}.json with this id.\") logging.warning(\"Check: https://unfmontreal.github.io/Dcm2Bids/docs/how-to/create-config-file/#id-and-intendedFor.\\n\") data[\"IntendedFor\"] = [item for sublist in intendedValue for item in sublist] # sidecarChanges for key, value in self.sidecarChanges.items(): data[key] = value return data setDstFile \u2693\ufe0e 1 2 3 def setDstFile ( self ) Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def setDstFile(self): \"\"\" Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html \"\"\" current_name = self.participant.prefix + self.suffix new_name = '' current_dict = dict(x.split(\"-\") for x in current_name.split(\"_\") if len(x.split('-')) == 2) suffix_list = [x for x in current_name.split(\"_\") if len(x.split('-')) == 1] for current_key in DEFAULT.entityTableKeys: if current_key in current_dict and new_name != '': new_name += f\"_{current_key}-{current_dict[current_key]}\" elif current_key in current_dict: new_name = f\"{current_key}-{current_dict[current_key]}\" current_dict.pop(current_key, None) for current_key in current_dict: new_name += f\"_{current_key}-{current_dict[current_key]}\" if current_dict: self.logger.warning(\"Entity \\\"{}\\\"\".format(list(current_dict.keys())) + \" is not a valid BIDS entity.\") new_name += f\"_{'_'.join(suffix_list)}\" # Allow multiple single keys (without value) if len(suffix_list) != 1: self.logger.warning(\"There was more than one suffix found \" f\"({suffix_list}). This is not BIDS \" \"compliant. Make sure you know what \" \"you are doing.\") if current_name != new_name: self.logger.warning( f\"\"\"\u2705 Filename was reordered according to BIDS entity table order: from: {current_name} to: {new_name}\"\"\") self.dstFile = new_name","title":"Acquisition"},{"location":"reference/dcm2bids/acquisition/#module-dcm2bidsacquisition","text":"Participant class View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 # -*- coding: utf-8 -*- \"\"\"Participant class\"\"\" import logging from os.path import join as opj from dcm2bids.utils.utils import DEFAULT from dcm2bids.version import __version__ class Acquisition(object): \"\"\" Class representing an acquisition Args: participant (Participant): A participant object dataType (str): A functional group of MRI data (ex: func, anat ...) modalityLabel (str): The modality of the acquisition (ex: T1w, T2w, bold ...) customLabels (str): Optional labels (ex: task-rest) srcSidecar (Sidecar): Optional sidecar object \"\"\" def __init__( self, participant, dataType, modalityLabel, customLabels=\"\", id=None, srcSidecar=None, sidecarChanges=None, intendedFor=None, IntendedFor=None, **kwargs ): self.logger = logging.getLogger(__name__) self._modalityLabel = \"\" self._customLabels = \"\" self._id = \"\" self._intendedFor = None self.participant = participant self.dataType = dataType self.modalityLabel = modalityLabel self.customLabels = customLabels self.srcSidecar = srcSidecar if sidecarChanges is None: self.sidecarChanges = {} else: self.sidecarChanges = sidecarChanges if intendedFor is None: self.intendedFor = IntendedFor else: self.intendedFor = intendedFor if id is None: self.id = None else: self.id = id self.dstFile = '' def __eq__(self, other): return ( self.dataType == other.dataType and self.participant.prefix == other.participant.prefix and self.suffix == other.suffix ) @property def modalityLabel(self): \"\"\" Returns: A string '_<modalityLabel>' \"\"\" return self._modalityLabel @modalityLabel.setter def modalityLabel(self, modalityLabel): \"\"\" Prepend '_' if necessary\"\"\" self._modalityLabel = self.prepend(modalityLabel) @property def id(self): \"\"\" Returns: A string '_<id>' \"\"\" return self._id @id.setter def id(self, value): self._id = value @property def customLabels(self): \"\"\" Returns: A string '_<customLabels>' \"\"\" return self._customLabels @customLabels.setter def customLabels(self, customLabels): \"\"\" Prepend '_' if necessary\"\"\" self._customLabels = self.prepend(customLabels) @property def suffix(self): \"\"\" The suffix to build filenames Returns: A string '_<modalityLabel>' or '_<customLabels>_<modalityLabel>' \"\"\" if self.customLabels.strip() == \"\": return self.modalityLabel else: return self.customLabels + self.modalityLabel @property def srcRoot(self): \"\"\" Return: The sidecar source root to move \"\"\" if self.srcSidecar: return self.srcSidecar.root else: return None @property def dstRoot(self): \"\"\" Return: The destination root inside the BIDS structure \"\"\" return opj( self.participant.directory, self.dataType, self.dstFile, ) @property def dstIntendedFor(self): \"\"\" Return: The destination root inside the BIDS structure for intendedFor \"\"\" return opj( self.participant.session, self.dataType, self.dstFile, ) def setDstFile(self): \"\"\" Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html \"\"\" current_name = self.participant.prefix + self.suffix new_name = '' current_dict = dict(x.split(\"-\") for x in current_name.split(\"_\") if len(x.split('-')) == 2) suffix_list = [x for x in current_name.split(\"_\") if len(x.split('-')) == 1] for current_key in DEFAULT.entityTableKeys: if current_key in current_dict and new_name != '': new_name += f\"_{current_key}-{current_dict[current_key]}\" elif current_key in current_dict: new_name = f\"{current_key}-{current_dict[current_key]}\" current_dict.pop(current_key, None) for current_key in current_dict: new_name += f\"_{current_key}-{current_dict[current_key]}\" if current_dict: self.logger.warning(\"Entity \\\"{}\\\"\".format(list(current_dict.keys())) + \" is not a valid BIDS entity.\") new_name += f\"_{'_'.join(suffix_list)}\" # Allow multiple single keys (without value) if len(suffix_list) != 1: self.logger.warning(\"There was more than one suffix found \" f\"({suffix_list}). This is not BIDS \" \"compliant. Make sure you know what \" \"you are doing.\") if current_name != new_name: self.logger.warning( f\"\"\"\u2705 Filename was reordered according to BIDS entity table order: from: {current_name} to: {new_name}\"\"\") self.dstFile = new_name @property def intendedFor(self): return self._intendedFor @intendedFor.setter def intendedFor(self, value): if isinstance(value, list): self._intendedFor = value else: self._intendedFor = [value] def dstSidecarData(self, intendedForList): \"\"\" \"\"\" data = self.srcSidecar.origData data[\"Dcm2bidsVersion\"] = __version__ # intendedFor key if self.intendedFor != [None]: intendedValue = [] for index in self.intendedFor: if index in intendedForList: intendedValue = intendedValue + [intendedForList[index]] else: logging.warning(f\"No id found for IntendedFor value '{index}'.\") logging.warning(f\"No sidecar changes for field IntendedFor will be made for json file {self.dstFile}.json with this id.\") logging.warning(\"Check: https://unfmontreal.github.io/Dcm2Bids/docs/how-to/create-config-file/#id-and-intendedFor.\\n\") data[\"IntendedFor\"] = [item for sublist in intendedValue for item in sublist] # sidecarChanges for key, value in self.sidecarChanges.items(): data[key] = value return data @staticmethod def prepend(value, char=\"_\"): \"\"\" Prepend `char` to `value` if necessary Args: value (str) char (str) \"\"\" if value.strip() == \"\": return \"\" elif value.startswith(char): return value else: return char + value","title":"Module dcm2bids.acquisition"},{"location":"reference/dcm2bids/acquisition/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/acquisition/#acquisition","text":"1 2 3 4 5 6 7 8 9 10 11 12 class Acquisition ( participant , dataType , modalityLabel , customLabels = '' , id = None , srcSidecar = None , sidecarChanges = None , intendedFor = None , IntendedFor = None , ** kwargs ) Class representing an acquisition","title":"Acquisition"},{"location":"reference/dcm2bids/acquisition/#attributes","text":"Name Type Description Default participant Participant A participant object None dataType str A functional group of MRI data (ex: func, anat ...) None modalityLabel str The modality of the acquisition (ex: T1w, T2w, bold ...) None customLabels str Optional labels (ex: task-rest) None srcSidecar Sidecar Optional sidecar object None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 class Acquisition(object): \"\"\" Class representing an acquisition Args: participant (Participant): A participant object dataType (str): A functional group of MRI data (ex: func, anat ...) modalityLabel (str): The modality of the acquisition (ex: T1w, T2w, bold ...) customLabels (str): Optional labels (ex: task-rest) srcSidecar (Sidecar): Optional sidecar object \"\"\" def __init__( self, participant, dataType, modalityLabel, customLabels=\"\", id=None, srcSidecar=None, sidecarChanges=None, intendedFor=None, IntendedFor=None, **kwargs ): self.logger = logging.getLogger(__name__) self._modalityLabel = \"\" self._customLabels = \"\" self._id = \"\" self._intendedFor = None self.participant = participant self.dataType = dataType self.modalityLabel = modalityLabel self.customLabels = customLabels self.srcSidecar = srcSidecar if sidecarChanges is None: self.sidecarChanges = {} else: self.sidecarChanges = sidecarChanges if intendedFor is None: self.intendedFor = IntendedFor else: self.intendedFor = intendedFor if id is None: self.id = None else: self.id = id self.dstFile = '' def __eq__(self, other): return ( self.dataType == other.dataType and self.participant.prefix == other.participant.prefix and self.suffix == other.suffix ) @property def modalityLabel(self): \"\"\" Returns: A string '_<modalityLabel>' \"\"\" return self._modalityLabel @modalityLabel.setter def modalityLabel(self, modalityLabel): \"\"\" Prepend '_' if necessary\"\"\" self._modalityLabel = self.prepend(modalityLabel) @property def id(self): \"\"\" Returns: A string '_<id>' \"\"\" return self._id @id.setter def id(self, value): self._id = value @property def customLabels(self): \"\"\" Returns: A string '_<customLabels>' \"\"\" return self._customLabels @customLabels.setter def customLabels(self, customLabels): \"\"\" Prepend '_' if necessary\"\"\" self._customLabels = self.prepend(customLabels) @property def suffix(self): \"\"\" The suffix to build filenames Returns: A string '_<modalityLabel>' or '_<customLabels>_<modalityLabel>' \"\"\" if self.customLabels.strip() == \"\": return self.modalityLabel else: return self.customLabels + self.modalityLabel @property def srcRoot(self): \"\"\" Return: The sidecar source root to move \"\"\" if self.srcSidecar: return self.srcSidecar.root else: return None @property def dstRoot(self): \"\"\" Return: The destination root inside the BIDS structure \"\"\" return opj( self.participant.directory, self.dataType, self.dstFile, ) @property def dstIntendedFor(self): \"\"\" Return: The destination root inside the BIDS structure for intendedFor \"\"\" return opj( self.participant.session, self.dataType, self.dstFile, ) def setDstFile(self): \"\"\" Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html \"\"\" current_name = self.participant.prefix + self.suffix new_name = '' current_dict = dict(x.split(\"-\") for x in current_name.split(\"_\") if len(x.split('-')) == 2) suffix_list = [x for x in current_name.split(\"_\") if len(x.split('-')) == 1] for current_key in DEFAULT.entityTableKeys: if current_key in current_dict and new_name != '': new_name += f\"_{current_key}-{current_dict[current_key]}\" elif current_key in current_dict: new_name = f\"{current_key}-{current_dict[current_key]}\" current_dict.pop(current_key, None) for current_key in current_dict: new_name += f\"_{current_key}-{current_dict[current_key]}\" if current_dict: self.logger.warning(\"Entity \\\"{}\\\"\".format(list(current_dict.keys())) + \" is not a valid BIDS entity.\") new_name += f\"_{'_'.join(suffix_list)}\" # Allow multiple single keys (without value) if len(suffix_list) != 1: self.logger.warning(\"There was more than one suffix found \" f\"({suffix_list}). This is not BIDS \" \"compliant. Make sure you know what \" \"you are doing.\") if current_name != new_name: self.logger.warning( f\"\"\"\u2705 Filename was reordered according to BIDS entity table order: from: {current_name} to: {new_name}\"\"\") self.dstFile = new_name @property def intendedFor(self): return self._intendedFor @intendedFor.setter def intendedFor(self, value): if isinstance(value, list): self._intendedFor = value else: self._intendedFor = [value] def dstSidecarData(self, intendedForList): \"\"\" \"\"\" data = self.srcSidecar.origData data[\"Dcm2bidsVersion\"] = __version__ # intendedFor key if self.intendedFor != [None]: intendedValue = [] for index in self.intendedFor: if index in intendedForList: intendedValue = intendedValue + [intendedForList[index]] else: logging.warning(f\"No id found for IntendedFor value '{index}'.\") logging.warning(f\"No sidecar changes for field IntendedFor will be made for json file {self.dstFile}.json with this id.\") logging.warning(\"Check: https://unfmontreal.github.io/Dcm2Bids/docs/how-to/create-config-file/#id-and-intendedFor.\\n\") data[\"IntendedFor\"] = [item for sublist in intendedValue for item in sublist] # sidecarChanges for key, value in self.sidecarChanges.items(): data[key] = value return data @staticmethod def prepend(value, char=\"_\"): \"\"\" Prepend `char` to `value` if necessary Args: value (str) char (str) \"\"\" if value.strip() == \"\": return \"\" elif value.startswith(char): return value else: return char + value","title":"Attributes"},{"location":"reference/dcm2bids/acquisition/#static-methods","text":"","title":"Static methods"},{"location":"reference/dcm2bids/acquisition/#prepend","text":"1 2 3 4 def prepend ( value , char = '_' ) Prepend char to value if necessary Args: value (str) char (str) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @staticmethod def prepend(value, char=\"_\"): \"\"\" Prepend `char` to `value` if necessary Args: value (str) char (str) \"\"\" if value.strip() == \"\": return \"\" elif value.startswith(char): return value else: return char + value","title":"prepend"},{"location":"reference/dcm2bids/acquisition/#instance-variables","text":"1 customLabels Returns: A string '_ ' 1 dstIntendedFor Return: The destination root inside the BIDS structure for intendedFor 1 dstRoot Return: The destination root inside the BIDS structure 1 id Returns: A string '_ ' 1 intendedFor 1 modalityLabel Returns: A string '_ ' 1 srcRoot Return: The sidecar source root to move 1 suffix The suffix to build filenames","title":"Instance variables"},{"location":"reference/dcm2bids/acquisition/#methods","text":"","title":"Methods"},{"location":"reference/dcm2bids/acquisition/#dstsidecardata","text":"1 2 3 4 def dstSidecarData ( self , intendedForList ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def dstSidecarData(self, intendedForList): \"\"\" \"\"\" data = self.srcSidecar.origData data[\"Dcm2bidsVersion\"] = __version__ # intendedFor key if self.intendedFor != [None]: intendedValue = [] for index in self.intendedFor: if index in intendedForList: intendedValue = intendedValue + [intendedForList[index]] else: logging.warning(f\"No id found for IntendedFor value '{index}'.\") logging.warning(f\"No sidecar changes for field IntendedFor will be made for json file {self.dstFile}.json with this id.\") logging.warning(\"Check: https://unfmontreal.github.io/Dcm2Bids/docs/how-to/create-config-file/#id-and-intendedFor.\\n\") data[\"IntendedFor\"] = [item for sublist in intendedValue for item in sublist] # sidecarChanges for key, value in self.sidecarChanges.items(): data[key] = value return data","title":"dstSidecarData"},{"location":"reference/dcm2bids/acquisition/#setdstfile","text":"1 2 3 def setDstFile ( self ) Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def setDstFile(self): \"\"\" Return: The destination filename formatted following the v1.7.0 BIDS entity key table https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html \"\"\" current_name = self.participant.prefix + self.suffix new_name = '' current_dict = dict(x.split(\"-\") for x in current_name.split(\"_\") if len(x.split('-')) == 2) suffix_list = [x for x in current_name.split(\"_\") if len(x.split('-')) == 1] for current_key in DEFAULT.entityTableKeys: if current_key in current_dict and new_name != '': new_name += f\"_{current_key}-{current_dict[current_key]}\" elif current_key in current_dict: new_name = f\"{current_key}-{current_dict[current_key]}\" current_dict.pop(current_key, None) for current_key in current_dict: new_name += f\"_{current_key}-{current_dict[current_key]}\" if current_dict: self.logger.warning(\"Entity \\\"{}\\\"\".format(list(current_dict.keys())) + \" is not a valid BIDS entity.\") new_name += f\"_{'_'.join(suffix_list)}\" # Allow multiple single keys (without value) if len(suffix_list) != 1: self.logger.warning(\"There was more than one suffix found \" f\"({suffix_list}). This is not BIDS \" \"compliant. Make sure you know what \" \"you are doing.\") if current_name != new_name: self.logger.warning( f\"\"\"\u2705 Filename was reordered according to BIDS entity table order: from: {current_name} to: {new_name}\"\"\") self.dstFile = new_name","title":"setDstFile"},{"location":"reference/dcm2bids/dcm2bids_gen/","text":"Module dcm2bids.dcm2bids_gen \u2693\ufe0e Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 # -*- coding: utf-8 -*- \"\"\" Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure \"\"\" import logging import os from pathlib import Path import platform import sys from datetime import datetime from glob import glob from dcm2bids.dcm2niix_gen import Dcm2niixGen from dcm2bids.utils.logger import setup_logging from dcm2bids.sidecar import Sidecar, SidecarPairing from dcm2bids.participant import Participant from dcm2bids.utils.utils import DEFAULT, run_shell_command from dcm2bids.utils.io import load_json, save_json, valid_path from dcm2bids.utils.tools import check_latest, dcm2niix_version from dcm2bids.version import __version__ class Dcm2BidsGen(object): \"\"\" Object to handle dcm2bids execution steps Args: dicom_dir (str or list): A list of folder with dicoms to convert participant (str): Label of your participant config (path): Path to a dcm2bids configuration file output_dir (path): Path to the BIDS base folder session (str): Optional label of a session clobber (boolean): Overwrite file if already in BIDS folder forceDcm2niix (boolean): Forces a cleaning of a previous execution of dcm2niix log_level (str): logging level \"\"\" def __init__( self, dicom_dir, participant, config, output_dir=DEFAULT.outputDir, bids_validate=DEFAULT.bids_validate, session=DEFAULT.session, clobber=DEFAULT.clobber, forceDcm2niix=DEFAULT.forceDcm2niix, log_level=DEFAULT.logLevel, **_ ): self._dicomDirs = [] self.dicomDirs = dicom_dir self.bidsDir = valid_path(output_dir, type=\"folder\") self.config = load_json(valid_path(config, type=\"file\")) self.participant = Participant(participant, session) self.clobber = clobber self.bids_validate = bids_validate self.forceDcm2niix = forceDcm2niix self.logLevel = log_level # logging setup self.set_logger() self.logger.info(\"--- dcm2bids start ---\") self.logger.info(\"OS:version: %s\", platform.platform()) self.logger.info(\"python:version: %s\", sys.version.replace(\"\\n\", \"\")) self.logger.info(\"dcm2bids:version: %s\", __version__) self.logger.info(\"dcm2niix:version: %s\", dcm2niix_version()) self.logger.info(\"participant: %s\", self.participant.name) self.logger.info(\"session: %s\", self.participant.session) self.logger.info(\"config: %s\", os.path.realpath(config)) self.logger.info(\"BIDS directory: %s\", os.path.realpath(output_dir)) self.logger.info(\"Validate BIDS: %s\", self.bids_validate) @property def dicomDirs(self): \"\"\"List of DICOMs directories\"\"\" return self._dicomDirs @dicomDirs.setter def dicomDirs(self, value): dicom_dirs = value if isinstance(value, list) else [value] valid_dirs = [valid_path(_dir, \"folder\") for _dir in dicom_dirs] self._dicomDirs = valid_dirs def set_logger(self): \"\"\" Set a basic logger\"\"\" logDir = self.bidsDir / DEFAULT.tmpDirName / \"log\" logFile = logDir / f\"{self.participant.prefix}_{datetime.now().isoformat().replace(':', '')}.log\" logDir.mkdir(parents=True, exist_ok=True) setup_logging(self.logLevel, logFile) self.logger = logging.getLogger(__name__) def run(self): \"\"\"Run dcm2bids\"\"\" dcm2niix = Dcm2niixGen( self.dicomDirs, self.bidsDir, self.participant, self.config.get(\"dcm2niixOptions\", DEFAULT.dcm2niixOptions), ) check_latest() check_latest(\"dcm2niix\") dcm2niix.run(self.forceDcm2niix) sidecars = [] for filename in dcm2niix.sidecarFiles: sidecars.append( Sidecar(filename, self.config.get(\"compKeys\", DEFAULT.compKeys)) ) sidecars = sorted(sidecars) parser = SidecarPairing( sidecars, self.config[\"descriptions\"], self.config.get(\"searchMethod\", DEFAULT.searchMethod), self.config.get(\"caseSensitive\", DEFAULT.caseSensitive) ) parser.build_graph() parser.build_acquisitions(self.participant) parser.find_runs() self.logger.info(\"moving acquisitions into BIDS folder\") intendedForList = {} for acq in parser.acquisitions: acq.setDstFile() intendedForList = self.move(acq, intendedForList) if self.bids_validate: try: self.logger.info(f\"Validate if { self.output_dir} is BIDS valid.\") self.logger.info(\"Use bids-validator version: \") run_shell_command(['bids-validator', '-v']) run_shell_command(['bids-validator', self.bidsDir]) except: self.logger.info(\"The bids-validator does not seem to work properly. \" \"The bids-validator may not been installed on your computer. \" \"Please check: https://github.com/bids-standard/bids-validator#quickstart.\") def move(self, acquisition, intendedForList): \"\"\"Move an acquisition to BIDS format\"\"\" for srcFile in glob(acquisition.srcRoot + \".*\"): ext = Path(srcFile).suffixes ext = [curr_ext for curr_ext in ext if curr_ext in ['.nii', '.gz', '.json', '.bval', '.bvec']] dstFile = (self.bidsDir / acquisition.dstRoot).with_suffix(\"\".join(ext)) dstFile.parent.mkdir(parents=True, exist_ok=True) # checking if destination file exists if dstFile.exists(): self.logger.info(\"'%s' already exists\", dstFile) if self.clobber: self.logger.info(\"Overwriting because of --clobber option\") else: self.logger.info(\"Use --clobber option to overwrite\") continue # Populate intendedFor if '.nii' in ext: if acquisition.id in intendedForList: intendedForList[acquisition.id].append(acquisition.dstIntendedFor + \"\".join(ext)) else: intendedForList[acquisition.id] = [acquisition.dstIntendedFor + \"\".join(ext)] # it's an anat nifti file and the user using a deface script if (self.config.get(\"defaceTpl\") and acquisition.dataType == \"anat\" and \".nii\" in ext): try: os.remove(dstFile) except FileNotFoundError: pass defaceTpl = self.config.get(\"defaceTpl\") cmd = [w.replace('srcFile', srcFile) for w in defaceTpl] cmd = [w.replace('dstFile', dstFile) for w in defaceTpl] run_shell_command(cmd) elif \".json\" in ext: data = acquisition.dstSidecarData(intendedForList) save_json(dstFile, data) os.remove(srcFile) # just move else: os.rename(srcFile, dstFile) return intendedForList Classes \u2693\ufe0e Dcm2BidsGen \u2693\ufe0e 1 2 3 4 5 6 7 8 9 10 11 12 class Dcm2BidsGen ( dicom_dir , participant , config , output_dir = PosixPath ( '/home/runner/work/Dcm2Bids/Dcm2Bids' ), bids_validate = False , session = '' , clobber = False , forceDcm2niix = False , log_level = 'WARNING' , ** _ ) Object to handle dcm2bids execution steps Attributes \u2693\ufe0e Name Type Description Default dicom_dir str or list A list of folder with dicoms to convert None participant str Label of your participant None config path Path to a dcm2bids configuration file None output_dir path Path to the BIDS base folder None session str Optional label of a session None clobber boolean Overwrite file if already in BIDS folder None forceDcm2niix boolean Forces a cleaning of a previous execution of dcm2niix None log_level str logging level None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 class Dcm2BidsGen(object): \"\"\" Object to handle dcm2bids execution steps Args: dicom_dir (str or list): A list of folder with dicoms to convert participant (str): Label of your participant config (path): Path to a dcm2bids configuration file output_dir (path): Path to the BIDS base folder session (str): Optional label of a session clobber (boolean): Overwrite file if already in BIDS folder forceDcm2niix (boolean): Forces a cleaning of a previous execution of dcm2niix log_level (str): logging level \"\"\" def __init__( self, dicom_dir, participant, config, output_dir=DEFAULT.outputDir, bids_validate=DEFAULT.bids_validate, session=DEFAULT.session, clobber=DEFAULT.clobber, forceDcm2niix=DEFAULT.forceDcm2niix, log_level=DEFAULT.logLevel, **_ ): self._dicomDirs = [] self.dicomDirs = dicom_dir self.bidsDir = valid_path(output_dir, type=\"folder\") self.config = load_json(valid_path(config, type=\"file\")) self.participant = Participant(participant, session) self.clobber = clobber self.bids_validate = bids_validate self.forceDcm2niix = forceDcm2niix self.logLevel = log_level # logging setup self.set_logger() self.logger.info(\"--- dcm2bids start ---\") self.logger.info(\"OS:version: %s\", platform.platform()) self.logger.info(\"python:version: %s\", sys.version.replace(\"\\n\", \"\")) self.logger.info(\"dcm2bids:version: %s\", __version__) self.logger.info(\"dcm2niix:version: %s\", dcm2niix_version()) self.logger.info(\"participant: %s\", self.participant.name) self.logger.info(\"session: %s\", self.participant.session) self.logger.info(\"config: %s\", os.path.realpath(config)) self.logger.info(\"BIDS directory: %s\", os.path.realpath(output_dir)) self.logger.info(\"Validate BIDS: %s\", self.bids_validate) @property def dicomDirs(self): \"\"\"List of DICOMs directories\"\"\" return self._dicomDirs @dicomDirs.setter def dicomDirs(self, value): dicom_dirs = value if isinstance(value, list) else [value] valid_dirs = [valid_path(_dir, \"folder\") for _dir in dicom_dirs] self._dicomDirs = valid_dirs def set_logger(self): \"\"\" Set a basic logger\"\"\" logDir = self.bidsDir / DEFAULT.tmpDirName / \"log\" logFile = logDir / f\"{self.participant.prefix}_{datetime.now().isoformat().replace(':', '')}.log\" logDir.mkdir(parents=True, exist_ok=True) setup_logging(self.logLevel, logFile) self.logger = logging.getLogger(__name__) def run(self): \"\"\"Run dcm2bids\"\"\" dcm2niix = Dcm2niixGen( self.dicomDirs, self.bidsDir, self.participant, self.config.get(\"dcm2niixOptions\", DEFAULT.dcm2niixOptions), ) check_latest() check_latest(\"dcm2niix\") dcm2niix.run(self.forceDcm2niix) sidecars = [] for filename in dcm2niix.sidecarFiles: sidecars.append( Sidecar(filename, self.config.get(\"compKeys\", DEFAULT.compKeys)) ) sidecars = sorted(sidecars) parser = SidecarPairing( sidecars, self.config[\"descriptions\"], self.config.get(\"searchMethod\", DEFAULT.searchMethod), self.config.get(\"caseSensitive\", DEFAULT.caseSensitive) ) parser.build_graph() parser.build_acquisitions(self.participant) parser.find_runs() self.logger.info(\"moving acquisitions into BIDS folder\") intendedForList = {} for acq in parser.acquisitions: acq.setDstFile() intendedForList = self.move(acq, intendedForList) if self.bids_validate: try: self.logger.info(f\"Validate if { self.output_dir} is BIDS valid.\") self.logger.info(\"Use bids-validator version: \") run_shell_command(['bids-validator', '-v']) run_shell_command(['bids-validator', self.bidsDir]) except: self.logger.info(\"The bids-validator does not seem to work properly. \" \"The bids-validator may not been installed on your computer. \" \"Please check: https://github.com/bids-standard/bids-validator#quickstart.\") def move(self, acquisition, intendedForList): \"\"\"Move an acquisition to BIDS format\"\"\" for srcFile in glob(acquisition.srcRoot + \".*\"): ext = Path(srcFile).suffixes ext = [curr_ext for curr_ext in ext if curr_ext in ['.nii', '.gz', '.json', '.bval', '.bvec']] dstFile = (self.bidsDir / acquisition.dstRoot).with_suffix(\"\".join(ext)) dstFile.parent.mkdir(parents=True, exist_ok=True) # checking if destination file exists if dstFile.exists(): self.logger.info(\"'%s' already exists\", dstFile) if self.clobber: self.logger.info(\"Overwriting because of --clobber option\") else: self.logger.info(\"Use --clobber option to overwrite\") continue # Populate intendedFor if '.nii' in ext: if acquisition.id in intendedForList: intendedForList[acquisition.id].append(acquisition.dstIntendedFor + \"\".join(ext)) else: intendedForList[acquisition.id] = [acquisition.dstIntendedFor + \"\".join(ext)] # it's an anat nifti file and the user using a deface script if (self.config.get(\"defaceTpl\") and acquisition.dataType == \"anat\" and \".nii\" in ext): try: os.remove(dstFile) except FileNotFoundError: pass defaceTpl = self.config.get(\"defaceTpl\") cmd = [w.replace('srcFile', srcFile) for w in defaceTpl] cmd = [w.replace('dstFile', dstFile) for w in defaceTpl] run_shell_command(cmd) elif \".json\" in ext: data = acquisition.dstSidecarData(intendedForList) save_json(dstFile, data) os.remove(srcFile) # just move else: os.rename(srcFile, dstFile) return intendedForList Instance variables \u2693\ufe0e 1 dicomDirs List of DICOMs directories Methods \u2693\ufe0e move \u2693\ufe0e 1 2 3 4 5 def move ( self , acquisition , intendedForList ) Move an acquisition to BIDS format View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def move(self, acquisition, intendedForList): \"\"\"Move an acquisition to BIDS format\"\"\" for srcFile in glob(acquisition.srcRoot + \".*\"): ext = Path(srcFile).suffixes ext = [curr_ext for curr_ext in ext if curr_ext in ['.nii', '.gz', '.json', '.bval', '.bvec']] dstFile = (self.bidsDir / acquisition.dstRoot).with_suffix(\"\".join(ext)) dstFile.parent.mkdir(parents=True, exist_ok=True) # checking if destination file exists if dstFile.exists(): self.logger.info(\"'%s' already exists\", dstFile) if self.clobber: self.logger.info(\"Overwriting because of --clobber option\") else: self.logger.info(\"Use --clobber option to overwrite\") continue # Populate intendedFor if '.nii' in ext: if acquisition.id in intendedForList: intendedForList[acquisition.id].append(acquisition.dstIntendedFor + \"\".join(ext)) else: intendedForList[acquisition.id] = [acquisition.dstIntendedFor + \"\".join(ext)] # it's an anat nifti file and the user using a deface script if (self.config.get(\"defaceTpl\") and acquisition.dataType == \"anat\" and \".nii\" in ext): try: os.remove(dstFile) except FileNotFoundError: pass defaceTpl = self.config.get(\"defaceTpl\") cmd = [w.replace('srcFile', srcFile) for w in defaceTpl] cmd = [w.replace('dstFile', dstFile) for w in defaceTpl] run_shell_command(cmd) elif \".json\" in ext: data = acquisition.dstSidecarData(intendedForList) save_json(dstFile, data) os.remove(srcFile) # just move else: os.rename(srcFile, dstFile) return intendedForList run \u2693\ufe0e 1 2 3 def run ( self ) Run dcm2bids View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def run(self): \"\"\"Run dcm2bids\"\"\" dcm2niix = Dcm2niixGen( self.dicomDirs, self.bidsDir, self.participant, self.config.get(\"dcm2niixOptions\", DEFAULT.dcm2niixOptions), ) check_latest() check_latest(\"dcm2niix\") dcm2niix.run(self.forceDcm2niix) sidecars = [] for filename in dcm2niix.sidecarFiles: sidecars.append( Sidecar(filename, self.config.get(\"compKeys\", DEFAULT.compKeys)) ) sidecars = sorted(sidecars) parser = SidecarPairing( sidecars, self.config[\"descriptions\"], self.config.get(\"searchMethod\", DEFAULT.searchMethod), self.config.get(\"caseSensitive\", DEFAULT.caseSensitive) ) parser.build_graph() parser.build_acquisitions(self.participant) parser.find_runs() self.logger.info(\"moving acquisitions into BIDS folder\") intendedForList = {} for acq in parser.acquisitions: acq.setDstFile() intendedForList = self.move(acq, intendedForList) if self.bids_validate: try: self.logger.info(f\"Validate if { self.output_dir} is BIDS valid.\") self.logger.info(\"Use bids-validator version: \") run_shell_command(['bids-validator', '-v']) run_shell_command(['bids-validator', self.bidsDir]) except: self.logger.info(\"The bids-validator does not seem to work properly. \" \"The bids-validator may not been installed on your computer. \" \"Please check: https://github.com/bids-standard/bids-validator#quickstart.\") set_logger \u2693\ufe0e 1 2 3 def set_logger ( self ) Set a basic logger View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def set_logger(self): \"\"\" Set a basic logger\"\"\" logDir = self.bidsDir / DEFAULT.tmpDirName / \"log\" logFile = logDir / f\"{self.participant.prefix}_{datetime.now().isoformat().replace(':', '')}.log\" logDir.mkdir(parents=True, exist_ok=True) setup_logging(self.logLevel, logFile) self.logger = logging.getLogger(__name__)","title":"Dcm2Bids Gen"},{"location":"reference/dcm2bids/dcm2bids_gen/#module-dcm2bidsdcm2bids_gen","text":"Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 # -*- coding: utf-8 -*- \"\"\" Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure \"\"\" import logging import os from pathlib import Path import platform import sys from datetime import datetime from glob import glob from dcm2bids.dcm2niix_gen import Dcm2niixGen from dcm2bids.utils.logger import setup_logging from dcm2bids.sidecar import Sidecar, SidecarPairing from dcm2bids.participant import Participant from dcm2bids.utils.utils import DEFAULT, run_shell_command from dcm2bids.utils.io import load_json, save_json, valid_path from dcm2bids.utils.tools import check_latest, dcm2niix_version from dcm2bids.version import __version__ class Dcm2BidsGen(object): \"\"\" Object to handle dcm2bids execution steps Args: dicom_dir (str or list): A list of folder with dicoms to convert participant (str): Label of your participant config (path): Path to a dcm2bids configuration file output_dir (path): Path to the BIDS base folder session (str): Optional label of a session clobber (boolean): Overwrite file if already in BIDS folder forceDcm2niix (boolean): Forces a cleaning of a previous execution of dcm2niix log_level (str): logging level \"\"\" def __init__( self, dicom_dir, participant, config, output_dir=DEFAULT.outputDir, bids_validate=DEFAULT.bids_validate, session=DEFAULT.session, clobber=DEFAULT.clobber, forceDcm2niix=DEFAULT.forceDcm2niix, log_level=DEFAULT.logLevel, **_ ): self._dicomDirs = [] self.dicomDirs = dicom_dir self.bidsDir = valid_path(output_dir, type=\"folder\") self.config = load_json(valid_path(config, type=\"file\")) self.participant = Participant(participant, session) self.clobber = clobber self.bids_validate = bids_validate self.forceDcm2niix = forceDcm2niix self.logLevel = log_level # logging setup self.set_logger() self.logger.info(\"--- dcm2bids start ---\") self.logger.info(\"OS:version: %s\", platform.platform()) self.logger.info(\"python:version: %s\", sys.version.replace(\"\\n\", \"\")) self.logger.info(\"dcm2bids:version: %s\", __version__) self.logger.info(\"dcm2niix:version: %s\", dcm2niix_version()) self.logger.info(\"participant: %s\", self.participant.name) self.logger.info(\"session: %s\", self.participant.session) self.logger.info(\"config: %s\", os.path.realpath(config)) self.logger.info(\"BIDS directory: %s\", os.path.realpath(output_dir)) self.logger.info(\"Validate BIDS: %s\", self.bids_validate) @property def dicomDirs(self): \"\"\"List of DICOMs directories\"\"\" return self._dicomDirs @dicomDirs.setter def dicomDirs(self, value): dicom_dirs = value if isinstance(value, list) else [value] valid_dirs = [valid_path(_dir, \"folder\") for _dir in dicom_dirs] self._dicomDirs = valid_dirs def set_logger(self): \"\"\" Set a basic logger\"\"\" logDir = self.bidsDir / DEFAULT.tmpDirName / \"log\" logFile = logDir / f\"{self.participant.prefix}_{datetime.now().isoformat().replace(':', '')}.log\" logDir.mkdir(parents=True, exist_ok=True) setup_logging(self.logLevel, logFile) self.logger = logging.getLogger(__name__) def run(self): \"\"\"Run dcm2bids\"\"\" dcm2niix = Dcm2niixGen( self.dicomDirs, self.bidsDir, self.participant, self.config.get(\"dcm2niixOptions\", DEFAULT.dcm2niixOptions), ) check_latest() check_latest(\"dcm2niix\") dcm2niix.run(self.forceDcm2niix) sidecars = [] for filename in dcm2niix.sidecarFiles: sidecars.append( Sidecar(filename, self.config.get(\"compKeys\", DEFAULT.compKeys)) ) sidecars = sorted(sidecars) parser = SidecarPairing( sidecars, self.config[\"descriptions\"], self.config.get(\"searchMethod\", DEFAULT.searchMethod), self.config.get(\"caseSensitive\", DEFAULT.caseSensitive) ) parser.build_graph() parser.build_acquisitions(self.participant) parser.find_runs() self.logger.info(\"moving acquisitions into BIDS folder\") intendedForList = {} for acq in parser.acquisitions: acq.setDstFile() intendedForList = self.move(acq, intendedForList) if self.bids_validate: try: self.logger.info(f\"Validate if { self.output_dir} is BIDS valid.\") self.logger.info(\"Use bids-validator version: \") run_shell_command(['bids-validator', '-v']) run_shell_command(['bids-validator', self.bidsDir]) except: self.logger.info(\"The bids-validator does not seem to work properly. \" \"The bids-validator may not been installed on your computer. \" \"Please check: https://github.com/bids-standard/bids-validator#quickstart.\") def move(self, acquisition, intendedForList): \"\"\"Move an acquisition to BIDS format\"\"\" for srcFile in glob(acquisition.srcRoot + \".*\"): ext = Path(srcFile).suffixes ext = [curr_ext for curr_ext in ext if curr_ext in ['.nii', '.gz', '.json', '.bval', '.bvec']] dstFile = (self.bidsDir / acquisition.dstRoot).with_suffix(\"\".join(ext)) dstFile.parent.mkdir(parents=True, exist_ok=True) # checking if destination file exists if dstFile.exists(): self.logger.info(\"'%s' already exists\", dstFile) if self.clobber: self.logger.info(\"Overwriting because of --clobber option\") else: self.logger.info(\"Use --clobber option to overwrite\") continue # Populate intendedFor if '.nii' in ext: if acquisition.id in intendedForList: intendedForList[acquisition.id].append(acquisition.dstIntendedFor + \"\".join(ext)) else: intendedForList[acquisition.id] = [acquisition.dstIntendedFor + \"\".join(ext)] # it's an anat nifti file and the user using a deface script if (self.config.get(\"defaceTpl\") and acquisition.dataType == \"anat\" and \".nii\" in ext): try: os.remove(dstFile) except FileNotFoundError: pass defaceTpl = self.config.get(\"defaceTpl\") cmd = [w.replace('srcFile', srcFile) for w in defaceTpl] cmd = [w.replace('dstFile', dstFile) for w in defaceTpl] run_shell_command(cmd) elif \".json\" in ext: data = acquisition.dstSidecarData(intendedForList) save_json(dstFile, data) os.remove(srcFile) # just move else: os.rename(srcFile, dstFile) return intendedForList","title":"Module dcm2bids.dcm2bids_gen"},{"location":"reference/dcm2bids/dcm2bids_gen/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/dcm2bids_gen/#dcm2bidsgen","text":"1 2 3 4 5 6 7 8 9 10 11 12 class Dcm2BidsGen ( dicom_dir , participant , config , output_dir = PosixPath ( '/home/runner/work/Dcm2Bids/Dcm2Bids' ), bids_validate = False , session = '' , clobber = False , forceDcm2niix = False , log_level = 'WARNING' , ** _ ) Object to handle dcm2bids execution steps","title":"Dcm2BidsGen"},{"location":"reference/dcm2bids/dcm2bids_gen/#attributes","text":"Name Type Description Default dicom_dir str or list A list of folder with dicoms to convert None participant str Label of your participant None config path Path to a dcm2bids configuration file None output_dir path Path to the BIDS base folder None session str Optional label of a session None clobber boolean Overwrite file if already in BIDS folder None forceDcm2niix boolean Forces a cleaning of a previous execution of dcm2niix None log_level str logging level None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 class Dcm2BidsGen(object): \"\"\" Object to handle dcm2bids execution steps Args: dicom_dir (str or list): A list of folder with dicoms to convert participant (str): Label of your participant config (path): Path to a dcm2bids configuration file output_dir (path): Path to the BIDS base folder session (str): Optional label of a session clobber (boolean): Overwrite file if already in BIDS folder forceDcm2niix (boolean): Forces a cleaning of a previous execution of dcm2niix log_level (str): logging level \"\"\" def __init__( self, dicom_dir, participant, config, output_dir=DEFAULT.outputDir, bids_validate=DEFAULT.bids_validate, session=DEFAULT.session, clobber=DEFAULT.clobber, forceDcm2niix=DEFAULT.forceDcm2niix, log_level=DEFAULT.logLevel, **_ ): self._dicomDirs = [] self.dicomDirs = dicom_dir self.bidsDir = valid_path(output_dir, type=\"folder\") self.config = load_json(valid_path(config, type=\"file\")) self.participant = Participant(participant, session) self.clobber = clobber self.bids_validate = bids_validate self.forceDcm2niix = forceDcm2niix self.logLevel = log_level # logging setup self.set_logger() self.logger.info(\"--- dcm2bids start ---\") self.logger.info(\"OS:version: %s\", platform.platform()) self.logger.info(\"python:version: %s\", sys.version.replace(\"\\n\", \"\")) self.logger.info(\"dcm2bids:version: %s\", __version__) self.logger.info(\"dcm2niix:version: %s\", dcm2niix_version()) self.logger.info(\"participant: %s\", self.participant.name) self.logger.info(\"session: %s\", self.participant.session) self.logger.info(\"config: %s\", os.path.realpath(config)) self.logger.info(\"BIDS directory: %s\", os.path.realpath(output_dir)) self.logger.info(\"Validate BIDS: %s\", self.bids_validate) @property def dicomDirs(self): \"\"\"List of DICOMs directories\"\"\" return self._dicomDirs @dicomDirs.setter def dicomDirs(self, value): dicom_dirs = value if isinstance(value, list) else [value] valid_dirs = [valid_path(_dir, \"folder\") for _dir in dicom_dirs] self._dicomDirs = valid_dirs def set_logger(self): \"\"\" Set a basic logger\"\"\" logDir = self.bidsDir / DEFAULT.tmpDirName / \"log\" logFile = logDir / f\"{self.participant.prefix}_{datetime.now().isoformat().replace(':', '')}.log\" logDir.mkdir(parents=True, exist_ok=True) setup_logging(self.logLevel, logFile) self.logger = logging.getLogger(__name__) def run(self): \"\"\"Run dcm2bids\"\"\" dcm2niix = Dcm2niixGen( self.dicomDirs, self.bidsDir, self.participant, self.config.get(\"dcm2niixOptions\", DEFAULT.dcm2niixOptions), ) check_latest() check_latest(\"dcm2niix\") dcm2niix.run(self.forceDcm2niix) sidecars = [] for filename in dcm2niix.sidecarFiles: sidecars.append( Sidecar(filename, self.config.get(\"compKeys\", DEFAULT.compKeys)) ) sidecars = sorted(sidecars) parser = SidecarPairing( sidecars, self.config[\"descriptions\"], self.config.get(\"searchMethod\", DEFAULT.searchMethod), self.config.get(\"caseSensitive\", DEFAULT.caseSensitive) ) parser.build_graph() parser.build_acquisitions(self.participant) parser.find_runs() self.logger.info(\"moving acquisitions into BIDS folder\") intendedForList = {} for acq in parser.acquisitions: acq.setDstFile() intendedForList = self.move(acq, intendedForList) if self.bids_validate: try: self.logger.info(f\"Validate if { self.output_dir} is BIDS valid.\") self.logger.info(\"Use bids-validator version: \") run_shell_command(['bids-validator', '-v']) run_shell_command(['bids-validator', self.bidsDir]) except: self.logger.info(\"The bids-validator does not seem to work properly. \" \"The bids-validator may not been installed on your computer. \" \"Please check: https://github.com/bids-standard/bids-validator#quickstart.\") def move(self, acquisition, intendedForList): \"\"\"Move an acquisition to BIDS format\"\"\" for srcFile in glob(acquisition.srcRoot + \".*\"): ext = Path(srcFile).suffixes ext = [curr_ext for curr_ext in ext if curr_ext in ['.nii', '.gz', '.json', '.bval', '.bvec']] dstFile = (self.bidsDir / acquisition.dstRoot).with_suffix(\"\".join(ext)) dstFile.parent.mkdir(parents=True, exist_ok=True) # checking if destination file exists if dstFile.exists(): self.logger.info(\"'%s' already exists\", dstFile) if self.clobber: self.logger.info(\"Overwriting because of --clobber option\") else: self.logger.info(\"Use --clobber option to overwrite\") continue # Populate intendedFor if '.nii' in ext: if acquisition.id in intendedForList: intendedForList[acquisition.id].append(acquisition.dstIntendedFor + \"\".join(ext)) else: intendedForList[acquisition.id] = [acquisition.dstIntendedFor + \"\".join(ext)] # it's an anat nifti file and the user using a deface script if (self.config.get(\"defaceTpl\") and acquisition.dataType == \"anat\" and \".nii\" in ext): try: os.remove(dstFile) except FileNotFoundError: pass defaceTpl = self.config.get(\"defaceTpl\") cmd = [w.replace('srcFile', srcFile) for w in defaceTpl] cmd = [w.replace('dstFile', dstFile) for w in defaceTpl] run_shell_command(cmd) elif \".json\" in ext: data = acquisition.dstSidecarData(intendedForList) save_json(dstFile, data) os.remove(srcFile) # just move else: os.rename(srcFile, dstFile) return intendedForList","title":"Attributes"},{"location":"reference/dcm2bids/dcm2bids_gen/#instance-variables","text":"1 dicomDirs List of DICOMs directories","title":"Instance variables"},{"location":"reference/dcm2bids/dcm2bids_gen/#methods","text":"","title":"Methods"},{"location":"reference/dcm2bids/dcm2bids_gen/#move","text":"1 2 3 4 5 def move ( self , acquisition , intendedForList ) Move an acquisition to BIDS format View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def move(self, acquisition, intendedForList): \"\"\"Move an acquisition to BIDS format\"\"\" for srcFile in glob(acquisition.srcRoot + \".*\"): ext = Path(srcFile).suffixes ext = [curr_ext for curr_ext in ext if curr_ext in ['.nii', '.gz', '.json', '.bval', '.bvec']] dstFile = (self.bidsDir / acquisition.dstRoot).with_suffix(\"\".join(ext)) dstFile.parent.mkdir(parents=True, exist_ok=True) # checking if destination file exists if dstFile.exists(): self.logger.info(\"'%s' already exists\", dstFile) if self.clobber: self.logger.info(\"Overwriting because of --clobber option\") else: self.logger.info(\"Use --clobber option to overwrite\") continue # Populate intendedFor if '.nii' in ext: if acquisition.id in intendedForList: intendedForList[acquisition.id].append(acquisition.dstIntendedFor + \"\".join(ext)) else: intendedForList[acquisition.id] = [acquisition.dstIntendedFor + \"\".join(ext)] # it's an anat nifti file and the user using a deface script if (self.config.get(\"defaceTpl\") and acquisition.dataType == \"anat\" and \".nii\" in ext): try: os.remove(dstFile) except FileNotFoundError: pass defaceTpl = self.config.get(\"defaceTpl\") cmd = [w.replace('srcFile', srcFile) for w in defaceTpl] cmd = [w.replace('dstFile', dstFile) for w in defaceTpl] run_shell_command(cmd) elif \".json\" in ext: data = acquisition.dstSidecarData(intendedForList) save_json(dstFile, data) os.remove(srcFile) # just move else: os.rename(srcFile, dstFile) return intendedForList","title":"move"},{"location":"reference/dcm2bids/dcm2bids_gen/#run","text":"1 2 3 def run ( self ) Run dcm2bids View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def run(self): \"\"\"Run dcm2bids\"\"\" dcm2niix = Dcm2niixGen( self.dicomDirs, self.bidsDir, self.participant, self.config.get(\"dcm2niixOptions\", DEFAULT.dcm2niixOptions), ) check_latest() check_latest(\"dcm2niix\") dcm2niix.run(self.forceDcm2niix) sidecars = [] for filename in dcm2niix.sidecarFiles: sidecars.append( Sidecar(filename, self.config.get(\"compKeys\", DEFAULT.compKeys)) ) sidecars = sorted(sidecars) parser = SidecarPairing( sidecars, self.config[\"descriptions\"], self.config.get(\"searchMethod\", DEFAULT.searchMethod), self.config.get(\"caseSensitive\", DEFAULT.caseSensitive) ) parser.build_graph() parser.build_acquisitions(self.participant) parser.find_runs() self.logger.info(\"moving acquisitions into BIDS folder\") intendedForList = {} for acq in parser.acquisitions: acq.setDstFile() intendedForList = self.move(acq, intendedForList) if self.bids_validate: try: self.logger.info(f\"Validate if { self.output_dir} is BIDS valid.\") self.logger.info(\"Use bids-validator version: \") run_shell_command(['bids-validator', '-v']) run_shell_command(['bids-validator', self.bidsDir]) except: self.logger.info(\"The bids-validator does not seem to work properly. \" \"The bids-validator may not been installed on your computer. \" \"Please check: https://github.com/bids-standard/bids-validator#quickstart.\")","title":"run"},{"location":"reference/dcm2bids/dcm2bids_gen/#set_logger","text":"1 2 3 def set_logger ( self ) Set a basic logger View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def set_logger(self): \"\"\" Set a basic logger\"\"\" logDir = self.bidsDir / DEFAULT.tmpDirName / \"log\" logFile = logDir / f\"{self.participant.prefix}_{datetime.now().isoformat().replace(':', '')}.log\" logDir.mkdir(parents=True, exist_ok=True) setup_logging(self.logLevel, logFile) self.logger = logging.getLogger(__name__)","title":"set_logger"},{"location":"reference/dcm2bids/dcm2niix_gen/","text":"Module dcm2bids.dcm2niix_gen \u2693\ufe0e Dcm2niix class View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 # -*- coding: utf-8 -*- \"\"\"Dcm2niix class\"\"\" import logging import os import shlex import shutil from glob import glob from dcm2bids.utils.utils import DEFAULT, run_shell_command class Dcm2niixGen(object): \"\"\" Object to handle dcm2niix execution Args: dicomDirs (list): A list of folder with dicoms to convert bidsDir (str): A path to the root BIDS directory participant: Optional Participant object options (str): Optional arguments for dcm2niix Properties: sidecars (list): A list of sidecar path created by dcm2niix \"\"\" def __init__( self, dicomDirs, bidsDir, participant=None, options=DEFAULT.dcm2niixOptions ): self.logger = logging.getLogger(__name__) self.sidecarsFiles = [] self.dicomDirs = dicomDirs self.bidsDir = bidsDir self.participant = participant self.options = options @property def outputDir(self): \"\"\" Returns: A directory to save all the output files of dcm2niix \"\"\" tmpDir = self.participant.prefix if self.participant else DEFAULT.helperDir return self.bidsDir / DEFAULT.tmpDirName / tmpDir def run(self, force=False): \"\"\" Run dcm2niix if necessary Args: force (boolean): Forces a cleaning of a previous execution of dcm2niix Sets: sidecarsFiles (list): A list of sidecar path created by dcm2niix \"\"\" try: oldOutput = os.listdir(self.outputDir) != [] except: oldOutput = False if oldOutput and force: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"'force' argument is set to True\") self.logger.warning(\"Cleaning the previous directory and running dcm2niix\") shutil.rmtree(self.outputDir, ignore_errors=True) # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() elif oldOutput: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"Use --forceDcm2niix to rerun dcm2niix\") else: # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() self.sidecarFiles = glob(os.path.join(self.outputDir, \"*.json\")) def execute(self): \"\"\" Execute dcm2niix for each directory in dicomDirs \"\"\" for dicomDir in self.dicomDirs: cmd = ['dcm2niix', *shlex.split(self.options), '-o', self.outputDir, dicomDir] output = run_shell_command(cmd) try: output = output.decode() except: pass self.logger.debug(\"\\n%s\", output) self.logger.info(\"Check log file for dcm2niix output\") Classes \u2693\ufe0e Dcm2niixGen \u2693\ufe0e 1 2 3 4 5 6 class Dcm2niixGen ( dicomDirs , bidsDir , participant = None , options = \"-b y -ba y -z y -f ' %3s _ %f _%p_%t'\" ) Object to handle dcm2niix execution Attributes \u2693\ufe0e Name Type Description Default dicomDirs list A list of folder with dicoms to convert None bidsDir str A path to the root BIDS directory None participant None Optional Participant object None options str Optional arguments for dcm2niix Properties: None sidecars list A list of sidecar path created by dcm2niix None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class Dcm2niixGen(object): \"\"\" Object to handle dcm2niix execution Args: dicomDirs (list): A list of folder with dicoms to convert bidsDir (str): A path to the root BIDS directory participant: Optional Participant object options (str): Optional arguments for dcm2niix Properties: sidecars (list): A list of sidecar path created by dcm2niix \"\"\" def __init__( self, dicomDirs, bidsDir, participant=None, options=DEFAULT.dcm2niixOptions ): self.logger = logging.getLogger(__name__) self.sidecarsFiles = [] self.dicomDirs = dicomDirs self.bidsDir = bidsDir self.participant = participant self.options = options @property def outputDir(self): \"\"\" Returns: A directory to save all the output files of dcm2niix \"\"\" tmpDir = self.participant.prefix if self.participant else DEFAULT.helperDir return self.bidsDir / DEFAULT.tmpDirName / tmpDir def run(self, force=False): \"\"\" Run dcm2niix if necessary Args: force (boolean): Forces a cleaning of a previous execution of dcm2niix Sets: sidecarsFiles (list): A list of sidecar path created by dcm2niix \"\"\" try: oldOutput = os.listdir(self.outputDir) != [] except: oldOutput = False if oldOutput and force: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"'force' argument is set to True\") self.logger.warning(\"Cleaning the previous directory and running dcm2niix\") shutil.rmtree(self.outputDir, ignore_errors=True) # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() elif oldOutput: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"Use --forceDcm2niix to rerun dcm2niix\") else: # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() self.sidecarFiles = glob(os.path.join(self.outputDir, \"*.json\")) def execute(self): \"\"\" Execute dcm2niix for each directory in dicomDirs \"\"\" for dicomDir in self.dicomDirs: cmd = ['dcm2niix', *shlex.split(self.options), '-o', self.outputDir, dicomDir] output = run_shell_command(cmd) try: output = output.decode() except: pass self.logger.debug(\"\\n%s\", output) self.logger.info(\"Check log file for dcm2niix output\") Instance variables \u2693\ufe0e 1 outputDir Returns: A directory to save all the output files of dcm2niix Methods \u2693\ufe0e execute \u2693\ufe0e 1 2 3 def execute ( self ) Execute dcm2niix for each directory in dicomDirs View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def execute(self): \"\"\" Execute dcm2niix for each directory in dicomDirs \"\"\" for dicomDir in self.dicomDirs: cmd = ['dcm2niix', *shlex.split(self.options), '-o', self.outputDir, dicomDir] output = run_shell_command(cmd) try: output = output.decode() except: pass self.logger.debug(\"\\n%s\", output) self.logger.info(\"Check log file for dcm2niix output\") run \u2693\ufe0e 1 2 3 4 def run ( self , force = False ) Run dcm2niix if necessary Parameters: Name Type Description Default force boolean Forces a cleaning of a previous execution of dcm2niix Sets: None sidecarsFiles list A list of sidecar path created by dcm2niix None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def run(self, force=False): \"\"\" Run dcm2niix if necessary Args: force (boolean): Forces a cleaning of a previous execution of dcm2niix Sets: sidecarsFiles (list): A list of sidecar path created by dcm2niix \"\"\" try: oldOutput = os.listdir(self.outputDir) != [] except: oldOutput = False if oldOutput and force: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"'force' argument is set to True\") self.logger.warning(\"Cleaning the previous directory and running dcm2niix\") shutil.rmtree(self.outputDir, ignore_errors=True) # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() elif oldOutput: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"Use --forceDcm2niix to rerun dcm2niix\") else: # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() self.sidecarFiles = glob(os.path.join(self.outputDir, \"*.json\"))","title":"Dcm2Niix Gen"},{"location":"reference/dcm2bids/dcm2niix_gen/#module-dcm2bidsdcm2niix_gen","text":"Dcm2niix class View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 # -*- coding: utf-8 -*- \"\"\"Dcm2niix class\"\"\" import logging import os import shlex import shutil from glob import glob from dcm2bids.utils.utils import DEFAULT, run_shell_command class Dcm2niixGen(object): \"\"\" Object to handle dcm2niix execution Args: dicomDirs (list): A list of folder with dicoms to convert bidsDir (str): A path to the root BIDS directory participant: Optional Participant object options (str): Optional arguments for dcm2niix Properties: sidecars (list): A list of sidecar path created by dcm2niix \"\"\" def __init__( self, dicomDirs, bidsDir, participant=None, options=DEFAULT.dcm2niixOptions ): self.logger = logging.getLogger(__name__) self.sidecarsFiles = [] self.dicomDirs = dicomDirs self.bidsDir = bidsDir self.participant = participant self.options = options @property def outputDir(self): \"\"\" Returns: A directory to save all the output files of dcm2niix \"\"\" tmpDir = self.participant.prefix if self.participant else DEFAULT.helperDir return self.bidsDir / DEFAULT.tmpDirName / tmpDir def run(self, force=False): \"\"\" Run dcm2niix if necessary Args: force (boolean): Forces a cleaning of a previous execution of dcm2niix Sets: sidecarsFiles (list): A list of sidecar path created by dcm2niix \"\"\" try: oldOutput = os.listdir(self.outputDir) != [] except: oldOutput = False if oldOutput and force: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"'force' argument is set to True\") self.logger.warning(\"Cleaning the previous directory and running dcm2niix\") shutil.rmtree(self.outputDir, ignore_errors=True) # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() elif oldOutput: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"Use --forceDcm2niix to rerun dcm2niix\") else: # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() self.sidecarFiles = glob(os.path.join(self.outputDir, \"*.json\")) def execute(self): \"\"\" Execute dcm2niix for each directory in dicomDirs \"\"\" for dicomDir in self.dicomDirs: cmd = ['dcm2niix', *shlex.split(self.options), '-o', self.outputDir, dicomDir] output = run_shell_command(cmd) try: output = output.decode() except: pass self.logger.debug(\"\\n%s\", output) self.logger.info(\"Check log file for dcm2niix output\")","title":"Module dcm2bids.dcm2niix_gen"},{"location":"reference/dcm2bids/dcm2niix_gen/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/dcm2niix_gen/#dcm2niixgen","text":"1 2 3 4 5 6 class Dcm2niixGen ( dicomDirs , bidsDir , participant = None , options = \"-b y -ba y -z y -f ' %3s _ %f _%p_%t'\" ) Object to handle dcm2niix execution","title":"Dcm2niixGen"},{"location":"reference/dcm2bids/dcm2niix_gen/#attributes","text":"Name Type Description Default dicomDirs list A list of folder with dicoms to convert None bidsDir str A path to the root BIDS directory None participant None Optional Participant object None options str Optional arguments for dcm2niix Properties: None sidecars list A list of sidecar path created by dcm2niix None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class Dcm2niixGen(object): \"\"\" Object to handle dcm2niix execution Args: dicomDirs (list): A list of folder with dicoms to convert bidsDir (str): A path to the root BIDS directory participant: Optional Participant object options (str): Optional arguments for dcm2niix Properties: sidecars (list): A list of sidecar path created by dcm2niix \"\"\" def __init__( self, dicomDirs, bidsDir, participant=None, options=DEFAULT.dcm2niixOptions ): self.logger = logging.getLogger(__name__) self.sidecarsFiles = [] self.dicomDirs = dicomDirs self.bidsDir = bidsDir self.participant = participant self.options = options @property def outputDir(self): \"\"\" Returns: A directory to save all the output files of dcm2niix \"\"\" tmpDir = self.participant.prefix if self.participant else DEFAULT.helperDir return self.bidsDir / DEFAULT.tmpDirName / tmpDir def run(self, force=False): \"\"\" Run dcm2niix if necessary Args: force (boolean): Forces a cleaning of a previous execution of dcm2niix Sets: sidecarsFiles (list): A list of sidecar path created by dcm2niix \"\"\" try: oldOutput = os.listdir(self.outputDir) != [] except: oldOutput = False if oldOutput and force: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"'force' argument is set to True\") self.logger.warning(\"Cleaning the previous directory and running dcm2niix\") shutil.rmtree(self.outputDir, ignore_errors=True) # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() elif oldOutput: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"Use --forceDcm2niix to rerun dcm2niix\") else: # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() self.sidecarFiles = glob(os.path.join(self.outputDir, \"*.json\")) def execute(self): \"\"\" Execute dcm2niix for each directory in dicomDirs \"\"\" for dicomDir in self.dicomDirs: cmd = ['dcm2niix', *shlex.split(self.options), '-o', self.outputDir, dicomDir] output = run_shell_command(cmd) try: output = output.decode() except: pass self.logger.debug(\"\\n%s\", output) self.logger.info(\"Check log file for dcm2niix output\")","title":"Attributes"},{"location":"reference/dcm2bids/dcm2niix_gen/#instance-variables","text":"1 outputDir Returns: A directory to save all the output files of dcm2niix","title":"Instance variables"},{"location":"reference/dcm2bids/dcm2niix_gen/#methods","text":"","title":"Methods"},{"location":"reference/dcm2bids/dcm2niix_gen/#execute","text":"1 2 3 def execute ( self ) Execute dcm2niix for each directory in dicomDirs View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def execute(self): \"\"\" Execute dcm2niix for each directory in dicomDirs \"\"\" for dicomDir in self.dicomDirs: cmd = ['dcm2niix', *shlex.split(self.options), '-o', self.outputDir, dicomDir] output = run_shell_command(cmd) try: output = output.decode() except: pass self.logger.debug(\"\\n%s\", output) self.logger.info(\"Check log file for dcm2niix output\")","title":"execute"},{"location":"reference/dcm2bids/dcm2niix_gen/#run","text":"1 2 3 4 def run ( self , force = False ) Run dcm2niix if necessary Parameters: Name Type Description Default force boolean Forces a cleaning of a previous execution of dcm2niix Sets: None sidecarsFiles list A list of sidecar path created by dcm2niix None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def run(self, force=False): \"\"\" Run dcm2niix if necessary Args: force (boolean): Forces a cleaning of a previous execution of dcm2niix Sets: sidecarsFiles (list): A list of sidecar path created by dcm2niix \"\"\" try: oldOutput = os.listdir(self.outputDir) != [] except: oldOutput = False if oldOutput and force: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"'force' argument is set to True\") self.logger.warning(\"Cleaning the previous directory and running dcm2niix\") shutil.rmtree(self.outputDir, ignore_errors=True) # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() elif oldOutput: self.logger.warning(\"Previous dcm2niix directory output found:\") self.logger.warning(self.outputDir) self.logger.warning(\"Use --forceDcm2niix to rerun dcm2niix\") else: # os.makedirs(self.outputDir, exist_ok=True) # python2 compatibility if not os.path.exists(self.outputDir): os.makedirs(self.outputDir) self.execute() self.sidecarFiles = glob(os.path.join(self.outputDir, \"*.json\"))","title":"run"},{"location":"reference/dcm2bids/participant/","text":"Module dcm2bids.participant \u2693\ufe0e Participant class View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 # -*- coding: utf-8 -*- \"\"\"Participant class\"\"\" from os.path import join as opj from dcm2bids.utils.utils import DEFAULT class Participant(object): \"\"\" Class representing a participant Args: name (str): Label of your participant session (str): Optional label of a session \"\"\" def __init__(self, name, session=DEFAULT.session): self._name = \"\" self._session = \"\" self.name = name self.session = session @property def name(self): \"\"\" Returns: A string 'sub-<subject_label>' \"\"\" return self._name @name.setter def name(self, name): \"\"\" Prepend 'sub-' if necessary\"\"\" if name.startswith(\"sub-\"): self._name = name else: self._name = \"sub-\" + name @property def session(self): \"\"\" Returns: A string 'ses-<session_label>' \"\"\" return self._session @session.setter def session(self, session): \"\"\" Prepend 'ses-' if necessary\"\"\" if session.strip() == \"\": self._session = \"\" elif session.startswith(\"ses-\"): self._session = session else: self._session = \"ses-\" + session @property def directory(self): \"\"\" The directory of the participant Returns: A path 'sub-<subject_label>' or 'sub-<subject_label>/ses-<session_label>' \"\"\" if self.hasSession(): return opj(self.name, self.session) else: return self.name @property def prefix(self): \"\"\" The prefix to build filenames Returns: A string 'sub-<subject_label>' or 'sub-<subject_label>_ses-<session_label>' \"\"\" if self.hasSession(): return self.name + \"_\" + self.session else: return self.name def hasSession(self): \"\"\" Check if a session is set Returns: Boolean \"\"\" return self.session.strip() != DEFAULT.session Classes \u2693\ufe0e Participant \u2693\ufe0e 1 2 3 4 class Participant ( name , session = '' ) Class representing a participant Attributes \u2693\ufe0e Name Type Description Default name str Label of your participant None session str Optional label of a session None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 class Participant(object): \"\"\" Class representing a participant Args: name (str): Label of your participant session (str): Optional label of a session \"\"\" def __init__(self, name, session=DEFAULT.session): self._name = \"\" self._session = \"\" self.name = name self.session = session @property def name(self): \"\"\" Returns: A string 'sub-<subject_label>' \"\"\" return self._name @name.setter def name(self, name): \"\"\" Prepend 'sub-' if necessary\"\"\" if name.startswith(\"sub-\"): self._name = name else: self._name = \"sub-\" + name @property def session(self): \"\"\" Returns: A string 'ses-<session_label>' \"\"\" return self._session @session.setter def session(self, session): \"\"\" Prepend 'ses-' if necessary\"\"\" if session.strip() == \"\": self._session = \"\" elif session.startswith(\"ses-\"): self._session = session else: self._session = \"ses-\" + session @property def directory(self): \"\"\" The directory of the participant Returns: A path 'sub-<subject_label>' or 'sub-<subject_label>/ses-<session_label>' \"\"\" if self.hasSession(): return opj(self.name, self.session) else: return self.name @property def prefix(self): \"\"\" The prefix to build filenames Returns: A string 'sub-<subject_label>' or 'sub-<subject_label>_ses-<session_label>' \"\"\" if self.hasSession(): return self.name + \"_\" + self.session else: return self.name def hasSession(self): \"\"\" Check if a session is set Returns: Boolean \"\"\" return self.session.strip() != DEFAULT.session Instance variables \u2693\ufe0e 1 directory The directory of the participant 1 name Returns: A string 'sub- ' 1 prefix The prefix to build filenames 1 session Returns: A string 'ses- ' Methods \u2693\ufe0e hasSession \u2693\ufe0e 1 2 3 def hasSession ( self ) Check if a session is set Returns: Type Description None Boolean View Source 1 2 3 4 5 6 7 8 9 10 11 def hasSession(self): \"\"\" Check if a session is set Returns: Boolean \"\"\" return self.session.strip() != DEFAULT.session","title":"Participant"},{"location":"reference/dcm2bids/participant/#module-dcm2bidsparticipant","text":"Participant class View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 # -*- coding: utf-8 -*- \"\"\"Participant class\"\"\" from os.path import join as opj from dcm2bids.utils.utils import DEFAULT class Participant(object): \"\"\" Class representing a participant Args: name (str): Label of your participant session (str): Optional label of a session \"\"\" def __init__(self, name, session=DEFAULT.session): self._name = \"\" self._session = \"\" self.name = name self.session = session @property def name(self): \"\"\" Returns: A string 'sub-<subject_label>' \"\"\" return self._name @name.setter def name(self, name): \"\"\" Prepend 'sub-' if necessary\"\"\" if name.startswith(\"sub-\"): self._name = name else: self._name = \"sub-\" + name @property def session(self): \"\"\" Returns: A string 'ses-<session_label>' \"\"\" return self._session @session.setter def session(self, session): \"\"\" Prepend 'ses-' if necessary\"\"\" if session.strip() == \"\": self._session = \"\" elif session.startswith(\"ses-\"): self._session = session else: self._session = \"ses-\" + session @property def directory(self): \"\"\" The directory of the participant Returns: A path 'sub-<subject_label>' or 'sub-<subject_label>/ses-<session_label>' \"\"\" if self.hasSession(): return opj(self.name, self.session) else: return self.name @property def prefix(self): \"\"\" The prefix to build filenames Returns: A string 'sub-<subject_label>' or 'sub-<subject_label>_ses-<session_label>' \"\"\" if self.hasSession(): return self.name + \"_\" + self.session else: return self.name def hasSession(self): \"\"\" Check if a session is set Returns: Boolean \"\"\" return self.session.strip() != DEFAULT.session","title":"Module dcm2bids.participant"},{"location":"reference/dcm2bids/participant/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/participant/#participant","text":"1 2 3 4 class Participant ( name , session = '' ) Class representing a participant","title":"Participant"},{"location":"reference/dcm2bids/participant/#attributes","text":"Name Type Description Default name str Label of your participant None session str Optional label of a session None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 class Participant(object): \"\"\" Class representing a participant Args: name (str): Label of your participant session (str): Optional label of a session \"\"\" def __init__(self, name, session=DEFAULT.session): self._name = \"\" self._session = \"\" self.name = name self.session = session @property def name(self): \"\"\" Returns: A string 'sub-<subject_label>' \"\"\" return self._name @name.setter def name(self, name): \"\"\" Prepend 'sub-' if necessary\"\"\" if name.startswith(\"sub-\"): self._name = name else: self._name = \"sub-\" + name @property def session(self): \"\"\" Returns: A string 'ses-<session_label>' \"\"\" return self._session @session.setter def session(self, session): \"\"\" Prepend 'ses-' if necessary\"\"\" if session.strip() == \"\": self._session = \"\" elif session.startswith(\"ses-\"): self._session = session else: self._session = \"ses-\" + session @property def directory(self): \"\"\" The directory of the participant Returns: A path 'sub-<subject_label>' or 'sub-<subject_label>/ses-<session_label>' \"\"\" if self.hasSession(): return opj(self.name, self.session) else: return self.name @property def prefix(self): \"\"\" The prefix to build filenames Returns: A string 'sub-<subject_label>' or 'sub-<subject_label>_ses-<session_label>' \"\"\" if self.hasSession(): return self.name + \"_\" + self.session else: return self.name def hasSession(self): \"\"\" Check if a session is set Returns: Boolean \"\"\" return self.session.strip() != DEFAULT.session","title":"Attributes"},{"location":"reference/dcm2bids/participant/#instance-variables","text":"1 directory The directory of the participant 1 name Returns: A string 'sub- ' 1 prefix The prefix to build filenames 1 session Returns: A string 'ses- '","title":"Instance variables"},{"location":"reference/dcm2bids/participant/#methods","text":"","title":"Methods"},{"location":"reference/dcm2bids/participant/#hassession","text":"1 2 3 def hasSession ( self ) Check if a session is set Returns: Type Description None Boolean View Source 1 2 3 4 5 6 7 8 9 10 11 def hasSession(self): \"\"\" Check if a session is set Returns: Boolean \"\"\" return self.session.strip() != DEFAULT.session","title":"hasSession"},{"location":"reference/dcm2bids/sidecar/","text":"Module dcm2bids.sidecar \u2693\ufe0e sidecars classes View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 # -*- coding: utf-8 -*- \"\"\"sidecars classes\"\"\" import itertools import logging import os import re from collections import defaultdict, OrderedDict from fnmatch import fnmatch from dcm2bids.acquisition import Acquisition from dcm2bids.utils.utils import DEFAULT, splitext_ from dcm2bids.utils.io import load_json class Sidecar(object): \"\"\" A sidecar object Args: filename (str): Path of a JSON sidecar keyComp (list): A list of keys from the JSON sidecar to compare sidecars default=[\"SeriesNumber\",\"AcquisitionTime\",\"SideCarFilename\"] \"\"\" def __init__(self, filename, compKeys=DEFAULT.compKeys): self._origData = {} self._data = {} self.filename = filename self.root, _ = splitext_(filename) self.data = filename self.compKeys = compKeys def __lt__(self, other): lts = [] for key in self.compKeys: try: if all(key in d for d in (self.data, other.data)): if self.data.get(key) == other.data.get(key): lts.append(None) else: lts.append(self.data.get(key) < other.data.get(key)) else: lts.append(None) except: lts.append(None) for lt in lts: if lt is not None: return lt def __eq__(self, other): return self.data == other.data def __hash__(self): return hash(self.filename) @property def origData(self): return self._origData @property def data(self): return self._data @data.setter def data(self, filename): \"\"\" Args: filename (path): path of a JSON file Return: A dictionnary of the JSON content plus the SidecarFilename \"\"\" try: data = load_json(filename) except: data = {} self._origData = data.copy() data[\"SidecarFilename\"] = os.path.basename(filename) self._data = data class SidecarPairing(object): \"\"\" Args: sidecars (list): List of Sidecar objects descriptions (list): List of dictionaries describing acquisitions \"\"\" def __init__(self, sidecars, descriptions, searchMethod=DEFAULT.searchMethod, caseSensitive=DEFAULT.caseSensitive): self.logger = logging.getLogger(__name__) self._searchMethod = \"\" self.graph = OrderedDict() self.acquisitions = [] self.sidecars = sidecars self.descriptions = descriptions self.searchMethod = searchMethod self.caseSensitive = caseSensitive @property def searchMethod(self): return self._searchMethod @searchMethod.setter def searchMethod(self, value): \"\"\" Checks if the search method is implemented Warns the user if not and fall back to default \"\"\" if value in DEFAULT.searchMethodChoices: self._searchMethod = value else: self._searchMethod = DEFAULT.searchMethod self.logger.warning(\"'%s' is not a search method implemented\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.searchMethod ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.searchMethodChoices ) @property def caseSensitive(self): return self._caseSensitive @caseSensitive.setter def caseSensitive(self, value): if isinstance(value, bool): self._caseSensitive = value else: self._caseSensitive = DEFAULT.caseSensitive self.logger.warning(\"'%s' is not a boolean\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.caseSensitive ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.caseSensitive ) def build_graph(self): \"\"\" Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: A graph (OrderedDict) \"\"\" graph = OrderedDict((_, []) for _ in self.sidecars) possibleLinks = itertools.product(self.sidecars, self.descriptions) for sidecar, description in possibleLinks: criteria = description.get(\"criteria\", None) if criteria and self.isLink(sidecar.data, criteria): graph[sidecar].append(description) self.graph = graph return graph def isLink(self, data, criteria): \"\"\" Args: data (dict): Dictionnary data of a sidecar criteria (dict): Dictionnary criteria Returns: boolean \"\"\" def compare(name, pattern): name = str(name) if self.searchMethod == \"re\": return bool(re.match(pattern, name)) else: pattern = str(pattern) if not self.caseSensitive: name = name.lower() pattern = pattern.lower() return fnmatch(name, pattern) result = [] for tag, pattern in criteria.items(): name = data.get(tag, '') if isinstance(name, list): try: subResult = [len(name) == len(pattern), isinstance(pattern, list)] for subName, subPattern in zip(name, pattern): subResult.append(compare(subName, subPattern)) except: subResult = [False] result.append(all(subResult)) else: result.append(compare(name, pattern)) return all(result) def build_acquisitions(self, participant): \"\"\" Args: participant (Participant): Participant object to create acquisitions Returns: A list of acquisition objects \"\"\" acquisitions = [] acquisitions_intendedFor = [] self.logger.info(\"Sidecars pairing:\") for sidecar, valid_descriptions in self.graph.items(): sidecarName = os.path.basename(sidecar.root) # only one description for the sidecar if len(valid_descriptions) == 1: desc = valid_descriptions[0] acq = Acquisition(participant, srcSidecar=sidecar, **desc) acq.setDstFile() if acq.intendedFor != [None]: acquisitions_intendedFor.append(acq) else: acquisitions.append(acq) self.logger.info(\"%s <- %s\", acq.suffix, sidecarName) # sidecar with no link elif len(valid_descriptions) == 0: self.logger.info(\"No Pairing <- %s\", sidecarName) # sidecar with several links else: self.logger.warning(\"Several Pairing <- %s\", sidecarName) for desc in valid_descriptions: acq = Acquisition(participant, **desc) self.logger.warning(\" -> %s\", acq.suffix) self.acquisitions = acquisitions + acquisitions_intendedFor return self.acquisitions def find_runs(self): \"\"\" Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition \"\"\" def duplicates(seq): \"\"\" Find duplicate items in a list Args: seq (list) Yield: A tuple of 2 items (item, list of index) ref: http://stackoverflow.com/a/5419576 \"\"\" tally = defaultdict(list) for i, item in enumerate(seq): tally[item].append(i) for key, locs in tally.items(): if len(locs) > 1: yield key, locs dstRoots = [_.dstRoot for _ in self.acquisitions] for dstRoot, dup in duplicates(dstRoots): self.logger.info(\"%s has %s runs\", dstRoot, len(dup)) self.logger.info(\"Adding 'run' information to the acquisition\") for runNum, acqInd in enumerate(dup): runStr = DEFAULT.runTpl.format(runNum + 1) self.acquisitions[acqInd].customLabels += runStr Classes \u2693\ufe0e Sidecar \u2693\ufe0e 1 2 3 4 class Sidecar ( filename , compKeys = [ 'SeriesNumber' , 'AcquisitionTime' , 'SidecarFilename' ] ) A sidecar object Attributes \u2693\ufe0e Name Type Description Default filename str Path of a JSON sidecar None keyComp list A list of keys from the JSON sidecar to compare sidecars default=[\"SeriesNumber\",\"AcquisitionTime\",\"SideCarFilename\"] None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 class Sidecar(object): \"\"\" A sidecar object Args: filename (str): Path of a JSON sidecar keyComp (list): A list of keys from the JSON sidecar to compare sidecars default=[\"SeriesNumber\",\"AcquisitionTime\",\"SideCarFilename\"] \"\"\" def __init__(self, filename, compKeys=DEFAULT.compKeys): self._origData = {} self._data = {} self.filename = filename self.root, _ = splitext_(filename) self.data = filename self.compKeys = compKeys def __lt__(self, other): lts = [] for key in self.compKeys: try: if all(key in d for d in (self.data, other.data)): if self.data.get(key) == other.data.get(key): lts.append(None) else: lts.append(self.data.get(key) < other.data.get(key)) else: lts.append(None) except: lts.append(None) for lt in lts: if lt is not None: return lt def __eq__(self, other): return self.data == other.data def __hash__(self): return hash(self.filename) @property def origData(self): return self._origData @property def data(self): return self._data @data.setter def data(self, filename): \"\"\" Args: filename (path): path of a JSON file Return: A dictionnary of the JSON content plus the SidecarFilename \"\"\" try: data = load_json(filename) except: data = {} self._origData = data.copy() data[\"SidecarFilename\"] = os.path.basename(filename) self._data = data Instance variables \u2693\ufe0e 1 data 1 origData SidecarPairing \u2693\ufe0e 1 2 3 4 5 6 class SidecarPairing ( sidecars , descriptions , searchMethod = 'fnmatch' , caseSensitive = True ) Args: sidecars (list): List of Sidecar objects descriptions (list): List of dictionaries describing acquisitions View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 class SidecarPairing(object): \"\"\" Args: sidecars (list): List of Sidecar objects descriptions (list): List of dictionaries describing acquisitions \"\"\" def __init__(self, sidecars, descriptions, searchMethod=DEFAULT.searchMethod, caseSensitive=DEFAULT.caseSensitive): self.logger = logging.getLogger(__name__) self._searchMethod = \"\" self.graph = OrderedDict() self.acquisitions = [] self.sidecars = sidecars self.descriptions = descriptions self.searchMethod = searchMethod self.caseSensitive = caseSensitive @property def searchMethod(self): return self._searchMethod @searchMethod.setter def searchMethod(self, value): \"\"\" Checks if the search method is implemented Warns the user if not and fall back to default \"\"\" if value in DEFAULT.searchMethodChoices: self._searchMethod = value else: self._searchMethod = DEFAULT.searchMethod self.logger.warning(\"'%s' is not a search method implemented\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.searchMethod ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.searchMethodChoices ) @property def caseSensitive(self): return self._caseSensitive @caseSensitive.setter def caseSensitive(self, value): if isinstance(value, bool): self._caseSensitive = value else: self._caseSensitive = DEFAULT.caseSensitive self.logger.warning(\"'%s' is not a boolean\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.caseSensitive ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.caseSensitive ) def build_graph(self): \"\"\" Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: A graph (OrderedDict) \"\"\" graph = OrderedDict((_, []) for _ in self.sidecars) possibleLinks = itertools.product(self.sidecars, self.descriptions) for sidecar, description in possibleLinks: criteria = description.get(\"criteria\", None) if criteria and self.isLink(sidecar.data, criteria): graph[sidecar].append(description) self.graph = graph return graph def isLink(self, data, criteria): \"\"\" Args: data (dict): Dictionnary data of a sidecar criteria (dict): Dictionnary criteria Returns: boolean \"\"\" def compare(name, pattern): name = str(name) if self.searchMethod == \"re\": return bool(re.match(pattern, name)) else: pattern = str(pattern) if not self.caseSensitive: name = name.lower() pattern = pattern.lower() return fnmatch(name, pattern) result = [] for tag, pattern in criteria.items(): name = data.get(tag, '') if isinstance(name, list): try: subResult = [len(name) == len(pattern), isinstance(pattern, list)] for subName, subPattern in zip(name, pattern): subResult.append(compare(subName, subPattern)) except: subResult = [False] result.append(all(subResult)) else: result.append(compare(name, pattern)) return all(result) def build_acquisitions(self, participant): \"\"\" Args: participant (Participant): Participant object to create acquisitions Returns: A list of acquisition objects \"\"\" acquisitions = [] acquisitions_intendedFor = [] self.logger.info(\"Sidecars pairing:\") for sidecar, valid_descriptions in self.graph.items(): sidecarName = os.path.basename(sidecar.root) # only one description for the sidecar if len(valid_descriptions) == 1: desc = valid_descriptions[0] acq = Acquisition(participant, srcSidecar=sidecar, **desc) acq.setDstFile() if acq.intendedFor != [None]: acquisitions_intendedFor.append(acq) else: acquisitions.append(acq) self.logger.info(\"%s <- %s\", acq.suffix, sidecarName) # sidecar with no link elif len(valid_descriptions) == 0: self.logger.info(\"No Pairing <- %s\", sidecarName) # sidecar with several links else: self.logger.warning(\"Several Pairing <- %s\", sidecarName) for desc in valid_descriptions: acq = Acquisition(participant, **desc) self.logger.warning(\" -> %s\", acq.suffix) self.acquisitions = acquisitions + acquisitions_intendedFor return self.acquisitions def find_runs(self): \"\"\" Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition \"\"\" def duplicates(seq): \"\"\" Find duplicate items in a list Args: seq (list) Yield: A tuple of 2 items (item, list of index) ref: http://stackoverflow.com/a/5419576 \"\"\" tally = defaultdict(list) for i, item in enumerate(seq): tally[item].append(i) for key, locs in tally.items(): if len(locs) > 1: yield key, locs dstRoots = [_.dstRoot for _ in self.acquisitions] for dstRoot, dup in duplicates(dstRoots): self.logger.info(\"%s has %s runs\", dstRoot, len(dup)) self.logger.info(\"Adding 'run' information to the acquisition\") for runNum, acqInd in enumerate(dup): runStr = DEFAULT.runTpl.format(runNum + 1) self.acquisitions[acqInd].customLabels += runStr Instance variables \u2693\ufe0e 1 caseSensitive 1 searchMethod Methods \u2693\ufe0e build_acquisitions \u2693\ufe0e 1 2 3 4 def build_acquisitions ( self , participant ) Parameters: Name Type Description Default participant Participant Participant object to create acquisitions None Returns: Type Description None A list of acquisition objects View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def build_acquisitions(self, participant): \"\"\" Args: participant (Participant): Participant object to create acquisitions Returns: A list of acquisition objects \"\"\" acquisitions = [] acquisitions_intendedFor = [] self.logger.info(\"Sidecars pairing:\") for sidecar, valid_descriptions in self.graph.items(): sidecarName = os.path.basename(sidecar.root) # only one description for the sidecar if len(valid_descriptions) == 1: desc = valid_descriptions[0] acq = Acquisition(participant, srcSidecar=sidecar, **desc) acq.setDstFile() if acq.intendedFor != [None]: acquisitions_intendedFor.append(acq) else: acquisitions.append(acq) self.logger.info(\"%s <- %s\", acq.suffix, sidecarName) # sidecar with no link elif len(valid_descriptions) == 0: self.logger.info(\"No Pairing <- %s\", sidecarName) # sidecar with several links else: self.logger.warning(\"Several Pairing <- %s\", sidecarName) for desc in valid_descriptions: acq = Acquisition(participant, **desc) self.logger.warning(\" -> %s\", acq.suffix) self.acquisitions = acquisitions + acquisitions_intendedFor return self.acquisitions build_graph \u2693\ufe0e 1 2 3 def build_graph ( self ) Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: Type Description None A graph (OrderedDict) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def build_graph(self): \"\"\" Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: A graph (OrderedDict) \"\"\" graph = OrderedDict((_, []) for _ in self.sidecars) possibleLinks = itertools.product(self.sidecars, self.descriptions) for sidecar, description in possibleLinks: criteria = description.get(\"criteria\", None) if criteria and self.isLink(sidecar.data, criteria): graph[sidecar].append(description) self.graph = graph return graph find_runs \u2693\ufe0e 1 2 3 def find_runs ( self ) Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def find_runs(self): \"\"\" Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition \"\"\" def duplicates(seq): \"\"\" Find duplicate items in a list Args: seq (list) Yield: A tuple of 2 items (item, list of index) ref: http://stackoverflow.com/a/5419576 \"\"\" tally = defaultdict(list) for i, item in enumerate(seq): tally[item].append(i) for key, locs in tally.items(): if len(locs) > 1: yield key, locs dstRoots = [_.dstRoot for _ in self.acquisitions] for dstRoot, dup in duplicates(dstRoots): self.logger.info(\"%s has %s runs\", dstRoot, len(dup)) self.logger.info(\"Adding 'run' information to the acquisition\") for runNum, acqInd in enumerate(dup): runStr = DEFAULT.runTpl.format(runNum + 1) self.acquisitions[acqInd].customLabels += runStr isLink \u2693\ufe0e 1 2 3 4 5 def isLink ( self , data , criteria ) Parameters: Name Type Description Default data dict Dictionnary data of a sidecar None criteria dict Dictionnary criteria None Returns: Type Description None boolean View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def isLink(self, data, criteria): \"\"\" Args: data (dict): Dictionnary data of a sidecar criteria (dict): Dictionnary criteria Returns: boolean \"\"\" def compare(name, pattern): name = str(name) if self.searchMethod == \"re\": return bool(re.match(pattern, name)) else: pattern = str(pattern) if not self.caseSensitive: name = name.lower() pattern = pattern.lower() return fnmatch(name, pattern) result = [] for tag, pattern in criteria.items(): name = data.get(tag, '') if isinstance(name, list): try: subResult = [len(name) == len(pattern), isinstance(pattern, list)] for subName, subPattern in zip(name, pattern): subResult.append(compare(subName, subPattern)) except: subResult = [False] result.append(all(subResult)) else: result.append(compare(name, pattern)) return all(result)","title":"Sidecar"},{"location":"reference/dcm2bids/sidecar/#module-dcm2bidssidecar","text":"sidecars classes View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 # -*- coding: utf-8 -*- \"\"\"sidecars classes\"\"\" import itertools import logging import os import re from collections import defaultdict, OrderedDict from fnmatch import fnmatch from dcm2bids.acquisition import Acquisition from dcm2bids.utils.utils import DEFAULT, splitext_ from dcm2bids.utils.io import load_json class Sidecar(object): \"\"\" A sidecar object Args: filename (str): Path of a JSON sidecar keyComp (list): A list of keys from the JSON sidecar to compare sidecars default=[\"SeriesNumber\",\"AcquisitionTime\",\"SideCarFilename\"] \"\"\" def __init__(self, filename, compKeys=DEFAULT.compKeys): self._origData = {} self._data = {} self.filename = filename self.root, _ = splitext_(filename) self.data = filename self.compKeys = compKeys def __lt__(self, other): lts = [] for key in self.compKeys: try: if all(key in d for d in (self.data, other.data)): if self.data.get(key) == other.data.get(key): lts.append(None) else: lts.append(self.data.get(key) < other.data.get(key)) else: lts.append(None) except: lts.append(None) for lt in lts: if lt is not None: return lt def __eq__(self, other): return self.data == other.data def __hash__(self): return hash(self.filename) @property def origData(self): return self._origData @property def data(self): return self._data @data.setter def data(self, filename): \"\"\" Args: filename (path): path of a JSON file Return: A dictionnary of the JSON content plus the SidecarFilename \"\"\" try: data = load_json(filename) except: data = {} self._origData = data.copy() data[\"SidecarFilename\"] = os.path.basename(filename) self._data = data class SidecarPairing(object): \"\"\" Args: sidecars (list): List of Sidecar objects descriptions (list): List of dictionaries describing acquisitions \"\"\" def __init__(self, sidecars, descriptions, searchMethod=DEFAULT.searchMethod, caseSensitive=DEFAULT.caseSensitive): self.logger = logging.getLogger(__name__) self._searchMethod = \"\" self.graph = OrderedDict() self.acquisitions = [] self.sidecars = sidecars self.descriptions = descriptions self.searchMethod = searchMethod self.caseSensitive = caseSensitive @property def searchMethod(self): return self._searchMethod @searchMethod.setter def searchMethod(self, value): \"\"\" Checks if the search method is implemented Warns the user if not and fall back to default \"\"\" if value in DEFAULT.searchMethodChoices: self._searchMethod = value else: self._searchMethod = DEFAULT.searchMethod self.logger.warning(\"'%s' is not a search method implemented\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.searchMethod ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.searchMethodChoices ) @property def caseSensitive(self): return self._caseSensitive @caseSensitive.setter def caseSensitive(self, value): if isinstance(value, bool): self._caseSensitive = value else: self._caseSensitive = DEFAULT.caseSensitive self.logger.warning(\"'%s' is not a boolean\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.caseSensitive ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.caseSensitive ) def build_graph(self): \"\"\" Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: A graph (OrderedDict) \"\"\" graph = OrderedDict((_, []) for _ in self.sidecars) possibleLinks = itertools.product(self.sidecars, self.descriptions) for sidecar, description in possibleLinks: criteria = description.get(\"criteria\", None) if criteria and self.isLink(sidecar.data, criteria): graph[sidecar].append(description) self.graph = graph return graph def isLink(self, data, criteria): \"\"\" Args: data (dict): Dictionnary data of a sidecar criteria (dict): Dictionnary criteria Returns: boolean \"\"\" def compare(name, pattern): name = str(name) if self.searchMethod == \"re\": return bool(re.match(pattern, name)) else: pattern = str(pattern) if not self.caseSensitive: name = name.lower() pattern = pattern.lower() return fnmatch(name, pattern) result = [] for tag, pattern in criteria.items(): name = data.get(tag, '') if isinstance(name, list): try: subResult = [len(name) == len(pattern), isinstance(pattern, list)] for subName, subPattern in zip(name, pattern): subResult.append(compare(subName, subPattern)) except: subResult = [False] result.append(all(subResult)) else: result.append(compare(name, pattern)) return all(result) def build_acquisitions(self, participant): \"\"\" Args: participant (Participant): Participant object to create acquisitions Returns: A list of acquisition objects \"\"\" acquisitions = [] acquisitions_intendedFor = [] self.logger.info(\"Sidecars pairing:\") for sidecar, valid_descriptions in self.graph.items(): sidecarName = os.path.basename(sidecar.root) # only one description for the sidecar if len(valid_descriptions) == 1: desc = valid_descriptions[0] acq = Acquisition(participant, srcSidecar=sidecar, **desc) acq.setDstFile() if acq.intendedFor != [None]: acquisitions_intendedFor.append(acq) else: acquisitions.append(acq) self.logger.info(\"%s <- %s\", acq.suffix, sidecarName) # sidecar with no link elif len(valid_descriptions) == 0: self.logger.info(\"No Pairing <- %s\", sidecarName) # sidecar with several links else: self.logger.warning(\"Several Pairing <- %s\", sidecarName) for desc in valid_descriptions: acq = Acquisition(participant, **desc) self.logger.warning(\" -> %s\", acq.suffix) self.acquisitions = acquisitions + acquisitions_intendedFor return self.acquisitions def find_runs(self): \"\"\" Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition \"\"\" def duplicates(seq): \"\"\" Find duplicate items in a list Args: seq (list) Yield: A tuple of 2 items (item, list of index) ref: http://stackoverflow.com/a/5419576 \"\"\" tally = defaultdict(list) for i, item in enumerate(seq): tally[item].append(i) for key, locs in tally.items(): if len(locs) > 1: yield key, locs dstRoots = [_.dstRoot for _ in self.acquisitions] for dstRoot, dup in duplicates(dstRoots): self.logger.info(\"%s has %s runs\", dstRoot, len(dup)) self.logger.info(\"Adding 'run' information to the acquisition\") for runNum, acqInd in enumerate(dup): runStr = DEFAULT.runTpl.format(runNum + 1) self.acquisitions[acqInd].customLabels += runStr","title":"Module dcm2bids.sidecar"},{"location":"reference/dcm2bids/sidecar/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/sidecar/#sidecar","text":"1 2 3 4 class Sidecar ( filename , compKeys = [ 'SeriesNumber' , 'AcquisitionTime' , 'SidecarFilename' ] ) A sidecar object","title":"Sidecar"},{"location":"reference/dcm2bids/sidecar/#attributes","text":"Name Type Description Default filename str Path of a JSON sidecar None keyComp list A list of keys from the JSON sidecar to compare sidecars default=[\"SeriesNumber\",\"AcquisitionTime\",\"SideCarFilename\"] None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 class Sidecar(object): \"\"\" A sidecar object Args: filename (str): Path of a JSON sidecar keyComp (list): A list of keys from the JSON sidecar to compare sidecars default=[\"SeriesNumber\",\"AcquisitionTime\",\"SideCarFilename\"] \"\"\" def __init__(self, filename, compKeys=DEFAULT.compKeys): self._origData = {} self._data = {} self.filename = filename self.root, _ = splitext_(filename) self.data = filename self.compKeys = compKeys def __lt__(self, other): lts = [] for key in self.compKeys: try: if all(key in d for d in (self.data, other.data)): if self.data.get(key) == other.data.get(key): lts.append(None) else: lts.append(self.data.get(key) < other.data.get(key)) else: lts.append(None) except: lts.append(None) for lt in lts: if lt is not None: return lt def __eq__(self, other): return self.data == other.data def __hash__(self): return hash(self.filename) @property def origData(self): return self._origData @property def data(self): return self._data @data.setter def data(self, filename): \"\"\" Args: filename (path): path of a JSON file Return: A dictionnary of the JSON content plus the SidecarFilename \"\"\" try: data = load_json(filename) except: data = {} self._origData = data.copy() data[\"SidecarFilename\"] = os.path.basename(filename) self._data = data","title":"Attributes"},{"location":"reference/dcm2bids/sidecar/#instance-variables","text":"1 data 1 origData","title":"Instance variables"},{"location":"reference/dcm2bids/sidecar/#sidecarpairing","text":"1 2 3 4 5 6 class SidecarPairing ( sidecars , descriptions , searchMethod = 'fnmatch' , caseSensitive = True ) Args: sidecars (list): List of Sidecar objects descriptions (list): List of dictionaries describing acquisitions View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 class SidecarPairing(object): \"\"\" Args: sidecars (list): List of Sidecar objects descriptions (list): List of dictionaries describing acquisitions \"\"\" def __init__(self, sidecars, descriptions, searchMethod=DEFAULT.searchMethod, caseSensitive=DEFAULT.caseSensitive): self.logger = logging.getLogger(__name__) self._searchMethod = \"\" self.graph = OrderedDict() self.acquisitions = [] self.sidecars = sidecars self.descriptions = descriptions self.searchMethod = searchMethod self.caseSensitive = caseSensitive @property def searchMethod(self): return self._searchMethod @searchMethod.setter def searchMethod(self, value): \"\"\" Checks if the search method is implemented Warns the user if not and fall back to default \"\"\" if value in DEFAULT.searchMethodChoices: self._searchMethod = value else: self._searchMethod = DEFAULT.searchMethod self.logger.warning(\"'%s' is not a search method implemented\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.searchMethod ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.searchMethodChoices ) @property def caseSensitive(self): return self._caseSensitive @caseSensitive.setter def caseSensitive(self, value): if isinstance(value, bool): self._caseSensitive = value else: self._caseSensitive = DEFAULT.caseSensitive self.logger.warning(\"'%s' is not a boolean\", value) self.logger.warning( \"Falling back to default: %s\", DEFAULT.caseSensitive ) self.logger.warning( \"Search methods implemented: %s\", DEFAULT.caseSensitive ) def build_graph(self): \"\"\" Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: A graph (OrderedDict) \"\"\" graph = OrderedDict((_, []) for _ in self.sidecars) possibleLinks = itertools.product(self.sidecars, self.descriptions) for sidecar, description in possibleLinks: criteria = description.get(\"criteria\", None) if criteria and self.isLink(sidecar.data, criteria): graph[sidecar].append(description) self.graph = graph return graph def isLink(self, data, criteria): \"\"\" Args: data (dict): Dictionnary data of a sidecar criteria (dict): Dictionnary criteria Returns: boolean \"\"\" def compare(name, pattern): name = str(name) if self.searchMethod == \"re\": return bool(re.match(pattern, name)) else: pattern = str(pattern) if not self.caseSensitive: name = name.lower() pattern = pattern.lower() return fnmatch(name, pattern) result = [] for tag, pattern in criteria.items(): name = data.get(tag, '') if isinstance(name, list): try: subResult = [len(name) == len(pattern), isinstance(pattern, list)] for subName, subPattern in zip(name, pattern): subResult.append(compare(subName, subPattern)) except: subResult = [False] result.append(all(subResult)) else: result.append(compare(name, pattern)) return all(result) def build_acquisitions(self, participant): \"\"\" Args: participant (Participant): Participant object to create acquisitions Returns: A list of acquisition objects \"\"\" acquisitions = [] acquisitions_intendedFor = [] self.logger.info(\"Sidecars pairing:\") for sidecar, valid_descriptions in self.graph.items(): sidecarName = os.path.basename(sidecar.root) # only one description for the sidecar if len(valid_descriptions) == 1: desc = valid_descriptions[0] acq = Acquisition(participant, srcSidecar=sidecar, **desc) acq.setDstFile() if acq.intendedFor != [None]: acquisitions_intendedFor.append(acq) else: acquisitions.append(acq) self.logger.info(\"%s <- %s\", acq.suffix, sidecarName) # sidecar with no link elif len(valid_descriptions) == 0: self.logger.info(\"No Pairing <- %s\", sidecarName) # sidecar with several links else: self.logger.warning(\"Several Pairing <- %s\", sidecarName) for desc in valid_descriptions: acq = Acquisition(participant, **desc) self.logger.warning(\" -> %s\", acq.suffix) self.acquisitions = acquisitions + acquisitions_intendedFor return self.acquisitions def find_runs(self): \"\"\" Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition \"\"\" def duplicates(seq): \"\"\" Find duplicate items in a list Args: seq (list) Yield: A tuple of 2 items (item, list of index) ref: http://stackoverflow.com/a/5419576 \"\"\" tally = defaultdict(list) for i, item in enumerate(seq): tally[item].append(i) for key, locs in tally.items(): if len(locs) > 1: yield key, locs dstRoots = [_.dstRoot for _ in self.acquisitions] for dstRoot, dup in duplicates(dstRoots): self.logger.info(\"%s has %s runs\", dstRoot, len(dup)) self.logger.info(\"Adding 'run' information to the acquisition\") for runNum, acqInd in enumerate(dup): runStr = DEFAULT.runTpl.format(runNum + 1) self.acquisitions[acqInd].customLabels += runStr","title":"SidecarPairing"},{"location":"reference/dcm2bids/sidecar/#instance-variables_1","text":"1 caseSensitive 1 searchMethod","title":"Instance variables"},{"location":"reference/dcm2bids/sidecar/#methods","text":"","title":"Methods"},{"location":"reference/dcm2bids/sidecar/#build_acquisitions","text":"1 2 3 4 def build_acquisitions ( self , participant ) Parameters: Name Type Description Default participant Participant Participant object to create acquisitions None Returns: Type Description None A list of acquisition objects View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def build_acquisitions(self, participant): \"\"\" Args: participant (Participant): Participant object to create acquisitions Returns: A list of acquisition objects \"\"\" acquisitions = [] acquisitions_intendedFor = [] self.logger.info(\"Sidecars pairing:\") for sidecar, valid_descriptions in self.graph.items(): sidecarName = os.path.basename(sidecar.root) # only one description for the sidecar if len(valid_descriptions) == 1: desc = valid_descriptions[0] acq = Acquisition(participant, srcSidecar=sidecar, **desc) acq.setDstFile() if acq.intendedFor != [None]: acquisitions_intendedFor.append(acq) else: acquisitions.append(acq) self.logger.info(\"%s <- %s\", acq.suffix, sidecarName) # sidecar with no link elif len(valid_descriptions) == 0: self.logger.info(\"No Pairing <- %s\", sidecarName) # sidecar with several links else: self.logger.warning(\"Several Pairing <- %s\", sidecarName) for desc in valid_descriptions: acq = Acquisition(participant, **desc) self.logger.warning(\" -> %s\", acq.suffix) self.acquisitions = acquisitions + acquisitions_intendedFor return self.acquisitions","title":"build_acquisitions"},{"location":"reference/dcm2bids/sidecar/#build_graph","text":"1 2 3 def build_graph ( self ) Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: Type Description None A graph (OrderedDict) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def build_graph(self): \"\"\" Test all the possible links between the list of sidecars and the description dictionaries and build a graph from it The graph is in a OrderedDict object. The keys are the Sidecars and the values are a list of possible descriptions Returns: A graph (OrderedDict) \"\"\" graph = OrderedDict((_, []) for _ in self.sidecars) possibleLinks = itertools.product(self.sidecars, self.descriptions) for sidecar, description in possibleLinks: criteria = description.get(\"criteria\", None) if criteria and self.isLink(sidecar.data, criteria): graph[sidecar].append(description) self.graph = graph return graph","title":"build_graph"},{"location":"reference/dcm2bids/sidecar/#find_runs","text":"1 2 3 def find_runs ( self ) Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def find_runs(self): \"\"\" Check if there is duplicate destination roots in the acquisitions and add '_run-' to the customLabels of the acquisition \"\"\" def duplicates(seq): \"\"\" Find duplicate items in a list Args: seq (list) Yield: A tuple of 2 items (item, list of index) ref: http://stackoverflow.com/a/5419576 \"\"\" tally = defaultdict(list) for i, item in enumerate(seq): tally[item].append(i) for key, locs in tally.items(): if len(locs) > 1: yield key, locs dstRoots = [_.dstRoot for _ in self.acquisitions] for dstRoot, dup in duplicates(dstRoots): self.logger.info(\"%s has %s runs\", dstRoot, len(dup)) self.logger.info(\"Adding 'run' information to the acquisition\") for runNum, acqInd in enumerate(dup): runStr = DEFAULT.runTpl.format(runNum + 1) self.acquisitions[acqInd].customLabels += runStr","title":"find_runs"},{"location":"reference/dcm2bids/sidecar/#islink","text":"1 2 3 4 5 def isLink ( self , data , criteria ) Parameters: Name Type Description Default data dict Dictionnary data of a sidecar None criteria dict Dictionnary criteria None Returns: Type Description None boolean View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def isLink(self, data, criteria): \"\"\" Args: data (dict): Dictionnary data of a sidecar criteria (dict): Dictionnary criteria Returns: boolean \"\"\" def compare(name, pattern): name = str(name) if self.searchMethod == \"re\": return bool(re.match(pattern, name)) else: pattern = str(pattern) if not self.caseSensitive: name = name.lower() pattern = pattern.lower() return fnmatch(name, pattern) result = [] for tag, pattern in criteria.items(): name = data.get(tag, '') if isinstance(name, list): try: subResult = [len(name) == len(pattern), isinstance(pattern, list)] for subName, subPattern in zip(name, pattern): subResult.append(compare(subName, subPattern)) except: subResult = [False] result.append(all(subResult)) else: result.append(compare(name, pattern)) return all(result)","title":"isLink"},{"location":"reference/dcm2bids/version/","text":"Module dcm2bids.version \u2693\ufe0e View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 # -*- coding: utf-8 -*- # Format expected by setup.py and doc/source/conf.py: string of form \"X.Y.Z\" _version_major = 3 _version_minor = 0 _version_micro = 0 _version_extra = 'dev' # Construct full version string from these. _ver = [_version_major, _version_minor] if _version_micro: _ver.append(_version_micro) if _version_extra: _ver.append(_version_extra) __version__ = '.'.join(map(str, _ver)) CLASSIFIERS = [ \"Intended Audience :: Healthcare Industry\", \"Intended Audience :: Science/Research\", \"Operating System :: MacOS\", \"Operating System :: Microsoft :: Windows\", \"Operating System :: Unix\", \"Programming Language :: Python\", \"Programming Language :: Python :: 3.8\", \"Programming Language :: Python :: 3.9\", \"Programming Language :: Python :: 3.10\", \"Topic :: Scientific/Engineering\", \"Topic :: Scientific/Engineering :: Bio-Informatics\", \"Topic :: Scientific/Engineering :: Medical Science Apps.\", ] # Description should be a one-liner: description = \"Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure\" NAME = \"dcm2bids\" MAINTAINER = \"Arnaud Bor\u00e9\" MAINTAINER_EMAIL = \"arnaud.bore@gmail.com\" DESCRIPTION = description PROJECT_URLS = { \"Documentation\": \"https://unfmontreal.github.io/Dcm2Bids\", \"Source Code\": \"https://github.com/unfmontreal/Dcm2Bids\", } LICENSE = \"GPLv3+\" PLATFORMS = \"OS Independent\" MAJOR = _version_major MINOR = _version_minor MICRO = _version_micro VERSION = __version__ ENTRY_POINTS = {'console_scripts': [ 'dcm2bids=dcm2bids.cli.dcm2bids:main', 'dcm2bids_helper=dcm2bids.cli.dcm2bids_helper:main', 'dcm2bids_scaffold=dcm2bids.cli.dcm2bids_scaffold:main', ]} Variables \u2693\ufe0e 1 CLASSIFIERS 1 DESCRIPTION 1 ENTRY_POINTS 1 LICENSE 1 MAINTAINER 1 MAINTAINER_EMAIL 1 MAJOR 1 MICRO 1 MINOR 1 NAME 1 PLATFORMS 1 PROJECT_URLS 1 VERSION 1 description","title":"Version"},{"location":"reference/dcm2bids/version/#module-dcm2bidsversion","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 # -*- coding: utf-8 -*- # Format expected by setup.py and doc/source/conf.py: string of form \"X.Y.Z\" _version_major = 3 _version_minor = 0 _version_micro = 0 _version_extra = 'dev' # Construct full version string from these. _ver = [_version_major, _version_minor] if _version_micro: _ver.append(_version_micro) if _version_extra: _ver.append(_version_extra) __version__ = '.'.join(map(str, _ver)) CLASSIFIERS = [ \"Intended Audience :: Healthcare Industry\", \"Intended Audience :: Science/Research\", \"Operating System :: MacOS\", \"Operating System :: Microsoft :: Windows\", \"Operating System :: Unix\", \"Programming Language :: Python\", \"Programming Language :: Python :: 3.8\", \"Programming Language :: Python :: 3.9\", \"Programming Language :: Python :: 3.10\", \"Topic :: Scientific/Engineering\", \"Topic :: Scientific/Engineering :: Bio-Informatics\", \"Topic :: Scientific/Engineering :: Medical Science Apps.\", ] # Description should be a one-liner: description = \"Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure\" NAME = \"dcm2bids\" MAINTAINER = \"Arnaud Bor\u00e9\" MAINTAINER_EMAIL = \"arnaud.bore@gmail.com\" DESCRIPTION = description PROJECT_URLS = { \"Documentation\": \"https://unfmontreal.github.io/Dcm2Bids\", \"Source Code\": \"https://github.com/unfmontreal/Dcm2Bids\", } LICENSE = \"GPLv3+\" PLATFORMS = \"OS Independent\" MAJOR = _version_major MINOR = _version_minor MICRO = _version_micro VERSION = __version__ ENTRY_POINTS = {'console_scripts': [ 'dcm2bids=dcm2bids.cli.dcm2bids:main', 'dcm2bids_helper=dcm2bids.cli.dcm2bids_helper:main', 'dcm2bids_scaffold=dcm2bids.cli.dcm2bids_scaffold:main', ]}","title":"Module dcm2bids.version"},{"location":"reference/dcm2bids/version/#variables","text":"1 CLASSIFIERS 1 DESCRIPTION 1 ENTRY_POINTS 1 LICENSE 1 MAINTAINER 1 MAINTAINER_EMAIL 1 MAJOR 1 MICRO 1 MINOR 1 NAME 1 PLATFORMS 1 PROJECT_URLS 1 VERSION 1 description","title":"Variables"},{"location":"reference/dcm2bids/cli/","text":"Module dcm2bids.cli \u2693\ufe0e Sub-modules \u2693\ufe0e dcm2bids.cli.dcm2bids dcm2bids.cli.dcm2bids_helper dcm2bids.cli.dcm2bids_scaffold","title":"Index"},{"location":"reference/dcm2bids/cli/#module-dcm2bidscli","text":"","title":"Module dcm2bids.cli"},{"location":"reference/dcm2bids/cli/#sub-modules","text":"dcm2bids.cli.dcm2bids dcm2bids.cli.dcm2bids_helper dcm2bids.cli.dcm2bids_scaffold","title":"Sub-modules"},{"location":"reference/dcm2bids/cli/dcm2bids/","text":"Module dcm2bids.cli.dcm2bids \u2693\ufe0e Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\" Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure \"\"\" import argparse from dcm2bids.dcm2bids_gen import Dcm2BidsGen from dcm2bids.utils.utils import DEFAULT from dcm2bids.version import __version__ def _build_arg_parser(): p = argparse.ArgumentParser(description=__doc__, epilog=DEFAULT.doc, formatter_class=argparse.RawTextHelpFormatter) p.add_argument(\"-d\", \"--dicom_dir\", required=True, nargs=\"+\", help=\"DICOM directory(ies).\") p.add_argument(\"-p\", \"--participant\", required=True, help=\"Participant ID.\") p.add_argument(\"-s\", \"--session\", required=False, default=DEFAULT.cliSession, help=\"Session ID. [%(default)s]\") p.add_argument(\"-c\", \"--config\", required=True, help=\"JSON configuration file (see example/config.json).\") p.add_argument(\"-o\", \"--output_dir\", required=False, default=DEFAULT.cliOutputDir, help=\"Output BIDS directory. [%(default)s]\") p.add_argument(\"--bids_validate\", action='store_true', help=\"If set, once your conversion is done it\" \" will check if your output folder is BIDS valid. [%(default)s]\\n\" f\"bids-validator needs to be installed check: {DEFAULT.link_bids_validator}\") p.add_argument(\"--forceDcm2niix\", action=\"store_true\", help=\"Overwrite previous temporary dcm2niix \" \"output if it exists.\") p.add_argument(\"--clobber\", action=\"store_true\", help=\"Overwrite output if it exists.\") p.add_argument(\"-l\", \"--log_level\", required=False, default=DEFAULT.cliLogLevel, choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"], help=\"Set logging level. [%(default)s]\") p.add_argument(\"-v\", \"--version\", action=\"version\", version=f\"dcm2bids version:\\t{__version__}\\nBased on BIDS version:\\t{DEFAULT.bids_version}\", help=\"Report dcm2bids version and the BIDS version.\") return p def main(): parser = _build_arg_parser() args = parser.parse_args() app = Dcm2BidsGen(**vars(args)) return app.run() if __name__ == \"__main__\": main() Functions \u2693\ufe0e main \u2693\ufe0e 1 2 3 def main ( ) View Source 1 2 3 4 5 6 7 8 9 def main(): parser = _build_arg_parser() args = parser.parse_args() app = Dcm2BidsGen(**vars(args)) return app.run()","title":"Dcm2Bids"},{"location":"reference/dcm2bids/cli/dcm2bids/#module-dcm2bidsclidcm2bids","text":"Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\" Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure \"\"\" import argparse from dcm2bids.dcm2bids_gen import Dcm2BidsGen from dcm2bids.utils.utils import DEFAULT from dcm2bids.version import __version__ def _build_arg_parser(): p = argparse.ArgumentParser(description=__doc__, epilog=DEFAULT.doc, formatter_class=argparse.RawTextHelpFormatter) p.add_argument(\"-d\", \"--dicom_dir\", required=True, nargs=\"+\", help=\"DICOM directory(ies).\") p.add_argument(\"-p\", \"--participant\", required=True, help=\"Participant ID.\") p.add_argument(\"-s\", \"--session\", required=False, default=DEFAULT.cliSession, help=\"Session ID. [%(default)s]\") p.add_argument(\"-c\", \"--config\", required=True, help=\"JSON configuration file (see example/config.json).\") p.add_argument(\"-o\", \"--output_dir\", required=False, default=DEFAULT.cliOutputDir, help=\"Output BIDS directory. [%(default)s]\") p.add_argument(\"--bids_validate\", action='store_true', help=\"If set, once your conversion is done it\" \" will check if your output folder is BIDS valid. [%(default)s]\\n\" f\"bids-validator needs to be installed check: {DEFAULT.link_bids_validator}\") p.add_argument(\"--forceDcm2niix\", action=\"store_true\", help=\"Overwrite previous temporary dcm2niix \" \"output if it exists.\") p.add_argument(\"--clobber\", action=\"store_true\", help=\"Overwrite output if it exists.\") p.add_argument(\"-l\", \"--log_level\", required=False, default=DEFAULT.cliLogLevel, choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"], help=\"Set logging level. [%(default)s]\") p.add_argument(\"-v\", \"--version\", action=\"version\", version=f\"dcm2bids version:\\t{__version__}\\nBased on BIDS version:\\t{DEFAULT.bids_version}\", help=\"Report dcm2bids version and the BIDS version.\") return p def main(): parser = _build_arg_parser() args = parser.parse_args() app = Dcm2BidsGen(**vars(args)) return app.run() if __name__ == \"__main__\": main()","title":"Module dcm2bids.cli.dcm2bids"},{"location":"reference/dcm2bids/cli/dcm2bids/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/cli/dcm2bids/#main","text":"1 2 3 def main ( ) View Source 1 2 3 4 5 6 7 8 9 def main(): parser = _build_arg_parser() args = parser.parse_args() app = Dcm2BidsGen(**vars(args)) return app.run()","title":"main"},{"location":"reference/dcm2bids/cli/dcm2bids_helper/","text":"Module dcm2bids.cli.dcm2bids_helper \u2693\ufe0e helper module View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 # -*- coding: utf-8 -*- \"\"\"helper module\"\"\" import argparse from os.path import join as opj from dcm2bids.dcm2niix_gen import Dcm2niixGen from dcm2bids.utils.args import assert_dirs_empty from dcm2bids.utils.utils import DEFAULT def _build_arg_parser(): p = argparse.ArgumentParser(description=__doc__, epilog=DEFAULT.doc, formatter_class=argparse.RawTextHelpFormatter) p.add_argument(\"-d\", \"--dicom_dir\", required=True, nargs=\"+\", help=\"DICOM files directory.\") p.add_argument(\"-o\", \"--output_dir\", required=False, default=DEFAULT.cliOutputDir, help=\"Output BIDS directory.\" \" (Default: %(default)s)\") p.add_argument('--force', dest='overwrite', action='store_true', help='Force command to overwrite existing output files.') return p def main(): \"\"\"Let's go\"\"\" parser = _build_arg_parser() args = parser.parse_args() out_folder = opj(args.output_dir, 'tmp_dcm2bids', 'helper') assert_dirs_empty(parser, args, out_folder) app = Dcm2niixGen(dicomDirs=args.dicom_dir, bidsDir=args.output_dir) rsl = app.run() print(\"Example in:\") print(opj(args.output_dir, DEFAULT.tmpDirName, DEFAULT.helperDir)) return rsl if __name__ == \"__main__\": main() Functions \u2693\ufe0e main \u2693\ufe0e 1 2 3 def main ( ) Let's go View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def main(): \"\"\"Let's go\"\"\" parser = _build_arg_parser() args = parser.parse_args() out_folder = opj(args.output_dir, 'tmp_dcm2bids', 'helper') assert_dirs_empty(parser, args, out_folder) app = Dcm2niixGen(dicomDirs=args.dicom_dir, bidsDir=args.output_dir) rsl = app.run() print(\"Example in:\") print(opj(args.output_dir, DEFAULT.tmpDirName, DEFAULT.helperDir)) return rsl","title":"Dcm2Bids Helper"},{"location":"reference/dcm2bids/cli/dcm2bids_helper/#module-dcm2bidsclidcm2bids_helper","text":"helper module View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 # -*- coding: utf-8 -*- \"\"\"helper module\"\"\" import argparse from os.path import join as opj from dcm2bids.dcm2niix_gen import Dcm2niixGen from dcm2bids.utils.args import assert_dirs_empty from dcm2bids.utils.utils import DEFAULT def _build_arg_parser(): p = argparse.ArgumentParser(description=__doc__, epilog=DEFAULT.doc, formatter_class=argparse.RawTextHelpFormatter) p.add_argument(\"-d\", \"--dicom_dir\", required=True, nargs=\"+\", help=\"DICOM files directory.\") p.add_argument(\"-o\", \"--output_dir\", required=False, default=DEFAULT.cliOutputDir, help=\"Output BIDS directory.\" \" (Default: %(default)s)\") p.add_argument('--force', dest='overwrite', action='store_true', help='Force command to overwrite existing output files.') return p def main(): \"\"\"Let's go\"\"\" parser = _build_arg_parser() args = parser.parse_args() out_folder = opj(args.output_dir, 'tmp_dcm2bids', 'helper') assert_dirs_empty(parser, args, out_folder) app = Dcm2niixGen(dicomDirs=args.dicom_dir, bidsDir=args.output_dir) rsl = app.run() print(\"Example in:\") print(opj(args.output_dir, DEFAULT.tmpDirName, DEFAULT.helperDir)) return rsl if __name__ == \"__main__\": main()","title":"Module dcm2bids.cli.dcm2bids_helper"},{"location":"reference/dcm2bids/cli/dcm2bids_helper/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/cli/dcm2bids_helper/#main","text":"1 2 3 def main ( ) Let's go View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def main(): \"\"\"Let's go\"\"\" parser = _build_arg_parser() args = parser.parse_args() out_folder = opj(args.output_dir, 'tmp_dcm2bids', 'helper') assert_dirs_empty(parser, args, out_folder) app = Dcm2niixGen(dicomDirs=args.dicom_dir, bidsDir=args.output_dir) rsl = app.run() print(\"Example in:\") print(opj(args.output_dir, DEFAULT.tmpDirName, DEFAULT.helperDir)) return rsl","title":"main"},{"location":"reference/dcm2bids/cli/dcm2bids_scaffold/","text":"Module dcm2bids.cli.dcm2bids_scaffold \u2693\ufe0e Create basic BIDS files and directories. Based on the material provided by https://github.com/bids-standard/bids-starter-kit View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\" Create basic BIDS files and directories. Based on the material provided by https://github.com/bids-standard/bids-starter-kit \"\"\" import argparse import datetime import logging import os from os.path import join as opj from dcm2bids.utils.io import write_txt from dcm2bids.utils.args import add_overwrite_arg, assert_dirs_empty from dcm2bids.utils.utils import DEFAULT, run_shell_command from dcm2bids.utils.scaffold import bids_starter_kit def _build_arg_parser(): p = argparse.ArgumentParser(description=__doc__, epilog=DEFAULT.doc, formatter_class=argparse.RawTextHelpFormatter) p.add_argument(\"-o\", \"--output_dir\", required=False, default=DEFAULT.cliOutputDir, help=\"Output BIDS directory. Default: [%(default)s]\") add_overwrite_arg(p) return p def main(): parser = _build_arg_parser() args = parser.parse_args() assert_dirs_empty(parser, args, args.output_dir) for _ in [\"code\", \"derivatives\", \"sourcedata\"]: os.makedirs(opj(args.output_dir, _), exist_ok=True) logging.info(\"The files used to create your BIDS directory comes from\" \"https://github.com/bids-standard/bids-starter-kit\") # CHANGES write_txt(opj(args.output_dir, \"CHANGES\"), bids_starter_kit.CHANGES.replace('DATE', datetime.date.today().strftime(\"%Y-%m-%d\"))) # dataset_description write_txt(opj(args.output_dir, \"dataset_description\"), bids_starter_kit.dataset_description.replace(\"BIDS_VERSION\", DEFAULT.bids_version)) # participants.json write_txt(opj(args.output_dir, \"participants.json\"), bids_starter_kit.participants_json) # participants.tsv write_txt(opj(args.output_dir, \"participants.tsv\"), bids_starter_kit.participants_tsv) # README try: run_shell_command(['wget', '-q', '-O', opj(args.output_dir, \"README\"), 'https://github.com/bids-standard/bids-starter-kit/blob/main/templates/README.MD']) except: write_txt(opj(args.output_dir, \"README\"), bids_starter_kit.README) if __name__ == \"__main__\": main() Functions \u2693\ufe0e main \u2693\ufe0e 1 2 3 def main ( ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def main(): parser = _build_arg_parser() args = parser.parse_args() assert_dirs_empty(parser, args, args.output_dir) for _ in [\"code\", \"derivatives\", \"sourcedata\"]: os.makedirs(opj(args.output_dir, _), exist_ok=True) logging.info(\"The files used to create your BIDS directory comes from\" \"https://github.com/bids-standard/bids-starter-kit\") # CHANGES write_txt(opj(args.output_dir, \"CHANGES\"), bids_starter_kit.CHANGES.replace('DATE', datetime.date.today().strftime(\"%Y-%m-%d\"))) # dataset_description write_txt(opj(args.output_dir, \"dataset_description\"), bids_starter_kit.dataset_description.replace(\"BIDS_VERSION\", DEFAULT.bids_version)) # participants.json write_txt(opj(args.output_dir, \"participants.json\"), bids_starter_kit.participants_json) # participants.tsv write_txt(opj(args.output_dir, \"participants.tsv\"), bids_starter_kit.participants_tsv) # README try: run_shell_command(['wget', '-q', '-O', opj(args.output_dir, \"README\"), 'https://github.com/bids-standard/bids-starter-kit/blob/main/templates/README.MD']) except: write_txt(opj(args.output_dir, \"README\"), bids_starter_kit.README)","title":"Dcm2Bids Scaffold"},{"location":"reference/dcm2bids/cli/dcm2bids_scaffold/#module-dcm2bidsclidcm2bids_scaffold","text":"Create basic BIDS files and directories. Based on the material provided by https://github.com/bids-standard/bids-starter-kit View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\" Create basic BIDS files and directories. Based on the material provided by https://github.com/bids-standard/bids-starter-kit \"\"\" import argparse import datetime import logging import os from os.path import join as opj from dcm2bids.utils.io import write_txt from dcm2bids.utils.args import add_overwrite_arg, assert_dirs_empty from dcm2bids.utils.utils import DEFAULT, run_shell_command from dcm2bids.utils.scaffold import bids_starter_kit def _build_arg_parser(): p = argparse.ArgumentParser(description=__doc__, epilog=DEFAULT.doc, formatter_class=argparse.RawTextHelpFormatter) p.add_argument(\"-o\", \"--output_dir\", required=False, default=DEFAULT.cliOutputDir, help=\"Output BIDS directory. Default: [%(default)s]\") add_overwrite_arg(p) return p def main(): parser = _build_arg_parser() args = parser.parse_args() assert_dirs_empty(parser, args, args.output_dir) for _ in [\"code\", \"derivatives\", \"sourcedata\"]: os.makedirs(opj(args.output_dir, _), exist_ok=True) logging.info(\"The files used to create your BIDS directory comes from\" \"https://github.com/bids-standard/bids-starter-kit\") # CHANGES write_txt(opj(args.output_dir, \"CHANGES\"), bids_starter_kit.CHANGES.replace('DATE', datetime.date.today().strftime(\"%Y-%m-%d\"))) # dataset_description write_txt(opj(args.output_dir, \"dataset_description\"), bids_starter_kit.dataset_description.replace(\"BIDS_VERSION\", DEFAULT.bids_version)) # participants.json write_txt(opj(args.output_dir, \"participants.json\"), bids_starter_kit.participants_json) # participants.tsv write_txt(opj(args.output_dir, \"participants.tsv\"), bids_starter_kit.participants_tsv) # README try: run_shell_command(['wget', '-q', '-O', opj(args.output_dir, \"README\"), 'https://github.com/bids-standard/bids-starter-kit/blob/main/templates/README.MD']) except: write_txt(opj(args.output_dir, \"README\"), bids_starter_kit.README) if __name__ == \"__main__\": main()","title":"Module dcm2bids.cli.dcm2bids_scaffold"},{"location":"reference/dcm2bids/cli/dcm2bids_scaffold/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/cli/dcm2bids_scaffold/#main","text":"1 2 3 def main ( ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def main(): parser = _build_arg_parser() args = parser.parse_args() assert_dirs_empty(parser, args, args.output_dir) for _ in [\"code\", \"derivatives\", \"sourcedata\"]: os.makedirs(opj(args.output_dir, _), exist_ok=True) logging.info(\"The files used to create your BIDS directory comes from\" \"https://github.com/bids-standard/bids-starter-kit\") # CHANGES write_txt(opj(args.output_dir, \"CHANGES\"), bids_starter_kit.CHANGES.replace('DATE', datetime.date.today().strftime(\"%Y-%m-%d\"))) # dataset_description write_txt(opj(args.output_dir, \"dataset_description\"), bids_starter_kit.dataset_description.replace(\"BIDS_VERSION\", DEFAULT.bids_version)) # participants.json write_txt(opj(args.output_dir, \"participants.json\"), bids_starter_kit.participants_json) # participants.tsv write_txt(opj(args.output_dir, \"participants.tsv\"), bids_starter_kit.participants_tsv) # README try: run_shell_command(['wget', '-q', '-O', opj(args.output_dir, \"README\"), 'https://github.com/bids-standard/bids-starter-kit/blob/main/templates/README.MD']) except: write_txt(opj(args.output_dir, \"README\"), bids_starter_kit.README)","title":"main"},{"location":"reference/dcm2bids/utils/","text":"Module dcm2bids.utils \u2693\ufe0e Sub-modules \u2693\ufe0e dcm2bids.utils.args dcm2bids.utils.io dcm2bids.utils.logger dcm2bids.utils.scaffold dcm2bids.utils.tools dcm2bids.utils.utils","title":"Index"},{"location":"reference/dcm2bids/utils/#module-dcm2bidsutils","text":"","title":"Module dcm2bids.utils"},{"location":"reference/dcm2bids/utils/#sub-modules","text":"dcm2bids.utils.args dcm2bids.utils.io dcm2bids.utils.logger dcm2bids.utils.scaffold dcm2bids.utils.tools dcm2bids.utils.utils","title":"Sub-modules"},{"location":"reference/dcm2bids/utils/args/","text":"Module dcm2bids.utils.args \u2693\ufe0e View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # -*- coding: utf-8 -*- import os import shutil def assert_dirs_empty(parser, args, required): \"\"\" Assert that all directories exist are empty. If dirs exist and not empty, and --force is used, delete dirs. Parameters ---------- parser: argparse.ArgumentParser object Parser. args: argparse namespace Argument list. required: string or list of paths to files Required paths to be checked. \"\"\" def check(path): if os.path.isdir(path): if os.listdir(path): if not args.overwrite: parser.error( f\"Output directory {path} isn't empty, so some files \" \"could be overwritten or deleted.\\nRerun the command\" \" with --force option to overwrite \" \"existing output files.\") else: for the_file in os.listdir(path): file_path = os.path.join(path, the_file) try: if os.path.isfile(file_path): os.unlink(file_path) elif os.path.isdir(file_path): shutil.rmtree(file_path) except Exception as e: print(e) if isinstance(required, str): required = [required] for cur_dir in required: check(cur_dir) def add_overwrite_arg(parser): parser.add_argument( '--force', dest='overwrite', action='store_true', help='Force overwriting of the output files.') Functions \u2693\ufe0e add_overwrite_arg \u2693\ufe0e 1 2 3 def add_overwrite_arg ( parser ) View Source 1 2 3 4 5 6 7 def add_overwrite_arg(parser): parser.add_argument( '--force', dest='overwrite', action='store_true', help='Force overwriting of the output files.') assert_dirs_empty \u2693\ufe0e 1 2 3 4 5 def assert_dirs_empty ( parser , args , required ) Assert that all directories exist are empty. If dirs exist and not empty, and --force is used, delete dirs. Parameters: Name Type Description Default parser argparse.ArgumentParser object Parser. None args argparse namespace Argument list. None required string or list of paths to files Required paths to be checked. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def assert_dirs_empty(parser, args, required): \"\"\" Assert that all directories exist are empty. If dirs exist and not empty, and --force is used, delete dirs. Parameters ---------- parser: argparse.ArgumentParser object Parser. args: argparse namespace Argument list. required: string or list of paths to files Required paths to be checked. \"\"\" def check(path): if os.path.isdir(path): if os.listdir(path): if not args.overwrite: parser.error( f\"Output directory {path} isn't empty, so some files \" \"could be overwritten or deleted.\\nRerun the command\" \" with --force option to overwrite \" \"existing output files.\") else: for the_file in os.listdir(path): file_path = os.path.join(path, the_file) try: if os.path.isfile(file_path): os.unlink(file_path) elif os.path.isdir(file_path): shutil.rmtree(file_path) except Exception as e: print(e) if isinstance(required, str): required = [required] for cur_dir in required: check(cur_dir)","title":"Args"},{"location":"reference/dcm2bids/utils/args/#module-dcm2bidsutilsargs","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # -*- coding: utf-8 -*- import os import shutil def assert_dirs_empty(parser, args, required): \"\"\" Assert that all directories exist are empty. If dirs exist and not empty, and --force is used, delete dirs. Parameters ---------- parser: argparse.ArgumentParser object Parser. args: argparse namespace Argument list. required: string or list of paths to files Required paths to be checked. \"\"\" def check(path): if os.path.isdir(path): if os.listdir(path): if not args.overwrite: parser.error( f\"Output directory {path} isn't empty, so some files \" \"could be overwritten or deleted.\\nRerun the command\" \" with --force option to overwrite \" \"existing output files.\") else: for the_file in os.listdir(path): file_path = os.path.join(path, the_file) try: if os.path.isfile(file_path): os.unlink(file_path) elif os.path.isdir(file_path): shutil.rmtree(file_path) except Exception as e: print(e) if isinstance(required, str): required = [required] for cur_dir in required: check(cur_dir) def add_overwrite_arg(parser): parser.add_argument( '--force', dest='overwrite', action='store_true', help='Force overwriting of the output files.')","title":"Module dcm2bids.utils.args"},{"location":"reference/dcm2bids/utils/args/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/utils/args/#add_overwrite_arg","text":"1 2 3 def add_overwrite_arg ( parser ) View Source 1 2 3 4 5 6 7 def add_overwrite_arg(parser): parser.add_argument( '--force', dest='overwrite', action='store_true', help='Force overwriting of the output files.')","title":"add_overwrite_arg"},{"location":"reference/dcm2bids/utils/args/#assert_dirs_empty","text":"1 2 3 4 5 def assert_dirs_empty ( parser , args , required ) Assert that all directories exist are empty. If dirs exist and not empty, and --force is used, delete dirs. Parameters: Name Type Description Default parser argparse.ArgumentParser object Parser. None args argparse namespace Argument list. None required string or list of paths to files Required paths to be checked. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def assert_dirs_empty(parser, args, required): \"\"\" Assert that all directories exist are empty. If dirs exist and not empty, and --force is used, delete dirs. Parameters ---------- parser: argparse.ArgumentParser object Parser. args: argparse namespace Argument list. required: string or list of paths to files Required paths to be checked. \"\"\" def check(path): if os.path.isdir(path): if os.listdir(path): if not args.overwrite: parser.error( f\"Output directory {path} isn't empty, so some files \" \"could be overwritten or deleted.\\nRerun the command\" \" with --force option to overwrite \" \"existing output files.\") else: for the_file in os.listdir(path): file_path = os.path.join(path, the_file) try: if os.path.isfile(file_path): os.unlink(file_path) elif os.path.isdir(file_path): shutil.rmtree(file_path) except Exception as e: print(e) if isinstance(required, str): required = [required] for cur_dir in required: check(cur_dir)","title":"assert_dirs_empty"},{"location":"reference/dcm2bids/utils/io/","text":"Module dcm2bids.utils.io \u2693\ufe0e View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 # -*- coding: utf-8 -*- import inspect import json import os import os.path as opj from pathlib import Path from collections import OrderedDict import dcm2bids def load_json(filename): \"\"\" Load a JSON file Args: filename (str): Path of a JSON file Return: Dictionnary of the JSON file \"\"\" with open(filename, \"r\") as f: data = json.load(f, object_pairs_hook=OrderedDict) return data def save_json(filename, data): with open(filename, \"w\") as f: json.dump(data, f, indent=4) def write_txt(filename, lines): with open(filename, \"a+\") as f: f.write(f\"{lines}\\n\") def get_scaffold_dir(): \"\"\" Return SCAFFOLD data directory in dcm2bids repository Returns ------- scaffold_dir: string SCAFFOLD path \"\"\" module_path = os.path.dirname(os.path.dirname(inspect.getfile(dcm2bids))) # module_path = inspect.getfile(dcm2bids) scaffold_dir = opj(module_path, 'data', 'scaffold') # scaffold_dir = pkg_resources.resource_filename(__name__, os.path.join(\"data\", \"scaffold\")) # print(module_path) # scaffold_dir = os.path.join(os.path.dirname( # os.path.dirname(module_path)), \"data\", \"scaffold\") print(scaffold_dir) return scaffold_dir def valid_path(in_path, type=\"folder\"): \"\"\"Assert that file exists. Parameters ---------- required_file: Path Path to be checked. \"\"\" if isinstance(in_path, str): in_path = Path(in_path) if type == 'folder': if in_path.is_dir() or in_path.parent.is_dir(): return in_path else: raise NotADirectoryError(in_path) elif type == \"file\": if in_path.is_file(): return in_path else: raise FileNotFoundError(in_path) raise TypeError(type) Functions \u2693\ufe0e get_scaffold_dir \u2693\ufe0e 1 2 3 def get_scaffold_dir ( ) Return SCAFFOLD data directory in dcm2bids repository Returns: Type Description string SCAFFOLD path View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def get_scaffold_dir(): \"\"\" Return SCAFFOLD data directory in dcm2bids repository Returns ------- scaffold_dir: string SCAFFOLD path \"\"\" module_path = os.path.dirname(os.path.dirname(inspect.getfile(dcm2bids))) # module_path = inspect.getfile(dcm2bids) scaffold_dir = opj(module_path, 'data', 'scaffold') # scaffold_dir = pkg_resources.resource_filename(__name__, os.path.join(\"data\", \"scaffold\")) # print(module_path) # scaffold_dir = os.path.join(os.path.dirname( # os.path.dirname(module_path)), \"data\", \"scaffold\") print(scaffold_dir) return scaffold_dir load_json \u2693\ufe0e 1 2 3 def load_json ( filename ) Load a JSON file Args: filename (str): Path of a JSON file Return: Dictionnary of the JSON file View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def load_json(filename): \"\"\" Load a JSON file Args: filename (str): Path of a JSON file Return: Dictionnary of the JSON file \"\"\" with open(filename, \"r\") as f: data = json.load(f, object_pairs_hook=OrderedDict) return data save_json \u2693\ufe0e 1 2 3 4 def save_json ( filename , data ) View Source 1 2 3 4 5 def save_json(filename, data): with open(filename, \"w\") as f: json.dump(data, f, indent=4) valid_path \u2693\ufe0e 1 2 3 4 def valid_path ( in_path , type = 'folder' ) Assert that file exists. Parameters: Name Type Description Default required_file Path Path to be checked. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def valid_path(in_path, type=\"folder\"): \"\"\"Assert that file exists. Parameters ---------- required_file: Path Path to be checked. \"\"\" if isinstance(in_path, str): in_path = Path(in_path) if type == 'folder': if in_path.is_dir() or in_path.parent.is_dir(): return in_path else: raise NotADirectoryError(in_path) elif type == \"file\": if in_path.is_file(): return in_path else: raise FileNotFoundError(in_path) raise TypeError(type) write_txt \u2693\ufe0e 1 2 3 4 def write_txt ( filename , lines ) View Source 1 2 3 4 5 def write_txt(filename, lines): with open(filename, \"a+\") as f: f.write(f\"{lines}\\n\")","title":"Io"},{"location":"reference/dcm2bids/utils/io/#module-dcm2bidsutilsio","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 # -*- coding: utf-8 -*- import inspect import json import os import os.path as opj from pathlib import Path from collections import OrderedDict import dcm2bids def load_json(filename): \"\"\" Load a JSON file Args: filename (str): Path of a JSON file Return: Dictionnary of the JSON file \"\"\" with open(filename, \"r\") as f: data = json.load(f, object_pairs_hook=OrderedDict) return data def save_json(filename, data): with open(filename, \"w\") as f: json.dump(data, f, indent=4) def write_txt(filename, lines): with open(filename, \"a+\") as f: f.write(f\"{lines}\\n\") def get_scaffold_dir(): \"\"\" Return SCAFFOLD data directory in dcm2bids repository Returns ------- scaffold_dir: string SCAFFOLD path \"\"\" module_path = os.path.dirname(os.path.dirname(inspect.getfile(dcm2bids))) # module_path = inspect.getfile(dcm2bids) scaffold_dir = opj(module_path, 'data', 'scaffold') # scaffold_dir = pkg_resources.resource_filename(__name__, os.path.join(\"data\", \"scaffold\")) # print(module_path) # scaffold_dir = os.path.join(os.path.dirname( # os.path.dirname(module_path)), \"data\", \"scaffold\") print(scaffold_dir) return scaffold_dir def valid_path(in_path, type=\"folder\"): \"\"\"Assert that file exists. Parameters ---------- required_file: Path Path to be checked. \"\"\" if isinstance(in_path, str): in_path = Path(in_path) if type == 'folder': if in_path.is_dir() or in_path.parent.is_dir(): return in_path else: raise NotADirectoryError(in_path) elif type == \"file\": if in_path.is_file(): return in_path else: raise FileNotFoundError(in_path) raise TypeError(type)","title":"Module dcm2bids.utils.io"},{"location":"reference/dcm2bids/utils/io/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/utils/io/#get_scaffold_dir","text":"1 2 3 def get_scaffold_dir ( ) Return SCAFFOLD data directory in dcm2bids repository Returns: Type Description string SCAFFOLD path View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def get_scaffold_dir(): \"\"\" Return SCAFFOLD data directory in dcm2bids repository Returns ------- scaffold_dir: string SCAFFOLD path \"\"\" module_path = os.path.dirname(os.path.dirname(inspect.getfile(dcm2bids))) # module_path = inspect.getfile(dcm2bids) scaffold_dir = opj(module_path, 'data', 'scaffold') # scaffold_dir = pkg_resources.resource_filename(__name__, os.path.join(\"data\", \"scaffold\")) # print(module_path) # scaffold_dir = os.path.join(os.path.dirname( # os.path.dirname(module_path)), \"data\", \"scaffold\") print(scaffold_dir) return scaffold_dir","title":"get_scaffold_dir"},{"location":"reference/dcm2bids/utils/io/#load_json","text":"1 2 3 def load_json ( filename ) Load a JSON file Args: filename (str): Path of a JSON file Return: Dictionnary of the JSON file View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def load_json(filename): \"\"\" Load a JSON file Args: filename (str): Path of a JSON file Return: Dictionnary of the JSON file \"\"\" with open(filename, \"r\") as f: data = json.load(f, object_pairs_hook=OrderedDict) return data","title":"load_json"},{"location":"reference/dcm2bids/utils/io/#save_json","text":"1 2 3 4 def save_json ( filename , data ) View Source 1 2 3 4 5 def save_json(filename, data): with open(filename, \"w\") as f: json.dump(data, f, indent=4)","title":"save_json"},{"location":"reference/dcm2bids/utils/io/#valid_path","text":"1 2 3 4 def valid_path ( in_path , type = 'folder' ) Assert that file exists. Parameters: Name Type Description Default required_file Path Path to be checked. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def valid_path(in_path, type=\"folder\"): \"\"\"Assert that file exists. Parameters ---------- required_file: Path Path to be checked. \"\"\" if isinstance(in_path, str): in_path = Path(in_path) if type == 'folder': if in_path.is_dir() or in_path.parent.is_dir(): return in_path else: raise NotADirectoryError(in_path) elif type == \"file\": if in_path.is_file(): return in_path else: raise FileNotFoundError(in_path) raise TypeError(type)","title":"valid_path"},{"location":"reference/dcm2bids/utils/io/#write_txt","text":"1 2 3 4 def write_txt ( filename , lines ) View Source 1 2 3 4 5 def write_txt(filename, lines): with open(filename, \"a+\") as f: f.write(f\"{lines}\\n\")","title":"write_txt"},{"location":"reference/dcm2bids/utils/logger/","text":"Module dcm2bids.utils.logger \u2693\ufe0e Setup logging configuration View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # -*- coding: utf-8 -*- \"\"\"Setup logging configuration\"\"\" import logging def setup_logging(logLevel, logFile=None): \"\"\" Setup logging configuration\"\"\" logging.basicConfig() logger = logging.getLogger() # Check level level = getattr(logging, logLevel.upper(), None) if not isinstance(level, int): raise ValueError(\"Invalid log level: {}\".format(logLevel)) logger.setLevel(level) # Set FileHandler if logFile: formatter = logging.Formatter(logging.BASIC_FORMAT) handler = logging.FileHandler(logFile) handler.setFormatter(formatter) handler.setLevel(\"DEBUG\") logger.addHandler(handler) Functions \u2693\ufe0e setup_logging \u2693\ufe0e 1 2 3 4 def setup_logging ( logLevel , logFile = None ) Setup logging configuration View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def setup_logging(logLevel, logFile=None): \"\"\" Setup logging configuration\"\"\" logging.basicConfig() logger = logging.getLogger() # Check level level = getattr(logging, logLevel.upper(), None) if not isinstance(level, int): raise ValueError(\"Invalid log level: {}\".format(logLevel)) logger.setLevel(level) # Set FileHandler if logFile: formatter = logging.Formatter(logging.BASIC_FORMAT) handler = logging.FileHandler(logFile) handler.setFormatter(formatter) handler.setLevel(\"DEBUG\") logger.addHandler(handler)","title":"Logger"},{"location":"reference/dcm2bids/utils/logger/#module-dcm2bidsutilslogger","text":"Setup logging configuration View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # -*- coding: utf-8 -*- \"\"\"Setup logging configuration\"\"\" import logging def setup_logging(logLevel, logFile=None): \"\"\" Setup logging configuration\"\"\" logging.basicConfig() logger = logging.getLogger() # Check level level = getattr(logging, logLevel.upper(), None) if not isinstance(level, int): raise ValueError(\"Invalid log level: {}\".format(logLevel)) logger.setLevel(level) # Set FileHandler if logFile: formatter = logging.Formatter(logging.BASIC_FORMAT) handler = logging.FileHandler(logFile) handler.setFormatter(formatter) handler.setLevel(\"DEBUG\") logger.addHandler(handler)","title":"Module dcm2bids.utils.logger"},{"location":"reference/dcm2bids/utils/logger/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/utils/logger/#setup_logging","text":"1 2 3 4 def setup_logging ( logLevel , logFile = None ) Setup logging configuration View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def setup_logging(logLevel, logFile=None): \"\"\" Setup logging configuration\"\"\" logging.basicConfig() logger = logging.getLogger() # Check level level = getattr(logging, logLevel.upper(), None) if not isinstance(level, int): raise ValueError(\"Invalid log level: {}\".format(logLevel)) logger.setLevel(level) # Set FileHandler if logFile: formatter = logging.Formatter(logging.BASIC_FORMAT) handler = logging.FileHandler(logFile) handler.setFormatter(formatter) handler.setLevel(\"DEBUG\") logger.addHandler(handler)","title":"setup_logging"},{"location":"reference/dcm2bids/utils/scaffold/","text":"Module dcm2bids.utils.scaffold \u2693\ufe0e View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 # -*- coding: utf-8 -*- class bids_starter_kit(object): CHANGES = \"\"\"Revision history for your dataset 1.0.0 DATE - Initialized study directory \"\"\" dataset_description = \"\"\"{ \"Name\": \"\", \"BIDSVersion\": \"BIDS_VERSION\", \"License\": \"\", \"Authors\": [ \"\" ], \"Acknowledgments\": \"\", \"HowToAcknowledge\": \"\", \"Funding\": [ \"\" ], \"ReferencesAndLinks\": [ \"\" ], \"DatasetDOI\": \"\" } \"\"\" participants_json = \"\"\"{ \"age\": { \"LongName\": \"\", \"Description\": \"age of the participant\", \"Levels\": [], \"Units\": \"years\", \"TermURL\": \"\" }, \"sex\": { \"LongName\": \"\", \"Description\": \"sex of the participant as reported by the participant\", \"Levels\": { \"M\": \"male\", \"F\": \"female\" }, \"Units\": \"\", \"TermURL\": \"\" }, \"group\": { \"LongName\": \"\", \"Description\": \"Group of the participant\", \"Levels\": { \"control\": \"Control\", \"patient\": \"Patient\" }, \"Units\": \"\", \"TermURL\": \"\" }, } \"\"\" participants_tsv = \"\"\"participant_id age sex group sub-01 34 M control sub-02 12 F control sub-03 33 F patient \"\"\" README = \"\"\"# README The README is usually the starting point for researchers using your data and serves as a guidepost for users of your data. A clear and informative README makes your data much more usable. In general you can include information in the README that is not captured by some other files in the BIDS dataset (dataset_description.json, events.tsv, ...). It can also be useful to also include information that might already be present in another file of the dataset but might be important for users to be aware of before preprocessing or analysing the data. If the README gets too long you have the possibility to create a `/doc` folder and add it to the `.bidsignore` file to make sure it is ignored by the BIDS validator. More info here: https://neurostars.org/t/where-in-a-bids-dataset-should-i-put-notes-about-individual-mri-acqusitions/17315/3 ## Details related to access to the data - [ ] Data user agreement If the dataset requires a data user agreement, link to the relevant information. - [ ] Contact person Indicate the name and contact details (email and ORCID) of the person responsible for additional information. - [ ] Practical information to access the data If there is any special information related to access rights or how to download the data make sure to include it. For example, if the dataset was curated using datalad, make sure to include the relevant section from the datalad handbook: http://handbook.datalad.org/en/latest/basics/101-180-FAQ.html#how-can-i-help-others-get-started-with-a-shared-dataset ## Overview - [ ] Project name (if relevant) - [ ] Year(s) that the project ran If no `scans.tsv` is included, this could at least cover when the data acquisition starter and ended. Local time of day is particularly relevant to subject state. - [ ] Brief overview of the tasks in the experiment A paragraph giving an overview of the experiment. This should include the goals or purpose and a discussion about how the experiment tries to achieve these goals. - [ ] Description of the contents of the dataset An easy thing to add is the output of the bids-validator that describes what type of data and the number of subject one can expect to find in the dataset. - [ ] Independent variables A brief discussion of condition variables (sometimes called contrasts or independent variables) that were varied across the experiment. - [ ] Dependent variables A brief discussion of the response variables (sometimes called the dependent variables) that were measured and or calculated to assess the effects of varying the condition variables. This might also include questionnaires administered to assess behavioral aspects of the experiment. - [ ] Control variables A brief discussion of the control variables --- that is what aspects were explicitly controlled in this experiment. The control variables might include subject pool, environmental conditions, set up, or other things that were explicitly controlled. - [ ] Quality assessment of the data Provide a short summary of the quality of the data ideally with descriptive statistics if relevant and with a link to more comprehensive description (like with MRIQC) if possible. ## Methods ### Subjects A brief sentence about the subject pool in this experiment. Remember that `Control` or `Patient` status should be defined in the `participants.tsv` using a group column. - [ ] Information about the recruitment procedure - [ ] Subject inclusion criteria (if relevant) - [ ] Subject exclusion criteria (if relevant) ### Apparatus A summary of the equipment and environment setup for the experiment. For example, was the experiment performed in a shielded room with the subject seated in a fixed position. ### Initial setup A summary of what setup was performed when a subject arrived. ### Task organization How the tasks were organized for a session. This is particularly important because BIDS datasets usually have task data separated into different files.) - [ ] Was task order counter-balanced? - [ ] What other activities were interspersed between tasks? - [ ] In what order were the tasks and other activities performed? ### Task details As much detail as possible about the task and the events that were recorded. ### Additional data acquired A brief indication of data other than the imaging data that was acquired as part of this experiment. In addition to data from other modalities and behavioral data, this might include questionnaires and surveys, swabs, and clinical information. Indicate the availability of this data. This is especially relevant if the data are not included in a `phenotype` folder. https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html#phenotypic-and-assessment-data ### Experimental location This should include any additional information regarding the the geographical location and facility that cannot be included in the relevant json files. ### Missing data Mention something if some participants are missing some aspects of the data. This can take the form of a processing log and/or abnormalities about the dataset. Some examples: - A brain lesion or defect only present in one participant - Some experimental conditions missing on a given run for a participant because of some technical issue. - Any noticeable feature of the data for certain participants - Differences (even slight) in protocol for certain participants. ### Notes Any additional information or pointers to information that might be helpful to users of the dataset. Include qualitative information related to how the data acquisition went. \"\"\" Classes \u2693\ufe0e bids_starter_kit \u2693\ufe0e 1 2 3 4 5 class bids_starter_kit ( / , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 class bids_starter_kit(object): CHANGES = \"\"\"Revision history for your dataset 1.0.0 DATE - Initialized study directory \"\"\" dataset_description = \"\"\"{ \"Name\": \"\", \"BIDSVersion\": \"BIDS_VERSION\", \"License\": \"\", \"Authors\": [ \"\" ], \"Acknowledgments\": \"\", \"HowToAcknowledge\": \"\", \"Funding\": [ \"\" ], \"ReferencesAndLinks\": [ \"\" ], \"DatasetDOI\": \"\" } \"\"\" participants_json = \"\"\"{ \"age\": { \"LongName\": \"\", \"Description\": \"age of the participant\", \"Levels\": [], \"Units\": \"years\", \"TermURL\": \"\" }, \"sex\": { \"LongName\": \"\", \"Description\": \"sex of the participant as reported by the participant\", \"Levels\": { \"M\": \"male\", \"F\": \"female\" }, \"Units\": \"\", \"TermURL\": \"\" }, \"group\": { \"LongName\": \"\", \"Description\": \"Group of the participant\", \"Levels\": { \"control\": \"Control\", \"patient\": \"Patient\" }, \"Units\": \"\", \"TermURL\": \"\" }, } \"\"\" participants_tsv = \"\"\"participant_id age sex group sub-01 34 M control sub-02 12 F control sub-03 33 F patient \"\"\" README = \"\"\"# README The README is usually the starting point for researchers using your data and serves as a guidepost for users of your data. A clear and informative README makes your data much more usable. In general you can include information in the README that is not captured by some other files in the BIDS dataset (dataset_description.json, events.tsv, ...). It can also be useful to also include information that might already be present in another file of the dataset but might be important for users to be aware of before preprocessing or analysing the data. If the README gets too long you have the possibility to create a `/doc` folder and add it to the `.bidsignore` file to make sure it is ignored by the BIDS validator. More info here: https://neurostars.org/t/where-in-a-bids-dataset-should-i-put-notes-about-individual-mri-acqusitions/17315/3 ## Details related to access to the data - [ ] Data user agreement If the dataset requires a data user agreement, link to the relevant information. - [ ] Contact person Indicate the name and contact details (email and ORCID) of the person responsible for additional information. - [ ] Practical information to access the data If there is any special information related to access rights or how to download the data make sure to include it. For example, if the dataset was curated using datalad, make sure to include the relevant section from the datalad handbook: http://handbook.datalad.org/en/latest/basics/101-180-FAQ.html#how-can-i-help-others-get-started-with-a-shared-dataset ## Overview - [ ] Project name (if relevant) - [ ] Year(s) that the project ran If no `scans.tsv` is included, this could at least cover when the data acquisition starter and ended. Local time of day is particularly relevant to subject state. - [ ] Brief overview of the tasks in the experiment A paragraph giving an overview of the experiment. This should include the goals or purpose and a discussion about how the experiment tries to achieve these goals. - [ ] Description of the contents of the dataset An easy thing to add is the output of the bids-validator that describes what type of data and the number of subject one can expect to find in the dataset. - [ ] Independent variables A brief discussion of condition variables (sometimes called contrasts or independent variables) that were varied across the experiment. - [ ] Dependent variables A brief discussion of the response variables (sometimes called the dependent variables) that were measured and or calculated to assess the effects of varying the condition variables. This might also include questionnaires administered to assess behavioral aspects of the experiment. - [ ] Control variables A brief discussion of the control variables --- that is what aspects were explicitly controlled in this experiment. The control variables might include subject pool, environmental conditions, set up, or other things that were explicitly controlled. - [ ] Quality assessment of the data Provide a short summary of the quality of the data ideally with descriptive statistics if relevant and with a link to more comprehensive description (like with MRIQC) if possible. ## Methods ### Subjects A brief sentence about the subject pool in this experiment. Remember that `Control` or `Patient` status should be defined in the `participants.tsv` using a group column. - [ ] Information about the recruitment procedure - [ ] Subject inclusion criteria (if relevant) - [ ] Subject exclusion criteria (if relevant) ### Apparatus A summary of the equipment and environment setup for the experiment. For example, was the experiment performed in a shielded room with the subject seated in a fixed position. ### Initial setup A summary of what setup was performed when a subject arrived. ### Task organization How the tasks were organized for a session. This is particularly important because BIDS datasets usually have task data separated into different files.) - [ ] Was task order counter-balanced? - [ ] What other activities were interspersed between tasks? - [ ] In what order were the tasks and other activities performed? ### Task details As much detail as possible about the task and the events that were recorded. ### Additional data acquired A brief indication of data other than the imaging data that was acquired as part of this experiment. In addition to data from other modalities and behavioral data, this might include questionnaires and surveys, swabs, and clinical information. Indicate the availability of this data. This is especially relevant if the data are not included in a `phenotype` folder. https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html#phenotypic-and-assessment-data ### Experimental location This should include any additional information regarding the the geographical location and facility that cannot be included in the relevant json files. ### Missing data Mention something if some participants are missing some aspects of the data. This can take the form of a processing log and/or abnormalities about the dataset. Some examples: - A brain lesion or defect only present in one participant - Some experimental conditions missing on a given run for a participant because of some technical issue. - Any noticeable feature of the data for certain participants - Differences (even slight) in protocol for certain participants. ### Notes Any additional information or pointers to information that might be helpful to users of the dataset. Include qualitative information related to how the data acquisition went. \"\"\" Class variables \u2693\ufe0e 1 CHANGES 1 README 1 dataset_description 1 participants_json 1 participants_tsv","title":"Scaffold"},{"location":"reference/dcm2bids/utils/scaffold/#module-dcm2bidsutilsscaffold","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 # -*- coding: utf-8 -*- class bids_starter_kit(object): CHANGES = \"\"\"Revision history for your dataset 1.0.0 DATE - Initialized study directory \"\"\" dataset_description = \"\"\"{ \"Name\": \"\", \"BIDSVersion\": \"BIDS_VERSION\", \"License\": \"\", \"Authors\": [ \"\" ], \"Acknowledgments\": \"\", \"HowToAcknowledge\": \"\", \"Funding\": [ \"\" ], \"ReferencesAndLinks\": [ \"\" ], \"DatasetDOI\": \"\" } \"\"\" participants_json = \"\"\"{ \"age\": { \"LongName\": \"\", \"Description\": \"age of the participant\", \"Levels\": [], \"Units\": \"years\", \"TermURL\": \"\" }, \"sex\": { \"LongName\": \"\", \"Description\": \"sex of the participant as reported by the participant\", \"Levels\": { \"M\": \"male\", \"F\": \"female\" }, \"Units\": \"\", \"TermURL\": \"\" }, \"group\": { \"LongName\": \"\", \"Description\": \"Group of the participant\", \"Levels\": { \"control\": \"Control\", \"patient\": \"Patient\" }, \"Units\": \"\", \"TermURL\": \"\" }, } \"\"\" participants_tsv = \"\"\"participant_id age sex group sub-01 34 M control sub-02 12 F control sub-03 33 F patient \"\"\" README = \"\"\"# README The README is usually the starting point for researchers using your data and serves as a guidepost for users of your data. A clear and informative README makes your data much more usable. In general you can include information in the README that is not captured by some other files in the BIDS dataset (dataset_description.json, events.tsv, ...). It can also be useful to also include information that might already be present in another file of the dataset but might be important for users to be aware of before preprocessing or analysing the data. If the README gets too long you have the possibility to create a `/doc` folder and add it to the `.bidsignore` file to make sure it is ignored by the BIDS validator. More info here: https://neurostars.org/t/where-in-a-bids-dataset-should-i-put-notes-about-individual-mri-acqusitions/17315/3 ## Details related to access to the data - [ ] Data user agreement If the dataset requires a data user agreement, link to the relevant information. - [ ] Contact person Indicate the name and contact details (email and ORCID) of the person responsible for additional information. - [ ] Practical information to access the data If there is any special information related to access rights or how to download the data make sure to include it. For example, if the dataset was curated using datalad, make sure to include the relevant section from the datalad handbook: http://handbook.datalad.org/en/latest/basics/101-180-FAQ.html#how-can-i-help-others-get-started-with-a-shared-dataset ## Overview - [ ] Project name (if relevant) - [ ] Year(s) that the project ran If no `scans.tsv` is included, this could at least cover when the data acquisition starter and ended. Local time of day is particularly relevant to subject state. - [ ] Brief overview of the tasks in the experiment A paragraph giving an overview of the experiment. This should include the goals or purpose and a discussion about how the experiment tries to achieve these goals. - [ ] Description of the contents of the dataset An easy thing to add is the output of the bids-validator that describes what type of data and the number of subject one can expect to find in the dataset. - [ ] Independent variables A brief discussion of condition variables (sometimes called contrasts or independent variables) that were varied across the experiment. - [ ] Dependent variables A brief discussion of the response variables (sometimes called the dependent variables) that were measured and or calculated to assess the effects of varying the condition variables. This might also include questionnaires administered to assess behavioral aspects of the experiment. - [ ] Control variables A brief discussion of the control variables --- that is what aspects were explicitly controlled in this experiment. The control variables might include subject pool, environmental conditions, set up, or other things that were explicitly controlled. - [ ] Quality assessment of the data Provide a short summary of the quality of the data ideally with descriptive statistics if relevant and with a link to more comprehensive description (like with MRIQC) if possible. ## Methods ### Subjects A brief sentence about the subject pool in this experiment. Remember that `Control` or `Patient` status should be defined in the `participants.tsv` using a group column. - [ ] Information about the recruitment procedure - [ ] Subject inclusion criteria (if relevant) - [ ] Subject exclusion criteria (if relevant) ### Apparatus A summary of the equipment and environment setup for the experiment. For example, was the experiment performed in a shielded room with the subject seated in a fixed position. ### Initial setup A summary of what setup was performed when a subject arrived. ### Task organization How the tasks were organized for a session. This is particularly important because BIDS datasets usually have task data separated into different files.) - [ ] Was task order counter-balanced? - [ ] What other activities were interspersed between tasks? - [ ] In what order were the tasks and other activities performed? ### Task details As much detail as possible about the task and the events that were recorded. ### Additional data acquired A brief indication of data other than the imaging data that was acquired as part of this experiment. In addition to data from other modalities and behavioral data, this might include questionnaires and surveys, swabs, and clinical information. Indicate the availability of this data. This is especially relevant if the data are not included in a `phenotype` folder. https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html#phenotypic-and-assessment-data ### Experimental location This should include any additional information regarding the the geographical location and facility that cannot be included in the relevant json files. ### Missing data Mention something if some participants are missing some aspects of the data. This can take the form of a processing log and/or abnormalities about the dataset. Some examples: - A brain lesion or defect only present in one participant - Some experimental conditions missing on a given run for a participant because of some technical issue. - Any noticeable feature of the data for certain participants - Differences (even slight) in protocol for certain participants. ### Notes Any additional information or pointers to information that might be helpful to users of the dataset. Include qualitative information related to how the data acquisition went. \"\"\"","title":"Module dcm2bids.utils.scaffold"},{"location":"reference/dcm2bids/utils/scaffold/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/utils/scaffold/#bids_starter_kit","text":"1 2 3 4 5 class bids_starter_kit ( / , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 class bids_starter_kit(object): CHANGES = \"\"\"Revision history for your dataset 1.0.0 DATE - Initialized study directory \"\"\" dataset_description = \"\"\"{ \"Name\": \"\", \"BIDSVersion\": \"BIDS_VERSION\", \"License\": \"\", \"Authors\": [ \"\" ], \"Acknowledgments\": \"\", \"HowToAcknowledge\": \"\", \"Funding\": [ \"\" ], \"ReferencesAndLinks\": [ \"\" ], \"DatasetDOI\": \"\" } \"\"\" participants_json = \"\"\"{ \"age\": { \"LongName\": \"\", \"Description\": \"age of the participant\", \"Levels\": [], \"Units\": \"years\", \"TermURL\": \"\" }, \"sex\": { \"LongName\": \"\", \"Description\": \"sex of the participant as reported by the participant\", \"Levels\": { \"M\": \"male\", \"F\": \"female\" }, \"Units\": \"\", \"TermURL\": \"\" }, \"group\": { \"LongName\": \"\", \"Description\": \"Group of the participant\", \"Levels\": { \"control\": \"Control\", \"patient\": \"Patient\" }, \"Units\": \"\", \"TermURL\": \"\" }, } \"\"\" participants_tsv = \"\"\"participant_id age sex group sub-01 34 M control sub-02 12 F control sub-03 33 F patient \"\"\" README = \"\"\"# README The README is usually the starting point for researchers using your data and serves as a guidepost for users of your data. A clear and informative README makes your data much more usable. In general you can include information in the README that is not captured by some other files in the BIDS dataset (dataset_description.json, events.tsv, ...). It can also be useful to also include information that might already be present in another file of the dataset but might be important for users to be aware of before preprocessing or analysing the data. If the README gets too long you have the possibility to create a `/doc` folder and add it to the `.bidsignore` file to make sure it is ignored by the BIDS validator. More info here: https://neurostars.org/t/where-in-a-bids-dataset-should-i-put-notes-about-individual-mri-acqusitions/17315/3 ## Details related to access to the data - [ ] Data user agreement If the dataset requires a data user agreement, link to the relevant information. - [ ] Contact person Indicate the name and contact details (email and ORCID) of the person responsible for additional information. - [ ] Practical information to access the data If there is any special information related to access rights or how to download the data make sure to include it. For example, if the dataset was curated using datalad, make sure to include the relevant section from the datalad handbook: http://handbook.datalad.org/en/latest/basics/101-180-FAQ.html#how-can-i-help-others-get-started-with-a-shared-dataset ## Overview - [ ] Project name (if relevant) - [ ] Year(s) that the project ran If no `scans.tsv` is included, this could at least cover when the data acquisition starter and ended. Local time of day is particularly relevant to subject state. - [ ] Brief overview of the tasks in the experiment A paragraph giving an overview of the experiment. This should include the goals or purpose and a discussion about how the experiment tries to achieve these goals. - [ ] Description of the contents of the dataset An easy thing to add is the output of the bids-validator that describes what type of data and the number of subject one can expect to find in the dataset. - [ ] Independent variables A brief discussion of condition variables (sometimes called contrasts or independent variables) that were varied across the experiment. - [ ] Dependent variables A brief discussion of the response variables (sometimes called the dependent variables) that were measured and or calculated to assess the effects of varying the condition variables. This might also include questionnaires administered to assess behavioral aspects of the experiment. - [ ] Control variables A brief discussion of the control variables --- that is what aspects were explicitly controlled in this experiment. The control variables might include subject pool, environmental conditions, set up, or other things that were explicitly controlled. - [ ] Quality assessment of the data Provide a short summary of the quality of the data ideally with descriptive statistics if relevant and with a link to more comprehensive description (like with MRIQC) if possible. ## Methods ### Subjects A brief sentence about the subject pool in this experiment. Remember that `Control` or `Patient` status should be defined in the `participants.tsv` using a group column. - [ ] Information about the recruitment procedure - [ ] Subject inclusion criteria (if relevant) - [ ] Subject exclusion criteria (if relevant) ### Apparatus A summary of the equipment and environment setup for the experiment. For example, was the experiment performed in a shielded room with the subject seated in a fixed position. ### Initial setup A summary of what setup was performed when a subject arrived. ### Task organization How the tasks were organized for a session. This is particularly important because BIDS datasets usually have task data separated into different files.) - [ ] Was task order counter-balanced? - [ ] What other activities were interspersed between tasks? - [ ] In what order were the tasks and other activities performed? ### Task details As much detail as possible about the task and the events that were recorded. ### Additional data acquired A brief indication of data other than the imaging data that was acquired as part of this experiment. In addition to data from other modalities and behavioral data, this might include questionnaires and surveys, swabs, and clinical information. Indicate the availability of this data. This is especially relevant if the data are not included in a `phenotype` folder. https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html#phenotypic-and-assessment-data ### Experimental location This should include any additional information regarding the the geographical location and facility that cannot be included in the relevant json files. ### Missing data Mention something if some participants are missing some aspects of the data. This can take the form of a processing log and/or abnormalities about the dataset. Some examples: - A brain lesion or defect only present in one participant - Some experimental conditions missing on a given run for a participant because of some technical issue. - Any noticeable feature of the data for certain participants - Differences (even slight) in protocol for certain participants. ### Notes Any additional information or pointers to information that might be helpful to users of the dataset. Include qualitative information related to how the data acquisition went. \"\"\"","title":"bids_starter_kit"},{"location":"reference/dcm2bids/utils/scaffold/#class-variables","text":"1 CHANGES 1 README 1 dataset_description 1 participants_json 1 participants_tsv","title":"Class variables"},{"location":"reference/dcm2bids/utils/tools/","text":"Module dcm2bids.utils.tools \u2693\ufe0e This module take care of the versioning View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 # -*- coding: utf-8 -*- \"\"\"This module take care of the versioning\"\"\" import logging import shlex from packaging import version from subprocess import check_output, CalledProcessError, TimeoutExpired from shutil import which from dcm2bids.version import __version__ logger = logging.getLogger(__name__) def is_tool(name): \"\"\" Check if a program is in PATH Args: name (string): program name Returns: boolean \"\"\" return which(name) is not None def check_github_latest(githubRepo, timeout=3): \"\"\" Check the latest version of a github repository Args: githubRepo (string): a github repository (\"username/repository\") timeout (int): time in seconds Returns: A string of the version \"\"\" url = f\"https://github.com/{githubRepo}/releases/latest\" try: output = check_output(shlex.split(\"curl -L --silent \" + url), timeout=timeout) except CalledProcessError: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Error while 'curl --silent {url}'\", exc_info=True) return except TimeoutExpired: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Command 'curl --silent {url}' timed out after {timeout}s\") return # The output should have this format # <html><body>You are being <a href=\"https://github.com/{gitRepo}/releases/tag/{version}\">redirected</a>.</body></html> try: version = output.decode().split(f\"{githubRepo}/releases/tag/\")[1].split('\"')[0] # Versions are X.X.X if len(version) > 5: version = version[:5] return version except: logger.debug( \"Checking latest version of %s was not possible\", githubRepo, exc_info=True, ) return def check_latest(name=\"dcm2bids\"): \"\"\" Check if a new version of a software exists and print some details Implemented for dcm2bids, dcm2niix Args: name (string): name of the software Returns: None \"\"\" data = { \"dcm2bids\": { \"repo\": \"unfmontreal/Dcm2Bids\", \"host\": \"https://github.com\", \"current\": __version__, }, \"dcm2niix\": { \"repo\": \"rordenlab/dcm2niix\", \"host\": \"https://github.com\", \"current\": dcm2niix_version, }, } if is_tool(\"curl\"): host = data.get(name)[\"host\"] if host == \"https://github.com\": repo = data.get(name)[\"repo\"] latest = check_github_latest(repo) else: # Not implemented return False else: logger.debug(\"Checking latest version of %s was not possible\", name) logger.debug(\"curl: %s\", is_tool(\"curl\")) return current = data.get(name)[\"current\"] if callable(current): current = current() try: news = version(latest) > version(current) except: news = None if news: logger.warning(\"Your using %s version %s\", name, current) logger.warning(\"A new version exists : %s\", latest) logger.warning(\"Check %s/%s\", host, repo) def dcm2niix_version(): \"\"\" Returns: A string of the version of dcm2niix install on the system \"\"\" if not is_tool(\"dcm2niix\"): logger.error(\"dcm2niix is not in your PATH or not installed\") logger.error(\"Check https://github.com/rordenlab/dcm2niix\") return try: output = check_output(shlex.split(\"dcm2niix\")) except: logger.error(\"Running: dcm2niix\", exc_info=True) return try: lines = output.decode().split(\"\\n\") except: logger.debug(output, exc_info=True) return for line in lines: try: splits = line.split() return splits[splits.index(\"version\") + 1] except: continue return Variables \u2693\ufe0e 1 logger Functions \u2693\ufe0e check_github_latest \u2693\ufe0e 1 2 3 4 def check_github_latest ( githubRepo , timeout = 3 ) Check the latest version of a github repository Parameters: Name Type Description Default githubRepo string a github repository (\"username/repository\") None timeout int time in seconds None Returns: Type Description None A string of the version View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def check_github_latest(githubRepo, timeout=3): \"\"\" Check the latest version of a github repository Args: githubRepo (string): a github repository (\"username/repository\") timeout (int): time in seconds Returns: A string of the version \"\"\" url = f\"https://github.com/{githubRepo}/releases/latest\" try: output = check_output(shlex.split(\"curl -L --silent \" + url), timeout=timeout) except CalledProcessError: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Error while 'curl --silent {url}'\", exc_info=True) return except TimeoutExpired: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Command 'curl --silent {url}' timed out after {timeout}s\") return # The output should have this format # <html><body>You are being <a href=\"https://github.com/{gitRepo}/releases/tag/{version}\">redirected</a>.</body></html> try: version = output.decode().split(f\"{githubRepo}/releases/tag/\")[1].split('\"')[0] # Versions are X.X.X if len(version) > 5: version = version[:5] return version except: logger.debug( \"Checking latest version of %s was not possible\", githubRepo, exc_info=True, ) return check_latest \u2693\ufe0e 1 2 3 def check_latest ( name = 'dcm2bids' ) Check if a new version of a software exists and print some details Implemented for dcm2bids, dcm2niix Parameters: Name Type Description Default name string name of the software None Returns: Type Description None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def check_latest(name=\"dcm2bids\"): \"\"\" Check if a new version of a software exists and print some details Implemented for dcm2bids, dcm2niix Args: name (string): name of the software Returns: None \"\"\" data = { \"dcm2bids\": { \"repo\": \"unfmontreal/Dcm2Bids\", \"host\": \"https://github.com\", \"current\": __version__, }, \"dcm2niix\": { \"repo\": \"rordenlab/dcm2niix\", \"host\": \"https://github.com\", \"current\": dcm2niix_version, }, } if is_tool(\"curl\"): host = data.get(name)[\"host\"] if host == \"https://github.com\": repo = data.get(name)[\"repo\"] latest = check_github_latest(repo) else: # Not implemented return False else: logger.debug(\"Checking latest version of %s was not possible\", name) logger.debug(\"curl: %s\", is_tool(\"curl\")) return current = data.get(name)[\"current\"] if callable(current): current = current() try: news = version(latest) > version(current) except: news = None if news: logger.warning(\"Your using %s version %s\", name, current) logger.warning(\"A new version exists : %s\", latest) logger.warning(\"Check %s/%s\", host, repo) dcm2niix_version \u2693\ufe0e 1 2 3 def dcm2niix_version ( ) Returns: A string of the version of dcm2niix install on the system View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def dcm2niix_version(): \"\"\" Returns: A string of the version of dcm2niix install on the system \"\"\" if not is_tool(\"dcm2niix\"): logger.error(\"dcm2niix is not in your PATH or not installed\") logger.error(\"Check https://github.com/rordenlab/dcm2niix\") return try: output = check_output(shlex.split(\"dcm2niix\")) except: logger.error(\"Running: dcm2niix\", exc_info=True) return try: lines = output.decode().split(\"\\n\") except: logger.debug(output, exc_info=True) return for line in lines: try: splits = line.split() return splits[splits.index(\"version\") + 1] except: continue return is_tool \u2693\ufe0e 1 2 3 def is_tool ( name ) Check if a program is in PATH Parameters: Name Type Description Default name string program name None Returns: Type Description None boolean View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def is_tool(name): \"\"\" Check if a program is in PATH Args: name (string): program name Returns: boolean \"\"\" return which(name) is not None","title":"Tools"},{"location":"reference/dcm2bids/utils/tools/#module-dcm2bidsutilstools","text":"This module take care of the versioning View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 # -*- coding: utf-8 -*- \"\"\"This module take care of the versioning\"\"\" import logging import shlex from packaging import version from subprocess import check_output, CalledProcessError, TimeoutExpired from shutil import which from dcm2bids.version import __version__ logger = logging.getLogger(__name__) def is_tool(name): \"\"\" Check if a program is in PATH Args: name (string): program name Returns: boolean \"\"\" return which(name) is not None def check_github_latest(githubRepo, timeout=3): \"\"\" Check the latest version of a github repository Args: githubRepo (string): a github repository (\"username/repository\") timeout (int): time in seconds Returns: A string of the version \"\"\" url = f\"https://github.com/{githubRepo}/releases/latest\" try: output = check_output(shlex.split(\"curl -L --silent \" + url), timeout=timeout) except CalledProcessError: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Error while 'curl --silent {url}'\", exc_info=True) return except TimeoutExpired: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Command 'curl --silent {url}' timed out after {timeout}s\") return # The output should have this format # <html><body>You are being <a href=\"https://github.com/{gitRepo}/releases/tag/{version}\">redirected</a>.</body></html> try: version = output.decode().split(f\"{githubRepo}/releases/tag/\")[1].split('\"')[0] # Versions are X.X.X if len(version) > 5: version = version[:5] return version except: logger.debug( \"Checking latest version of %s was not possible\", githubRepo, exc_info=True, ) return def check_latest(name=\"dcm2bids\"): \"\"\" Check if a new version of a software exists and print some details Implemented for dcm2bids, dcm2niix Args: name (string): name of the software Returns: None \"\"\" data = { \"dcm2bids\": { \"repo\": \"unfmontreal/Dcm2Bids\", \"host\": \"https://github.com\", \"current\": __version__, }, \"dcm2niix\": { \"repo\": \"rordenlab/dcm2niix\", \"host\": \"https://github.com\", \"current\": dcm2niix_version, }, } if is_tool(\"curl\"): host = data.get(name)[\"host\"] if host == \"https://github.com\": repo = data.get(name)[\"repo\"] latest = check_github_latest(repo) else: # Not implemented return False else: logger.debug(\"Checking latest version of %s was not possible\", name) logger.debug(\"curl: %s\", is_tool(\"curl\")) return current = data.get(name)[\"current\"] if callable(current): current = current() try: news = version(latest) > version(current) except: news = None if news: logger.warning(\"Your using %s version %s\", name, current) logger.warning(\"A new version exists : %s\", latest) logger.warning(\"Check %s/%s\", host, repo) def dcm2niix_version(): \"\"\" Returns: A string of the version of dcm2niix install on the system \"\"\" if not is_tool(\"dcm2niix\"): logger.error(\"dcm2niix is not in your PATH or not installed\") logger.error(\"Check https://github.com/rordenlab/dcm2niix\") return try: output = check_output(shlex.split(\"dcm2niix\")) except: logger.error(\"Running: dcm2niix\", exc_info=True) return try: lines = output.decode().split(\"\\n\") except: logger.debug(output, exc_info=True) return for line in lines: try: splits = line.split() return splits[splits.index(\"version\") + 1] except: continue return","title":"Module dcm2bids.utils.tools"},{"location":"reference/dcm2bids/utils/tools/#variables","text":"1 logger","title":"Variables"},{"location":"reference/dcm2bids/utils/tools/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/utils/tools/#check_github_latest","text":"1 2 3 4 def check_github_latest ( githubRepo , timeout = 3 ) Check the latest version of a github repository Parameters: Name Type Description Default githubRepo string a github repository (\"username/repository\") None timeout int time in seconds None Returns: Type Description None A string of the version View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def check_github_latest(githubRepo, timeout=3): \"\"\" Check the latest version of a github repository Args: githubRepo (string): a github repository (\"username/repository\") timeout (int): time in seconds Returns: A string of the version \"\"\" url = f\"https://github.com/{githubRepo}/releases/latest\" try: output = check_output(shlex.split(\"curl -L --silent \" + url), timeout=timeout) except CalledProcessError: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Error while 'curl --silent {url}'\", exc_info=True) return except TimeoutExpired: logger.info(f\"Checking latest version of {githubRepo} was not possible\") logger.debug(f\"Command 'curl --silent {url}' timed out after {timeout}s\") return # The output should have this format # <html><body>You are being <a href=\"https://github.com/{gitRepo}/releases/tag/{version}\">redirected</a>.</body></html> try: version = output.decode().split(f\"{githubRepo}/releases/tag/\")[1].split('\"')[0] # Versions are X.X.X if len(version) > 5: version = version[:5] return version except: logger.debug( \"Checking latest version of %s was not possible\", githubRepo, exc_info=True, ) return","title":"check_github_latest"},{"location":"reference/dcm2bids/utils/tools/#check_latest","text":"1 2 3 def check_latest ( name = 'dcm2bids' ) Check if a new version of a software exists and print some details Implemented for dcm2bids, dcm2niix Parameters: Name Type Description Default name string name of the software None Returns: Type Description None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def check_latest(name=\"dcm2bids\"): \"\"\" Check if a new version of a software exists and print some details Implemented for dcm2bids, dcm2niix Args: name (string): name of the software Returns: None \"\"\" data = { \"dcm2bids\": { \"repo\": \"unfmontreal/Dcm2Bids\", \"host\": \"https://github.com\", \"current\": __version__, }, \"dcm2niix\": { \"repo\": \"rordenlab/dcm2niix\", \"host\": \"https://github.com\", \"current\": dcm2niix_version, }, } if is_tool(\"curl\"): host = data.get(name)[\"host\"] if host == \"https://github.com\": repo = data.get(name)[\"repo\"] latest = check_github_latest(repo) else: # Not implemented return False else: logger.debug(\"Checking latest version of %s was not possible\", name) logger.debug(\"curl: %s\", is_tool(\"curl\")) return current = data.get(name)[\"current\"] if callable(current): current = current() try: news = version(latest) > version(current) except: news = None if news: logger.warning(\"Your using %s version %s\", name, current) logger.warning(\"A new version exists : %s\", latest) logger.warning(\"Check %s/%s\", host, repo)","title":"check_latest"},{"location":"reference/dcm2bids/utils/tools/#dcm2niix_version","text":"1 2 3 def dcm2niix_version ( ) Returns: A string of the version of dcm2niix install on the system View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def dcm2niix_version(): \"\"\" Returns: A string of the version of dcm2niix install on the system \"\"\" if not is_tool(\"dcm2niix\"): logger.error(\"dcm2niix is not in your PATH or not installed\") logger.error(\"Check https://github.com/rordenlab/dcm2niix\") return try: output = check_output(shlex.split(\"dcm2niix\")) except: logger.error(\"Running: dcm2niix\", exc_info=True) return try: lines = output.decode().split(\"\\n\") except: logger.debug(output, exc_info=True) return for line in lines: try: splits = line.split() return splits[splits.index(\"version\") + 1] except: continue return","title":"dcm2niix_version"},{"location":"reference/dcm2bids/utils/tools/#is_tool","text":"1 2 3 def is_tool ( name ) Check if a program is in PATH Parameters: Name Type Description Default name string program name None Returns: Type Description None boolean View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def is_tool(name): \"\"\" Check if a program is in PATH Args: name (string): program name Returns: boolean \"\"\" return which(name) is not None","title":"is_tool"},{"location":"reference/dcm2bids/utils/utils/","text":"Module dcm2bids.utils.utils \u2693\ufe0e View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 # -*- coding: utf-8 -*- import csv import logging import os from pathlib import Path from subprocess import check_output class DEFAULT(object): \"\"\" Default values of the package\"\"\" doc = \"Documentation at https://unfmontreal.github.io/Dcm2Bids/\" link_bids_validator = \"https://github.com/bids-standard/bids-validator#quickstart\" link_doc_intended_for = \"https://unfmontreal.github.io/Dcm2Bids/docs/tutorial/first-steps/#populating-the-config-file\" # cli dcm2bids cliSession = \"\" cliOutputDir = os.getcwd() cliLogLevel = \"INFO\" # dcm2bids.py outputDir = Path.cwd() session = \"\" # also Participant object bids_validate = False clobber = False forceDcm2niix = False defaceTpl = None logLevel = \"WARNING\" # dcm2niix.py dcm2niixOptions = \"-b y -ba y -z y -f '%3s_%f_%p_%t'\" # sidecar.py compKeys = [\"SeriesNumber\", \"AcquisitionTime\", \"SidecarFilename\"] searchMethod = \"fnmatch\" searchMethodChoices = [\"fnmatch\", \"re\"] runTpl = \"_run-{:02d}\" caseSensitive = True # Entity table: # https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html entityTableKeys = [\"sub\", \"ses\", \"task\", \"acq\", \"ce\", \"rec\", \"dir\", \"run\", \"mod\", \"echo\", \"flip\", \"inv\", \"mt\", \"part\", \"recording\"] # misc tmpDirName = \"tmp_dcm2bids\" helperDir = \"helper\" # BIDS version bids_version = \"v1.8.0\" def write_participants(filename, participants): with open(filename, \"w\") as f: writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=participants[0].keys()) writer.writeheader() writer.writerows(participants) def read_participants(filename): if not os.path.exists(filename): return [] with open(filename, \"r\") as f: reader = csv.DictReader(f, delimiter=\"\\t\") return [row for row in reader] def splitext_(path, extensions=None): \"\"\" Split the extension from a pathname Handle case with extensions with '.' in it Args: path (str): A path to split extensions (list): List of special extensions Returns: (root, ext): ext may be empty \"\"\" if extensions is None: extensions = [\".nii.gz\"] for ext in extensions: if path.endswith(ext): return path[: -len(ext)], path[-len(ext) :] return os.path.splitext(path) def run_shell_command(commandLine): \"\"\" Wrapper of subprocess.check_output Returns: Run command with arguments and return its output \"\"\" logger = logging.getLogger(__name__) logger.info(\"Running %s\", commandLine) return check_output(commandLine) Functions \u2693\ufe0e read_participants \u2693\ufe0e 1 2 3 def read_participants ( filename ) View Source 1 2 3 4 5 6 7 8 9 10 11 def read_participants(filename): if not os.path.exists(filename): return [] with open(filename, \"r\") as f: reader = csv.DictReader(f, delimiter=\"\\t\") return [row for row in reader] run_shell_command \u2693\ufe0e 1 2 3 def run_shell_command ( commandLine ) Wrapper of subprocess.check_output Returns: Type Description None Run command with arguments and return its output View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def run_shell_command(commandLine): \"\"\" Wrapper of subprocess.check_output Returns: Run command with arguments and return its output \"\"\" logger = logging.getLogger(__name__) logger.info(\"Running %s\", commandLine) return check_output(commandLine) splitext_ \u2693\ufe0e 1 2 3 4 def splitext_ ( path , extensions = None ) Split the extension from a pathname Handle case with extensions with '.' in it Parameters: Name Type Description Default path str A path to split None extensions list List of special extensions None Returns: Type Description None (root, ext): ext may be empty View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def splitext_(path, extensions=None): \"\"\" Split the extension from a pathname Handle case with extensions with '.' in it Args: path (str): A path to split extensions (list): List of special extensions Returns: (root, ext): ext may be empty \"\"\" if extensions is None: extensions = [\".nii.gz\"] for ext in extensions: if path.endswith(ext): return path[: -len(ext)], path[-len(ext) :] return os.path.splitext(path) write_participants \u2693\ufe0e 1 2 3 4 def write_participants ( filename , participants ) View Source 1 2 3 4 5 6 7 8 9 def write_participants(filename, participants): with open(filename, \"w\") as f: writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=participants[0].keys()) writer.writeheader() writer.writerows(participants) Classes \u2693\ufe0e DEFAULT \u2693\ufe0e 1 2 3 4 5 class DEFAULT ( / , * args , ** kwargs ) Default values of the package View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class DEFAULT(object): \"\"\" Default values of the package\"\"\" doc = \"Documentation at https://unfmontreal.github.io/Dcm2Bids/\" link_bids_validator = \"https://github.com/bids-standard/bids-validator#quickstart\" link_doc_intended_for = \"https://unfmontreal.github.io/Dcm2Bids/docs/tutorial/first-steps/#populating-the-config-file\" # cli dcm2bids cliSession = \"\" cliOutputDir = os.getcwd() cliLogLevel = \"INFO\" # dcm2bids.py outputDir = Path.cwd() session = \"\" # also Participant object bids_validate = False clobber = False forceDcm2niix = False defaceTpl = None logLevel = \"WARNING\" # dcm2niix.py dcm2niixOptions = \"-b y -ba y -z y -f '%3s_%f_%p_%t'\" # sidecar.py compKeys = [\"SeriesNumber\", \"AcquisitionTime\", \"SidecarFilename\"] searchMethod = \"fnmatch\" searchMethodChoices = [\"fnmatch\", \"re\"] runTpl = \"_run-{:02d}\" caseSensitive = True # Entity table: # https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html entityTableKeys = [\"sub\", \"ses\", \"task\", \"acq\", \"ce\", \"rec\", \"dir\", \"run\", \"mod\", \"echo\", \"flip\", \"inv\", \"mt\", \"part\", \"recording\"] # misc tmpDirName = \"tmp_dcm2bids\" helperDir = \"helper\" # BIDS version bids_version = \"v1.8.0\" Class variables \u2693\ufe0e 1 bids_validate 1 bids_version 1 caseSensitive 1 cliLogLevel 1 cliOutputDir 1 cliSession 1 clobber 1 compKeys 1 dcm2niixOptions 1 defaceTpl 1 doc 1 entityTableKeys 1 forceDcm2niix 1 helperDir 1 link_bids_validator 1 link_doc_intended_for 1 logLevel 1 outputDir 1 runTpl 1 searchMethod 1 searchMethodChoices 1 session 1 tmpDirName","title":"Utils"},{"location":"reference/dcm2bids/utils/utils/#module-dcm2bidsutilsutils","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 # -*- coding: utf-8 -*- import csv import logging import os from pathlib import Path from subprocess import check_output class DEFAULT(object): \"\"\" Default values of the package\"\"\" doc = \"Documentation at https://unfmontreal.github.io/Dcm2Bids/\" link_bids_validator = \"https://github.com/bids-standard/bids-validator#quickstart\" link_doc_intended_for = \"https://unfmontreal.github.io/Dcm2Bids/docs/tutorial/first-steps/#populating-the-config-file\" # cli dcm2bids cliSession = \"\" cliOutputDir = os.getcwd() cliLogLevel = \"INFO\" # dcm2bids.py outputDir = Path.cwd() session = \"\" # also Participant object bids_validate = False clobber = False forceDcm2niix = False defaceTpl = None logLevel = \"WARNING\" # dcm2niix.py dcm2niixOptions = \"-b y -ba y -z y -f '%3s_%f_%p_%t'\" # sidecar.py compKeys = [\"SeriesNumber\", \"AcquisitionTime\", \"SidecarFilename\"] searchMethod = \"fnmatch\" searchMethodChoices = [\"fnmatch\", \"re\"] runTpl = \"_run-{:02d}\" caseSensitive = True # Entity table: # https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html entityTableKeys = [\"sub\", \"ses\", \"task\", \"acq\", \"ce\", \"rec\", \"dir\", \"run\", \"mod\", \"echo\", \"flip\", \"inv\", \"mt\", \"part\", \"recording\"] # misc tmpDirName = \"tmp_dcm2bids\" helperDir = \"helper\" # BIDS version bids_version = \"v1.8.0\" def write_participants(filename, participants): with open(filename, \"w\") as f: writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=participants[0].keys()) writer.writeheader() writer.writerows(participants) def read_participants(filename): if not os.path.exists(filename): return [] with open(filename, \"r\") as f: reader = csv.DictReader(f, delimiter=\"\\t\") return [row for row in reader] def splitext_(path, extensions=None): \"\"\" Split the extension from a pathname Handle case with extensions with '.' in it Args: path (str): A path to split extensions (list): List of special extensions Returns: (root, ext): ext may be empty \"\"\" if extensions is None: extensions = [\".nii.gz\"] for ext in extensions: if path.endswith(ext): return path[: -len(ext)], path[-len(ext) :] return os.path.splitext(path) def run_shell_command(commandLine): \"\"\" Wrapper of subprocess.check_output Returns: Run command with arguments and return its output \"\"\" logger = logging.getLogger(__name__) logger.info(\"Running %s\", commandLine) return check_output(commandLine)","title":"Module dcm2bids.utils.utils"},{"location":"reference/dcm2bids/utils/utils/#functions","text":"","title":"Functions"},{"location":"reference/dcm2bids/utils/utils/#read_participants","text":"1 2 3 def read_participants ( filename ) View Source 1 2 3 4 5 6 7 8 9 10 11 def read_participants(filename): if not os.path.exists(filename): return [] with open(filename, \"r\") as f: reader = csv.DictReader(f, delimiter=\"\\t\") return [row for row in reader]","title":"read_participants"},{"location":"reference/dcm2bids/utils/utils/#run_shell_command","text":"1 2 3 def run_shell_command ( commandLine ) Wrapper of subprocess.check_output Returns: Type Description None Run command with arguments and return its output View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def run_shell_command(commandLine): \"\"\" Wrapper of subprocess.check_output Returns: Run command with arguments and return its output \"\"\" logger = logging.getLogger(__name__) logger.info(\"Running %s\", commandLine) return check_output(commandLine)","title":"run_shell_command"},{"location":"reference/dcm2bids/utils/utils/#splitext_","text":"1 2 3 4 def splitext_ ( path , extensions = None ) Split the extension from a pathname Handle case with extensions with '.' in it Parameters: Name Type Description Default path str A path to split None extensions list List of special extensions None Returns: Type Description None (root, ext): ext may be empty View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def splitext_(path, extensions=None): \"\"\" Split the extension from a pathname Handle case with extensions with '.' in it Args: path (str): A path to split extensions (list): List of special extensions Returns: (root, ext): ext may be empty \"\"\" if extensions is None: extensions = [\".nii.gz\"] for ext in extensions: if path.endswith(ext): return path[: -len(ext)], path[-len(ext) :] return os.path.splitext(path)","title":"splitext_"},{"location":"reference/dcm2bids/utils/utils/#write_participants","text":"1 2 3 4 def write_participants ( filename , participants ) View Source 1 2 3 4 5 6 7 8 9 def write_participants(filename, participants): with open(filename, \"w\") as f: writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=participants[0].keys()) writer.writeheader() writer.writerows(participants)","title":"write_participants"},{"location":"reference/dcm2bids/utils/utils/#classes","text":"","title":"Classes"},{"location":"reference/dcm2bids/utils/utils/#default","text":"1 2 3 4 5 class DEFAULT ( / , * args , ** kwargs ) Default values of the package View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class DEFAULT(object): \"\"\" Default values of the package\"\"\" doc = \"Documentation at https://unfmontreal.github.io/Dcm2Bids/\" link_bids_validator = \"https://github.com/bids-standard/bids-validator#quickstart\" link_doc_intended_for = \"https://unfmontreal.github.io/Dcm2Bids/docs/tutorial/first-steps/#populating-the-config-file\" # cli dcm2bids cliSession = \"\" cliOutputDir = os.getcwd() cliLogLevel = \"INFO\" # dcm2bids.py outputDir = Path.cwd() session = \"\" # also Participant object bids_validate = False clobber = False forceDcm2niix = False defaceTpl = None logLevel = \"WARNING\" # dcm2niix.py dcm2niixOptions = \"-b y -ba y -z y -f '%3s_%f_%p_%t'\" # sidecar.py compKeys = [\"SeriesNumber\", \"AcquisitionTime\", \"SidecarFilename\"] searchMethod = \"fnmatch\" searchMethodChoices = [\"fnmatch\", \"re\"] runTpl = \"_run-{:02d}\" caseSensitive = True # Entity table: # https://bids-specification.readthedocs.io/en/v1.7.0/99-appendices/04-entity-table.html entityTableKeys = [\"sub\", \"ses\", \"task\", \"acq\", \"ce\", \"rec\", \"dir\", \"run\", \"mod\", \"echo\", \"flip\", \"inv\", \"mt\", \"part\", \"recording\"] # misc tmpDirName = \"tmp_dcm2bids\" helperDir = \"helper\" # BIDS version bids_version = \"v1.8.0\"","title":"DEFAULT"},{"location":"reference/dcm2bids/utils/utils/#class-variables","text":"1 bids_validate 1 bids_version 1 caseSensitive 1 cliLogLevel 1 cliOutputDir 1 cliSession 1 clobber 1 compKeys 1 dcm2niixOptions 1 defaceTpl 1 doc 1 entityTableKeys 1 forceDcm2niix 1 helperDir 1 link_bids_validator 1 link_doc_intended_for 1 logLevel 1 outputDir 1 runTpl 1 searchMethod 1 searchMethodChoices 1 session 1 tmpDirName","title":"Class variables"}]}